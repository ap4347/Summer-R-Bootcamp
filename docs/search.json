[{"path":"index.html","id":"welcome","chapter":"Welcome","heading":"Welcome","text":"  Welcome Summer R Bootcamp. website contains comprehensive notes tutorials topics covered bootcamp. Objectives: Summer R Bootcamp aims help current/incoming MA students gain understanding core concepts R programming improve coding skills order successfully complete MA program curriculum.Students exposed various topics R programming tutorials, examples, exercises. successfully complete summer bootcamp able toManipulate wrangle data different structuresExplore data via visualization basic models exploratory data analysisTackle familiar statistical conceptsCommunicate results Timeline: July 5 – August 2 (4 weeks) topics covered Summer R Bootcamp:Week 1: Base RData TypesData StructuresConditional Statements (Control Structures) & LoopsFunctionsWeek 2: Functional Programming Tidyverse packagesFunctional ProgrammingDplyr PackageTidyr PackageWeek 3: Data Visualization, Communication, Reporting ToolsData Visualization (Base R ggplot2 package)Rmarkdown FilesWeek 4: Basic Applied Statistics ProbabilityGenerating Probability Distributions Random SamplesStatistical InferenceLinear Regression Models Assignments: requirement complete/submit homework assignments. Every week chance complete self-assessment assignments (Problem Sets), \ngraded (Solutions assignments provided).addition, supported teaching assistants (TAs), address questions walk tutorials assignments (needed) help room hours.","code":""},{"path":"introduction.html","id":"introduction","chapter":"Introduction","heading":"Introduction","text":" R programming language software environment statistical analysis, graphics representation, reporting. R created Ross Ihaka Robert Gentleman University Auckland, New Zealand, currently developed R Development Core Team. free charge open-source.Nowadays, many companies, universities, individuals backgrounds shifting towards using R, ():free open-source, available every major platform.Results produced R reproducible.R diverse supportive community, online offline.numerous set packages various tasks statistical analysis, data science, data visualization, reporting results etc.Powerful tools communicating results.RStudio IDE (Integrated Development Environment).Deep-seated language support data analysis.strong foundation functional programming.","code":""},{"path":"introduction.html","id":"getting-started-downloading-and-installing-r-rstudio","chapter":"Introduction","heading":"Getting Started: Downloading and Installing R & RStudio","text":"","code":""},{"path":"introduction.html","id":"installing-r","chapter":"Introduction","heading":"Installing R","text":"first thing need install R computer. works pretty much every platform available, including widely used Windows, Mac OS, Linux systems. can download R . Pick operating system follow instructions stated page. download R, install machine.","code":""},{"path":"introduction.html","id":"installing-rstudio","chapter":"Introduction","heading":"Installing RStudio","text":"R old-fashion, old-school interface, less intuitive makes coding harder (especially beginners). Thus, using RStudio instead. RStudio IDE (Integrated Development Environment), user-friendly interface equipment many useful features. facilitates extensive code editing, development well various features make R easy language implement. using RStudio call R. can dowload RStudio .Note, order work RStudio, first need download install R.","code":""},{"path":"introduction.html","id":"rstudio-interface","chapter":"Introduction","heading":"RStudio Interface","text":"may initially overwhelmed different panes tabs available RStudio. , things, take little bit get used eventually learn love layout.RStudio 4 main panes:","code":""},{"path":"introduction.html","id":"code-editor-source-pane","chapter":"Introduction","heading":"Code Editor (Source Pane)","text":"likely pane spend majority time top left corner. ’s called Code Editor (.k.Source Pane). place create edit R Scripts (files \".R\" extension contain code). open RStudio, automatically start new Untitled script. start typing untitled R script, always save file new file name (example, \"script_1.R\"). way, something computer crashes ’re working, R code saved re-open RStudio.notice, typing code R scripts execute . run entire code, can click Run button top pane. , want execute specific line code, put cursor line press Command + Return Mac Control + Enter PC.","code":""},{"path":"introduction.html","id":"console-pane","chapter":"Introduction","heading":"Console Pane","text":"bottom left pane called Console. using Console way check work thoughts. Basically, Console place R code run executing R scripts. place output/results displayed.","code":""},{"path":"introduction.html","id":"environmenthistory-pane","chapter":"Introduction","heading":"Environment/History Pane","text":"Environment (.k.Global Environment, .k.Working Environment) tab shows names data objects ’ve defined current R session. can also see information objects contain.History tab simply shows history code ’ve previously evaluated Console.","code":""},{"path":"introduction.html","id":"output-pane","chapter":"Introduction","heading":"Output Pane","text":"bottom right pane RStudio contains tabs default useful place view variety miscellaneous information RStudio projects files.Files: leftmost tab shows file folder structure. shows files stored, called, folders may exist project folder.Plots/Viewer: shows resulting graphs/figures R code generated.Packages: shows packages downloaded computer. can also see packages loaded current working environment looking see check-mark exists next package name.Help: shows documentations R functions, datasets, packages available R.","code":""},{"path":"introduction.html","id":"r-as-a-calculator-operators","chapter":"Introduction","heading":"R as a Calculator: Operators","text":"operator symbol tells R perform specific mathematical logical manipulations. R language rich built-operators provides following types operators:Arithmetic OperatorsRelational OperatorsLogical OperatorsAssignment OperatorsIn module consider arithmetic assignment operators. Later , discuss relational logical ones.","code":""},{"path":"introduction.html","id":"arithmetic-operators","chapter":"Introduction","heading":"Arithmetic Operators","text":"R supports various arithmetic operations. words, can use R simple calculator. instance,following table shows basic arithmetic operators supported R language:","code":"\nprint(2 + 3)\n#> [1] 5\nprint(4*5 - 2/3)\n#> [1] 19.33333"},{"path":"introduction.html","id":"assignment-operators","chapter":"Introduction","heading":"Assignment Operators","text":"order create variable R, can use <- assignment symbol. example, let’s create variable x give value 4:Let’s create another variable y, equal 10:create variables, stored global environment available use operations. Now R knows x = 4 y = 10.Note, R case sensitive. mean? means R x X different objects. , now call X variable, R throw error tell object exist global environment:","code":"\nx <- 4\nprint(x)\n#> [1] 4\ny <- 10\nprint(y)\n#> [1] 10\nprint(x + y)\n#> [1] 14\nprint(X)\n#> Error in print(X): object 'X' not found"},{"path":"introduction.html","id":"working-with-a-global-environment","chapter":"Introduction","heading":"Working with a Global Environment","text":"","code":""},{"path":"introduction.html","id":"saving-the-global-environment","chapter":"Introduction","heading":"Saving the Global Environment","text":"’ve run long code produced valuable results, might want save output stored global environment now. , can execute following line code, saves global environment working directory (place computer R saves files):","code":"\nsave.image()"},{"path":"introduction.html","id":"removing-objects-from-the-global-environment","chapter":"Introduction","heading":"Removing Objects from the Global Environment","text":"remove specific object (suppose variable x) Global Environment, use rm() function:remove objects stored Global Environment, use rm(list = ls()) function:","code":"\nrm(x)\nrm(list = ls())"},{"path":"introduction.html","id":"listing-objects-stored-in-the-global-environment","chapter":"Introduction","heading":"Listing Objects Stored in the Global Environment","text":"list objects stored Global Environment, use ls() function:","code":"\nls()"},{"path":"introduction.html","id":"working-directory","chapter":"Introduction","heading":"Working Directory","text":"mentioned, R stores files working directory. check working directory machine , use getwd() function:","code":"\ngetwd()\n#> [1] \"C:/Users/alexp/OneDrive/Desktop/R Bootcamp/R_bootcamp\""},{"path":"introduction.html","id":"getting-help","chapter":"Introduction","heading":"Getting Help","text":"Sometimes don’t exactly know certain functions work. can use ? console followed function name figure inputs (arguments) function can utilized. example, let’s check mean() function works:Now output pane (bottom right pane) Help tab see information mean() function.","code":"\n?mean"},{"path":"module-1.html","id":"module-1","chapter":"Module 1","heading":"Module 1","text":" ","code":""},{"path":"module-1.html","id":"data-types-and-data-stuctures-part-i","chapter":"Module 1","heading":"Data Types and Data Stuctures (Part I)","text":"","code":""},{"path":"module-1.html","id":"data-types","chapter":"Module 1","heading":"Data Types","text":"programming, data types important concept. Variables can store data different types, different types can different things. correct processing, programming language must know can done particular value. example, addition performed words Hello world. Similarly, change numbers 5 -22 lower uppercase.Due , R feature called data types. Different kind values assign different data types help differentiate . types certain characteristics rules associated define properties.course consider following data types:NumericIntegersComplexLogicalCharactersThere data types available R, beyond scope class. Let’s get data types one--one.","code":""},{"path":"module-1.html","id":"numeric-data-type","chapter":"Module 1","heading":"Numeric Data Type","text":"may expect, numeric data type numerical values. create variable numeric data type, simply assign numeric value variable.Use class() function find type variable .","code":"\n\nx_num <- 1\n\nprint(x_num)\n#> [1] 1\n\ny_num <- -2.35\n\nprint(y_num)\n#> [1] -2.35\n\nclass(x_num)\n#> [1] \"numeric\"\n\nclass(y_num)\n#> [1] \"numeric\""},{"path":"module-1.html","id":"integers-data-type","chapter":"Module 1","heading":"Integers Data Type","text":"integers data type special case numeric data type used integer values. store value integer, need specify using .integer() function:input value integer (example, 2.85), .integer() function remove decimal points keep integers .Another way creating variable integer data type use integer followed L letter:","code":"\n\nx_int <- as.integer(2)\n\nprint(x_int)\n#> [1] 2\n\nclass(x_int)\n#> [1] \"integer\"\n\ny_int <- as.integer(2.85)\n\nprint(y_int)\n#> [1] 2\n\nclass(x_int)\n#> [1] \"integer\"\n\nz_int <- 4L\n\nprint(z_int)\n#> [1] 4\n\nclass(z_int)\n#> [1] \"integer\""},{"path":"module-1.html","id":"complex-data-type","chapter":"Module 1","heading":"Complex Data Type","text":"Complex data types used store numbers imaginary component. instance, 1 + 3i, 2 - 5i, 3 - 4i. class going use data type, good know .","code":"\n\nx_comp <- 20 + 6i\n\nprint(x_comp)\n#> [1] 20+6i\n\nclass(x_comp)\n#> [1] \"complex\""},{"path":"module-1.html","id":"logical-data-type","chapter":"Module 1","heading":"Logical Data Type","text":"logical data type stores logical (also known boolean) values TRUE FALSE:","code":"\n\nx_logical <- TRUE\n\nprint(x_logical)\n#> [1] TRUE\n\nclass(x_logical)\n#> [1] \"logical\"\n\ny_logical <- FALSE\n\nclass(y_logical)\n#> [1] \"logical\"\n\nz_logical <- T\n\nclass(z_logical)\n#> [1] \"logical\""},{"path":"module-1.html","id":"character-data-type","chapter":"Module 1","heading":"Character Data Type","text":"character data type stores character values strings. Strings R can contain alphabet, numbers, symbols. easiest way denote value character type R wrap value inside single double quotes:","code":"\n\nx_char <- \"2102\"\n\nprint(x_char)\n#> [1] \"2102\"\n\nclass(x_char)\n#> [1] \"character\"\n\ny_char <- \"Welcome to STAT 2102!\"\n\nprint(y_char)\n#> [1] \"Welcome to STAT 2102!\"\n\nclass(y_char)\n#> [1] \"character\""},{"path":"module-1.html","id":"converting-data-types","chapter":"Module 1","heading":"Converting Data Types","text":"R can convert values one data type another. R certain rules govern conversions.","code":""},{"path":"module-1.html","id":"converting-into-numeric-data-type","chapter":"Module 1","heading":"Converting into Numeric Data Type","text":"discuss convert data type numeric, let’s first introduce .numeric() function checks whether variable numeric data type:convert data type numeric, can use .numeric() function. converting integer type data numeric, .numeric() changes type keeps value ; converting complex data type, removes imaginary part number; converting logical data type, TRUE value converted 1, FALSE converted 0; finally, character values can similarly converted numerical values string contains letters symbols, numeric value becomes NA:","code":"\n\nis.numeric(x_num)\n#> [1] TRUE\n\nis.numeric(x_char)\n#> [1] FALSE\n\n######################################\nx_comp\n#> [1] 20+6i\n\nis.numeric(x_comp)\n#> [1] FALSE\n\nnum1 <- as.numeric(x_comp)\n#> Warning: imaginary parts discarded in coercion\n\nclass(num1)\n#> [1] \"numeric\"\n\nprint(num1)\n#> [1] 20\n\n######################################\n\nx_logical\n#> [1] TRUE\n\nlogical1 <- as.numeric(x_logical)\n\nclass(logical1)\n#> [1] \"numeric\"\n\nprint(logical1)\n#> [1] 1\n\n######################################\n\ny_logical\n#> [1] FALSE\n\nlogical2 <- as.numeric(y_logical)\n\nclass(logical2)\n#> [1] \"numeric\"\n\nprint(logical2)\n#> [1] 0\n\n######################################\n\nprint(y_char)\n#> [1] \"Welcome to STAT 2102!\"\n\nchar1 <- as.numeric(y_char)\n#> Warning: NAs introduced by coercion\n\nclass(char1)\n#> [1] \"numeric\"\n\nprint(char1)\n#> [1] NA\n\n######################################\n\nprint(x_char)\n#> [1] \"2102\"\n\nchar2 <- as.numeric(x_char)\n\nclass(char2)\n#> [1] \"numeric\"\n\nprint(char2)\n#> [1] 2102"},{"path":"module-1.html","id":"converting-into-integer-data-type","chapter":"Module 1","heading":"Converting into Integer Data Type","text":"convert data type integer, can use .integer() function. properties function similar stated , skip . (Try !)","code":""},{"path":"module-1.html","id":"converting-into-logical-data-type","chapter":"Module 1","heading":"Converting into Logical Data Type","text":"convert data type logical, can utilize .logical() function. return FALSE value zero TRUE anything else. Character values converted .logical() function, always return NA:","code":"\n\n######################################\nprint(y_num)\n#> [1] -2.35\n\nis.logical(y_num)\n#> [1] FALSE\n\nlogi1 <- as.logical(y_num)\n\nclass(logi1)\n#> [1] \"logical\"\n\nprint(logi1)\n#> [1] TRUE\n\n\n\n######################################\n\nprint(y_char)\n#> [1] \"Welcome to STAT 2102!\"\n\nlogi2 <- as.logical(y_char)\n\nclass(logi2)\n#> [1] \"logical\"\n\nprint(logi2)\n#> [1] NA\n\n######################################\n\nprint(x_char)\n#> [1] \"2102\"\n\nlogi3 <- as.logical(x_char)\n\nclass(logi3)\n#> [1] \"logical\"\n\nprint(logi3)\n#> [1] NA"},{"path":"module-1.html","id":"converting-into-character-data-type","chapter":"Module 1","heading":"Converting into Character Data Type","text":"can convert data type character data type using .character() function. converts original value character string.","code":"\n\n######################################\nprint(y_num)\n#> [1] -2.35\n\nis.character(y_num)\n#> [1] FALSE\n\nchar1 <- as.character(y_num)\n\nclass(char1)\n#> [1] \"character\"\n\nprint(char1)\n#> [1] \"-2.35\"\n\n######################################\n\nprint(x_comp)\n#> [1] 20+6i\n\nchar2 <- as.character(x_comp)\n\nclass(char2)\n#> [1] \"character\"\n\nprint(char2)\n#> [1] \"20+6i\""},{"path":"module-1.html","id":"data-structures","chapter":"Module 1","heading":"Data Structures","text":"programming language, need use different variables store different data. Unlike programming languages like C Java, R doesn’t variables declared data type. , variables appointed R-objects knowledge form R-object becomes datatype variable. many types R-objects (data structures). commonly used ones :VectorsListsMatricesData FramesFactorsIn module, discuss vectors lists. Later, go data structures well.","code":""},{"path":"module-1.html","id":"vectors","chapter":"Module 1","heading":"Vectors","text":"","code":""},{"path":"module-1.html","id":"creating-vectors","chapter":"Module 1","heading":"Creating Vectors","text":"Vector basic data structure R programming language. various ways creating vector. common way using c() function:can also use : operator create vector:Another way use seq() function:can consider one function, rep(), create vector:","code":"\n\nvec1 <- c(1, 2, 3, 4, 5)\n\nprint(vec1)\n#> [1] 1 2 3 4 5\n\nvec2 <- c(\"fall\", \"winter\", \"spring\", \"summer\")\n\nprint(vec2)\n#> [1] \"fall\"   \"winter\" \"spring\" \"summer\"\n\nvec3 <- 3:11\n\nprint(vec3)\n#> [1]  3  4  5  6  7  8  9 10 11\n\nvec4 <- seq(from = 1, to = 5, by = 0.7)\n\nprint(vec4)\n#> [1] 1.0 1.7 2.4 3.1 3.8 4.5\n\n\nvec5 <- seq(from = 1, to = 5, length.out = 8)\n\nprint(vec5)\n#> [1] 1.000000 1.571429 2.142857 2.714286 3.285714 3.857143\n#> [7] 4.428571 5.000000\n\nvec6 <- rep(5, times = 3)\n\nprint(vec6)\n#> [1] 5 5 5\n\nvec7 <- rep(c(1,3,4), times = 2)\n\nprint(vec7)\n#> [1] 1 3 4 1 3 4\n\nvec8 <- rep(c(\"apple\", \"orange\", \"mango\"), times = 2, each = 3)\n\nprint(vec8)\n#>  [1] \"apple\"  \"apple\"  \"apple\"  \"orange\" \"orange\" \"orange\"\n#>  [7] \"mango\"  \"mango\"  \"mango\"  \"apple\"  \"apple\"  \"apple\" \n#> [13] \"orange\" \"orange\" \"orange\" \"mango\"  \"mango\"  \"mango\""},{"path":"module-1.html","id":"how-many-elements-does-your-vector-contain","chapter":"Module 1","heading":"How Many Elements Does Your Vector Contain?","text":"can use length() function check many elements stored vectors:","code":"\n\nprint(vec7)\n#> [1] 1 3 4 1 3 4\n\nlength(vec7)\n#> [1] 6"},{"path":"module-1.html","id":"adding-elements-to-vectors","chapter":"Module 1","heading":"Adding Elements to Vectors","text":"order add new elements existing vector, can utilize c() function :like insert element(s) specific position(s) vector, use append() function:","code":"\n\n# Adding three elements, c(15, 3, 4), to vec1\n\nvec9 <- c(vec1, c(15, 3, 4))\n\nprint(vec9)\n#> [1]  1  2  3  4  5 15  3  4\n\n# Merging vec1 and vec3\n\nvec10 <- c(vec1, vec3)\n\nprint(vec10)\n#>  [1]  1  2  3  4  5  3  4  5  6  7  8  9 10 11\n\n# Insert 55 to vec1 at the 2nd position\n\nvec11 <- append(vec1, 55, after = 1) \n\nprint(vec11)\n#> [1]  1 55  2  3  4  5"},{"path":"module-1.html","id":"subsettingindexing-vectors","chapter":"Module 1","heading":"Subsetting/Indexing Vectors","text":"use square brackets, [], extract specific elements vectors:","code":"\n\n# selects the first element of the vec1\n\nvec1[1]  \n#> [1] 1\n\n# selects the 1st, 5th, and 8th elements of the vec9\n\nvec9[c(1,5,8)]  \n#> [1] 1 5 4\n\n# selects the 4th, 5th, 6th, and 7th elements of the vec9\n\nvec9[4:7] \n#> [1]  4  5 15  3\n\n# selects the first and second elements of vec1\n\nvec1[c(T, T, F, F, F,F)]  \n#> [1] 1 2\n\n# select all elements of vec1 that are greater than 2.5\n\nvec1[vec1 > 2.5] \n#> [1] 3 4 5\n\n# select all elements of vec1 that are not equal to 3\n\nvec1[vec1 != 3] \n#> [1] 1 2 4 5\n\n# selects all elements of vec1 except the 4th one\n\nvec2[-4]  \n#> [1] \"fall\"   \"winter\" \"spring\"\n\n# selects all elements of vec1 except the 1st and 2nd ones\n\nvec2[c(-1, -2)]                \n#> [1] \"spring\" \"summer\""},{"path":"module-1.html","id":"assigning-new-values-to-elements-of-the-existing-vector","chapter":"Module 1","heading":"Assigning New Values to Elements of the Existing Vector","text":"Use assignment operator, <-, assign new values elements existing vector:","code":"\n\n# Assigning a new value to the first element of vec1\n\nprint(vec1)\n#> [1] 1 2 3 4 5\n\nvec1[1] <- 100\n\nprint(vec1)\n#> [1] 100   2   3   4   5"},{"path":"module-1.html","id":"vectorization","chapter":"Module 1","heading":"Vectorization","text":"main advantage vectors R can perform vectorized operations :","code":"\n\n# Adding 1 to each element of vec1\n\nprint(vec1 + 1)\n#> [1] 101   3   4   5   6\n\n# For each element of the vector (1:3), raising 2 to the power of its elements\n\nprint(2^(1:3))\n#> [1] 2 4 8\n\n# Doing elementwise addition (you can do it with all arithmetic operations)\n\nprint(c(1, 2, 3) + c(4, 5, 6))\n#> [1] 5 7 9\n\n# Be careful! vectors should have the same length, otherwise it will recycle\n# values of the shorter vector\n\nprint(c(1, 2, 3) + c(4, 5, 6, 7)) \n#> Warning in c(1, 2, 3) + c(4, 5, 6, 7): longer object length\n#> is not a multiple of shorter object length\n#> [1] 5 7 9 8\n\n# Checking whether 2 is in vec1 using %in% function\n\nprint(2 %in% vec1)\n#> [1] TRUE"},{"path":"module-1.html","id":"vectors-are-homogeneous","chapter":"Module 1","heading":"Vectors Are Homogeneous!","text":"main disadvantage vectors R can store homogeneous data (data type). elements vector different data types, vector convert types elements type: Question: want store heterogeneous data (data different types)?Solution: Use Lists.","code":"\n\n# R will convert all elements of vec12 into characters, because vectors can only \n#contain homogeneous data\n\nvec12 <- c(2, 3.5, \"fall\", 2.7)   \n\nprint(vec12)\n#> [1] \"2\"    \"3.5\"  \"fall\" \"2.7\"\n\nclass(vec12)\n#> [1] \"character\""},{"path":"module-1.html","id":"lists","chapter":"Module 1","heading":"Lists","text":"","code":""},{"path":"module-1.html","id":"creating-lists","chapter":"Module 1","heading":"Creating Lists","text":"can create list using list() function:","code":"\n\nlist1 <- list(2, 3.5, \"fall\", 2.7)\n\nprint(list1)\n#> [[1]]\n#> [1] 2\n#> \n#> [[2]]\n#> [1] 3.5\n#> \n#> [[3]]\n#> [1] \"fall\"\n#> \n#> [[4]]\n#> [1] 2.7\n\n\nlist2 <- list(c(2,4,10), c(\"one\", \"two\", \"three\"), 45)\n\nprint(list2)\n#> [[1]]\n#> [1]  2  4 10\n#> \n#> [[2]]\n#> [1] \"one\"   \"two\"   \"three\"\n#> \n#> [[3]]\n#> [1] 45"},{"path":"module-1.html","id":"subsettingindexing-lists-using-square-brackets-single-and-double-and","chapter":"Module 1","heading":"Subsetting/Indexing Lists Using Square Brackets (Single and Double), [] and [[]]","text":"","code":"\n\n# Selecting the first element of the list2 as a list\n\nlist2[1] \n#> [[1]]\n#> [1]  2  4 10\n\n# Selecting the first element of the list2 as it is\n\nlist2[[1]]                                    \n#> [1]  2  4 10\n\n# Selecting the second element of the first element of the list2\n\nlist2[[1]][2]                                 \n#> [1] 4"},{"path":"module-1.html","id":"merging-lists","chapter":"Module 1","heading":"Merging Lists","text":"can merge lists using c() list() functions. Can tell difference outputs functions produce?c() function merged elements list list b created list containing 6 elements. contrast, list() function created list containing two elements, list list b.","code":"\n\na <- list(1, 2, 3)\n\nb <- list (4, 5, 6)\n\nmerged_list1 <- c(a, b) \n\nprint(merged_list1)\n#> [[1]]\n#> [1] 1\n#> \n#> [[2]]\n#> [1] 2\n#> \n#> [[3]]\n#> [1] 3\n#> \n#> [[4]]\n#> [1] 4\n#> \n#> [[5]]\n#> [1] 5\n#> \n#> [[6]]\n#> [1] 6\n\nmerged_list2 <- list(a, b)  \n\nprint(merged_list2)\n#> [[1]]\n#> [[1]][[1]]\n#> [1] 1\n#> \n#> [[1]][[2]]\n#> [1] 2\n#> \n#> [[1]][[3]]\n#> [1] 3\n#> \n#> \n#> [[2]]\n#> [[2]][[1]]\n#> [1] 4\n#> \n#> [[2]][[2]]\n#> [1] 5\n#> \n#> [[2]][[3]]\n#> [1] 6"},{"path":"module-1.html","id":"flattening-lists-into-vectors","chapter":"Module 1","heading":"Flattening Lists into Vectors","text":"can convert list vector using unlist() function:","code":"\n\nlist3 <- list (c(1,2,3), 45, c(20, -5))\n\nunlist(list3)                           \n#> [1]  1  2  3 45 20 -5"},{"path":"module-1.html","id":"manipulating-elements-in-a-list","chapter":"Module 1","heading":"Manipulating Elements in a List","text":"Adding element list:Removing element list:Changing values elements list:","code":"\n\nprint(list3)\n#> [[1]]\n#> [1] 1 2 3\n#> \n#> [[2]]\n#> [1] 45\n#> \n#> [[3]]\n#> [1] 20 -5\n\nlist3[4] <- 100   \n\nprint(list3)\n#> [[1]]\n#> [1] 1 2 3\n#> \n#> [[2]]\n#> [1] 45\n#> \n#> [[3]]\n#> [1] 20 -5\n#> \n#> [[4]]\n#> [1] 100\n\n# Removing the second element in the list3\n\nlist3[2] <- NULL                           \n\nprint(list3)\n#> [[1]]\n#> [1] 1 2 3\n#> \n#> [[2]]\n#> [1] 20 -5\n#> \n#> [[3]]\n#> [1] 100\n\n# Changing the second element of the first element of the list3\n\nlist3[[1]][3] <- 50                       \n\nprint(list3)\n#> [[1]]\n#> [1]  1  2 50\n#> \n#> [[2]]\n#> [1] 20 -5\n#> \n#> [[3]]\n#> [1] 100"},{"path":"module-2.html","id":"module-2","chapter":"Module 2","heading":"Module 2","text":" ","code":""},{"path":"module-2.html","id":"data-structures-part-ii","chapter":"Module 2","heading":"Data Structures (Part II)","text":" continue exploring different data structures R programming language. module discuss matrices data frames.","code":""},{"path":"module-2.html","id":"matrices","chapter":"Module 2","heading":"Matrices","text":"Matrices R objects elements arranged two-dimensional rectangular layout (columns rows). column vertical representation data, row horizontal representation data. Like vectors, matrices work homogeneous data .","code":""},{"path":"module-2.html","id":"creating-matrices","chapter":"Module 2","heading":"Creating Matrices","text":"use matrix() function create matrix. following arguments (input values):matrix(data, nrow, ncol, byrow, dimnames)data input vector becomes data elements matrixnrow number rows createdncol number columns createdbyrow logical argument. TRUE input vector elements arranged rowdimname names assigned rows columns let’s create matrix containing c(1:12) elements:","code":"\n\n# Elements are arranged sequentially by row\n\nmatrix_1 <- matrix(c(1:12), nrow = 4, byrow = TRUE)\n\nprint(matrix_1)\n#>      [,1] [,2] [,3]\n#> [1,]    1    2    3\n#> [2,]    4    5    6\n#> [3,]    7    8    9\n#> [4,]   10   11   12\n\n\n# Elements are arranged sequentially by column\n\nmatrix_2 <- matrix(c(1:12), nrow = 4, byrow = FALSE)\n\nprint(matrix_2)\n#>      [,1] [,2] [,3]\n#> [1,]    1    5    9\n#> [2,]    2    6   10\n#> [3,]    3    7   11\n#> [4,]    4    8   12\n\n\n# Specifying the number of columns instead\n\nmatrix_3 <- matrix(c(1:12), ncol = 4, byrow = TRUE)\n\nprint(matrix_3)\n#>      [,1] [,2] [,3] [,4]\n#> [1,]    1    2    3    4\n#> [2,]    5    6    7    8\n#> [3,]    9   10   11   12\n\n\n# Defining names of columns and rows in a matrix\n\nrows <- c(\"row1\", \"row2\", \"row3\", \"row4\")\n\ncols <- c(\"col1\", \"col2\", \"col3\")\n\nmatrix_4 <- matrix(c(1:12), nrow = 4, byrow = TRUE, dimnames = list(rows, cols))\n\nprint(matrix_4)\n#>      col1 col2 col3\n#> row1    1    2    3\n#> row2    4    5    6\n#> row3    7    8    9\n#> row4   10   11   12"},{"path":"module-2.html","id":"accessing-matrix-elements","chapter":"Module 2","heading":"Accessing Matrix Elements","text":"Elements matrix can accessed using column row index element square brackets:","code":"\n\n# Accessing the element in 3rd columns and 1st row\n\nmatrix_1[1, 3]\n#> [1] 3\n\n# Accessing the element in 2nd column and 4th row\n\nmatrix_1[4, 2]\n#> [1] 11\n\n# Accessing only the 2nd row\n\nmatrix_1[2, ]\n#> [1] 4 5 6\n\n# Accessing only the 3rd column\n\nmatrix_1[, 3]\n#> [1]  3  6  9 12\n\n# Accessing only the 2nd and 3rd rows \n\nmatrix_1[c(2,3), ]\n#>      [,1] [,2] [,3]\n#> [1,]    4    5    6\n#> [2,]    7    8    9"},{"path":"module-2.html","id":"adding-and-removing-rows-columns","chapter":"Module 2","heading":"Adding and Removing Rows & Columns","text":"Use cbind() function add additional columns matrix:Use rbind() function add additional rows matrix:Use c() function negative indexes remove rows columns matrix:","code":"\n\nprint(matrix_1)\n#>      [,1] [,2] [,3]\n#> [1,]    1    2    3\n#> [2,]    4    5    6\n#> [3,]    7    8    9\n#> [4,]   10   11   12\n\nmatrix_5 <- cbind(matrix_1, c(10, 20, 30, 40))\n\nprint(matrix_5)\n#>      [,1] [,2] [,3] [,4]\n#> [1,]    1    2    3   10\n#> [2,]    4    5    6   20\n#> [3,]    7    8    9   30\n#> [4,]   10   11   12   40\n\nprint(matrix_1)\n#>      [,1] [,2] [,3]\n#> [1,]    1    2    3\n#> [2,]    4    5    6\n#> [3,]    7    8    9\n#> [4,]   10   11   12\n\nmatrix_6 <- rbind(matrix_1, c(10, 20, 30))\n\nprint(matrix_6)\n#>      [,1] [,2] [,3]\n#> [1,]    1    2    3\n#> [2,]    4    5    6\n#> [3,]    7    8    9\n#> [4,]   10   11   12\n#> [5,]   10   20   30\n\n# Removing the 1st and 2nd rows and 1st column from a matrix\n\nprint(matrix_1)\n#>      [,1] [,2] [,3]\n#> [1,]    1    2    3\n#> [2,]    4    5    6\n#> [3,]    7    8    9\n#> [4,]   10   11   12\n\nmatrix_7 <- matrix_1[c(-1, -2), c(-1)]\n\nprint(matrix_7)\n#>      [,1] [,2]\n#> [1,]    8    9\n#> [2,]   11   12"},{"path":"module-2.html","id":"assigning-values-to-matrix-elements","chapter":"Module 2","heading":"Assigning Values to Matrix Elements","text":"","code":"\n\n# Assigning a single value\n\nprint(matrix_1)\n#>      [,1] [,2] [,3]\n#> [1,]    1    2    3\n#> [2,]    4    5    6\n#> [3,]    7    8    9\n#> [4,]   10   11   12\n\nmatrix_1[1, 1] <- 100\n\nprint(matrix_1)\n#>      [,1] [,2] [,3]\n#> [1,]  100    2    3\n#> [2,]    4    5    6\n#> [3,]    7    8    9\n#> [4,]   10   11   12\n\n# Assigning a row\n\nmatrix_1[2, ] <- c(11, 22, 33)\n\nprint(matrix_1)\n#>      [,1] [,2] [,3]\n#> [1,]  100    2    3\n#> [2,]   11   22   33\n#> [3,]    7    8    9\n#> [4,]   10   11   12\n\n# Replace elements that are equal to 8 with 0\n\nmatrix_1[matrix_1 == 8] <- 0\n\nprint(matrix_1)\n#>      [,1] [,2] [,3]\n#> [1,]  100    2    3\n#> [2,]   11   22   33\n#> [3,]    7    0    9\n#> [4,]   10   11   12"},{"path":"module-2.html","id":"matrix-operations","chapter":"Module 2","heading":"Matrix Operations","text":"","code":"\n\nmatrix_8 <- matrix(1:8, nrow = 4, byrow = T)\n\nprint(matrix_8)\n#>      [,1] [,2]\n#> [1,]    1    2\n#> [2,]    3    4\n#> [3,]    5    6\n#> [4,]    7    8\n\nmatrix_9 <- matrix(1:8, nrow = 4, byrow = T)\n\nprint(matrix_9)\n#>      [,1] [,2]\n#> [1,]    1    2\n#> [2,]    3    4\n#> [3,]    5    6\n#> [4,]    7    8\n\n# Elementwise Addition\n\nprint(matrix_8 + matrix_9)\n#>      [,1] [,2]\n#> [1,]    2    4\n#> [2,]    6    8\n#> [3,]   10   12\n#> [4,]   14   16\n\n# Elementwise Subtraction\n\nprint(matrix_8 - matrix_9)\n#>      [,1] [,2]\n#> [1,]    0    0\n#> [2,]    0    0\n#> [3,]    0    0\n#> [4,]    0    0\n\n# Elementwise Multiplication\n\nprint(matrix_8 * matrix_9)\n#>      [,1] [,2]\n#> [1,]    1    4\n#> [2,]    9   16\n#> [3,]   25   36\n#> [4,]   49   64\n\n# Elementwise Division\n\nprint(matrix_8 / matrix_9)\n#>      [,1] [,2]\n#> [1,]    1    1\n#> [2,]    1    1\n#> [3,]    1    1\n#> [4,]    1    1\n\n# Multiplication by Constant\n\nprint(2 * matrix_8)\n#>      [,1] [,2]\n#> [1,]    2    4\n#> [2,]    6    8\n#> [3,]   10   12\n#> [4,]   14   16\n\n# Matrix Multiplication\n\nmatrix_10 <- matrix(1:8, nrow = 2, byrow = T)\n\nprint(matrix_10)\n#>      [,1] [,2] [,3] [,4]\n#> [1,]    1    2    3    4\n#> [2,]    5    6    7    8\n\nprint(matrix_8 %*% matrix_10)\n#>      [,1] [,2] [,3] [,4]\n#> [1,]   11   14   17   20\n#> [2,]   23   30   37   44\n#> [3,]   35   46   57   68\n#> [4,]   47   62   77   92\n\n# Matrix Transpose\n\nprint(t(matrix_8))\n#>      [,1] [,2] [,3] [,4]\n#> [1,]    1    3    5    7\n#> [2,]    2    4    6    8"},{"path":"module-2.html","id":"matrix-dimensions","chapter":"Module 2","heading":"Matrix Dimensions","text":"Use dim() function check matrix dimensions:length() function, applied matrix, shows many elements stored matrix:","code":"\n\nprint(matrix_1)\n#>      [,1] [,2] [,3]\n#> [1,]  100    2    3\n#> [2,]   11   22   33\n#> [3,]    7    0    9\n#> [4,]   10   11   12\n\ndim(matrix_1)\n#> [1] 4 3\n\nlength(matrix_1)\n#> [1] 12"},{"path":"module-2.html","id":"data-frames","chapter":"Module 2","heading":"Data Frames","text":"data frame table column contains values one variable row contains one set values column. words, data structure represents cases observations (rows) measurements (columns). Following characteristics data frame:column names non-emptyThe data stored data frame can numeric, factor (discussed later), character typeEach column contain number data items","code":""},{"path":"module-2.html","id":"creating-a-data-frame","chapter":"Module 2","heading":"Creating a Data Frame","text":"can use data.frame() function create data frame set vectors:can use srt() function check structure data frame summary() get quick summary variables stored data frame:head() tail() functions allow us view first last 6 rows data frame, respectively (number rows can specified argument):Use colnames() function get list column names change names columns data frame:","code":"\n\nName <- c(\"James\", \"Linda\", \"Stacy\", \"Mary\", \"Tom\", \"Anna\", \"Bob\", \"Jeniffer\", \"Lucas\", \"Amy\")\n\nAge <- c(22, 56, 34, 48, 19, 31, 68, 72, 39, 52)\n\nState <- c(\"California\", \"New York\", \"New York\", \"Michigan\", \"Texas\", \"Ohio\", \"Arizona\", \"Florida\", \"Nebraska\", \"Indiana\")\n\nSalary <- c(30000, 96500, 72000, 54300, 25000, 61000, 74700, 40000, 83000, 92400)\n\ndf <- data.frame(Name, Age, State, Salary)\n\nprint(df)\n#>        Name Age      State Salary\n#> 1     James  22 California  30000\n#> 2     Linda  56   New York  96500\n#> 3     Stacy  34   New York  72000\n#> 4      Mary  48   Michigan  54300\n#> 5       Tom  19      Texas  25000\n#> 6      Anna  31       Ohio  61000\n#> 7       Bob  68    Arizona  74700\n#> 8  Jeniffer  72    Florida  40000\n#> 9     Lucas  39   Nebraska  83000\n#> 10      Amy  52    Indiana  92400\n\n# Data frame structure\n\nstr(df)\n#> 'data.frame':    10 obs. of  4 variables:\n#>  $ Name  : chr  \"James\" \"Linda\" \"Stacy\" \"Mary\" ...\n#>  $ Age   : num  22 56 34 48 19 31 68 72 39 52\n#>  $ State : chr  \"California\" \"New York\" \"New York\" \"Michigan\" ...\n#>  $ Salary: num  30000 96500 72000 54300 25000 61000 74700 40000 83000 92400\n\n# Summary of variables stored in a data frame\n\nsummary(df)\n#>      Name                Age           State          \n#>  Length:10          Min.   :19.00   Length:10         \n#>  Class :character   1st Qu.:31.75   Class :character  \n#>  Mode  :character   Median :43.50   Mode  :character  \n#>                     Mean   :44.10                     \n#>                     3rd Qu.:55.00                     \n#>                     Max.   :72.00                     \n#>      Salary     \n#>  Min.   :25000  \n#>  1st Qu.:43575  \n#>  Median :66500  \n#>  Mean   :62890  \n#>  3rd Qu.:80925  \n#>  Max.   :96500\n\nhead(df)\n#>    Name Age      State Salary\n#> 1 James  22 California  30000\n#> 2 Linda  56   New York  96500\n#> 3 Stacy  34   New York  72000\n#> 4  Mary  48   Michigan  54300\n#> 5   Tom  19      Texas  25000\n#> 6  Anna  31       Ohio  61000\n\ntail(df)\n#>        Name Age    State Salary\n#> 5       Tom  19    Texas  25000\n#> 6      Anna  31     Ohio  61000\n#> 7       Bob  68  Arizona  74700\n#> 8  Jeniffer  72  Florida  40000\n#> 9     Lucas  39 Nebraska  83000\n#> 10      Amy  52  Indiana  92400\n\nhead(df, 3)\n#>    Name Age      State Salary\n#> 1 James  22 California  30000\n#> 2 Linda  56   New York  96500\n#> 3 Stacy  34   New York  72000\n\ncolnames(df)\n#> [1] \"Name\"   \"Age\"    \"State\"  \"Salary\"\n\ncolnames(df)[1] <- \"NAME\"\n\nprint(df)\n#>        NAME Age      State Salary\n#> 1     James  22 California  30000\n#> 2     Linda  56   New York  96500\n#> 3     Stacy  34   New York  72000\n#> 4      Mary  48   Michigan  54300\n#> 5       Tom  19      Texas  25000\n#> 6      Anna  31       Ohio  61000\n#> 7       Bob  68    Arizona  74700\n#> 8  Jeniffer  72    Florida  40000\n#> 9     Lucas  39   Nebraska  83000\n#> 10      Amy  52    Indiana  92400\n\ncolnames(df) <- c(\"NAME\", \"AGE\", \"STATE\", \"SALARY\")\n\nprint(df)\n#>        NAME AGE      STATE SALARY\n#> 1     James  22 California  30000\n#> 2     Linda  56   New York  96500\n#> 3     Stacy  34   New York  72000\n#> 4      Mary  48   Michigan  54300\n#> 5       Tom  19      Texas  25000\n#> 6      Anna  31       Ohio  61000\n#> 7       Bob  68    Arizona  74700\n#> 8  Jeniffer  72    Florida  40000\n#> 9     Lucas  39   Nebraska  83000\n#> 10      Amy  52    Indiana  92400"},{"path":"module-2.html","id":"subsettingextracting-elementscolumnsrows-from-a-data-frame","chapter":"Module 2","heading":"Subsetting/Extracting Elements/Columns/Rows from a Data Frame","text":"can use [], $, [[]] extract elements, columns, rows data frame (uses rule matrices):","code":"\n\n# Extracting the first column using its position; output: data frame\n\ndf[1]\n#>        NAME\n#> 1     James\n#> 2     Linda\n#> 3     Stacy\n#> 4      Mary\n#> 5       Tom\n#> 6      Anna\n#> 7       Bob\n#> 8  Jeniffer\n#> 9     Lucas\n#> 10      Amy\n\n# Extracting the first column using its position; output: vector\n\ndf[[1]]\n#>  [1] \"James\"    \"Linda\"    \"Stacy\"    \"Mary\"     \"Tom\"     \n#>  [6] \"Anna\"     \"Bob\"      \"Jeniffer\" \"Lucas\"    \"Amy\"\n\n# Extracting a column using its name; output: data frame\n\ndf[\"AGE\"]\n#>    AGE\n#> 1   22\n#> 2   56\n#> 3   34\n#> 4   48\n#> 5   19\n#> 6   31\n#> 7   68\n#> 8   72\n#> 9   39\n#> 10  52\n\ndf[c(\"AGE\", \"STATE\")]\n#>    AGE      STATE\n#> 1   22 California\n#> 2   56   New York\n#> 3   34   New York\n#> 4   48   Michigan\n#> 5   19      Texas\n#> 6   31       Ohio\n#> 7   68    Arizona\n#> 8   72    Florida\n#> 9   39   Nebraska\n#> 10  52    Indiana\n\n# Extracting a column using its name; output: vector\n\ndf[[\"AGE\"]]\n#>  [1] 22 56 34 48 19 31 68 72 39 52\n\n# Extracting a column using its name and '$' operator; output: vector\n\ndf$AGE\n#>  [1] 22 56 34 48 19 31 68 72 39 52\n\n# Extracting a single element\n\ndf[1, 2]\n#> [1] 22\n\n# Extracting multiple elements\n\ndf[1:4, c(1, 3)]\n#>    NAME      STATE\n#> 1 James California\n#> 2 Linda   New York\n#> 3 Stacy   New York\n#> 4  Mary   Michigan\n\n# Extracting the first row only\n\ndf[1, ]\n#>    NAME AGE      STATE SALARY\n#> 1 James  22 California  30000\n\n# Extracting the third column only\n\ndf[, 3]\n#>  [1] \"California\" \"New York\"   \"New York\"   \"Michigan\"  \n#>  [5] \"Texas\"      \"Ohio\"       \"Arizona\"    \"Florida\"   \n#>  [9] \"Nebraska\"   \"Indiana\"\n\n# Extracting all elements except the second column\n\ndf[, -2]\n#>        NAME      STATE SALARY\n#> 1     James California  30000\n#> 2     Linda   New York  96500\n#> 3     Stacy   New York  72000\n#> 4      Mary   Michigan  54300\n#> 5       Tom      Texas  25000\n#> 6      Anna       Ohio  61000\n#> 7       Bob    Arizona  74700\n#> 8  Jeniffer    Florida  40000\n#> 9     Lucas   Nebraska  83000\n#> 10      Amy    Indiana  92400\n\n# Extracting elements using logical operator\n\ndf[df$AGE < 50, ]\n#>    NAME AGE      STATE SALARY\n#> 1 James  22 California  30000\n#> 3 Stacy  34   New York  72000\n#> 4  Mary  48   Michigan  54300\n#> 5   Tom  19      Texas  25000\n#> 6  Anna  31       Ohio  61000\n#> 9 Lucas  39   Nebraska  83000"},{"path":"module-2.html","id":"assigning-new-value-to-data-frame-elements","chapter":"Module 2","heading":"Assigning New Value to Data Frame Elements","text":"Like matrices, can use <- operator assign values:","code":"\n\ndf[1, 4] <- 100000\n\nprint(df)\n#>        NAME AGE      STATE SALARY\n#> 1     James  22 California 100000\n#> 2     Linda  56   New York  96500\n#> 3     Stacy  34   New York  72000\n#> 4      Mary  48   Michigan  54300\n#> 5       Tom  19      Texas  25000\n#> 6      Anna  31       Ohio  61000\n#> 7       Bob  68    Arizona  74700\n#> 8  Jeniffer  72    Florida  40000\n#> 9     Lucas  39   Nebraska  83000\n#> 10      Amy  52    Indiana  92400"},{"path":"module-2.html","id":"addingremoving-columnsrows","chapter":"Module 2","heading":"Adding/Removing Columns/Rows","text":"","code":"\n\n# Adding a new column using `$` operator\n\ndf$EXPERIENCE = c(2, 30, 10, 22, 1, 12, 40, 55, 15, 22)\n\nprint(df)\n#>        NAME AGE      STATE SALARY EXPERIENCE\n#> 1     James  22 California 100000          2\n#> 2     Linda  56   New York  96500         30\n#> 3     Stacy  34   New York  72000         10\n#> 4      Mary  48   Michigan  54300         22\n#> 5       Tom  19      Texas  25000          1\n#> 6      Anna  31       Ohio  61000         12\n#> 7       Bob  68    Arizona  74700         40\n#> 8  Jeniffer  72    Florida  40000         55\n#> 9     Lucas  39   Nebraska  83000         15\n#> 10      Amy  52    Indiana  92400         22\n\n# Adding a new column using `cbind()` function\n\nSex <- c(\"Male\", \"Female\", \"Female\", \"Female\", \"Male\", \"Female\", \"Male\", \"Female\", \"Male\", \"Female\")\n\ndf_2 <- cbind(df, Sex)\n\nprint(df_2)\n#>        NAME AGE      STATE SALARY EXPERIENCE    Sex\n#> 1     James  22 California 100000          2   Male\n#> 2     Linda  56   New York  96500         30 Female\n#> 3     Stacy  34   New York  72000         10 Female\n#> 4      Mary  48   Michigan  54300         22 Female\n#> 5       Tom  19      Texas  25000          1   Male\n#> 6      Anna  31       Ohio  61000         12 Female\n#> 7       Bob  68    Arizona  74700         40   Male\n#> 8  Jeniffer  72    Florida  40000         55 Female\n#> 9     Lucas  39   Nebraska  83000         15   Male\n#> 10      Amy  52    Indiana  92400         22 Female\n\n# Adding a new row using `rbind()` function\n\nnew_obs <- data.frame(NAME = \"Jack\", AGE = 41, STATE = \"Texas\", SALARY = 150000, EXPERIENCE = 20)\n\ndf_3 <- rbind(df, new_obs)\n\nprint(df_3)\n#>        NAME AGE      STATE SALARY EXPERIENCE\n#> 1     James  22 California 100000          2\n#> 2     Linda  56   New York  96500         30\n#> 3     Stacy  34   New York  72000         10\n#> 4      Mary  48   Michigan  54300         22\n#> 5       Tom  19      Texas  25000          1\n#> 6      Anna  31       Ohio  61000         12\n#> 7       Bob  68    Arizona  74700         40\n#> 8  Jeniffer  72    Florida  40000         55\n#> 9     Lucas  39   Nebraska  83000         15\n#> 10      Amy  52    Indiana  92400         22\n#> 11     Jack  41      Texas 150000         20\n\n# Removing columns from a data frame using a `c()` function\n\ndf_4 <- df_3[, -4]\n\nprint(df_4)\n#>        NAME AGE      STATE EXPERIENCE\n#> 1     James  22 California          2\n#> 2     Linda  56   New York         30\n#> 3     Stacy  34   New York         10\n#> 4      Mary  48   Michigan         22\n#> 5       Tom  19      Texas          1\n#> 6      Anna  31       Ohio         12\n#> 7       Bob  68    Arizona         40\n#> 8  Jeniffer  72    Florida         55\n#> 9     Lucas  39   Nebraska         15\n#> 10      Amy  52    Indiana         22\n#> 11     Jack  41      Texas         20\n\n# Removing columns by assigning a `NULL` value\n\ndf_3[c(\"AGE\", \"SALARY\")] <- NULL\n\nprint(df_3)\n#>        NAME      STATE EXPERIENCE\n#> 1     James California          2\n#> 2     Linda   New York         30\n#> 3     Stacy   New York         10\n#> 4      Mary   Michigan         22\n#> 5       Tom      Texas          1\n#> 6      Anna       Ohio         12\n#> 7       Bob    Arizona         40\n#> 8  Jeniffer    Florida         55\n#> 9     Lucas   Nebraska         15\n#> 10      Amy    Indiana         22\n#> 11     Jack      Texas         20\n\n# Removing rows from a data frame\n\ndf_3[-11, ]\n#>        NAME      STATE EXPERIENCE\n#> 1     James California          2\n#> 2     Linda   New York         30\n#> 3     Stacy   New York         10\n#> 4      Mary   Michigan         22\n#> 5       Tom      Texas          1\n#> 6      Anna       Ohio         12\n#> 7       Bob    Arizona         40\n#> 8  Jeniffer    Florida         55\n#> 9     Lucas   Nebraska         15\n#> 10      Amy    Indiana         22"},{"path":"module-2.html","id":"re-ordering-columnsrows-in-a-data-frame","chapter":"Module 2","heading":"Re-ordering Columns/Rows in a Data Frame","text":"order re-order columns data frame, pass vector desired order columns using [] operator:","code":"\n\n# Re-ordering columns in a data frame\n\ndf_3[, c(\"EXPERIENCE\", \"NAME\", \"STATE\")]\n#>    EXPERIENCE     NAME      STATE\n#> 1           2    James California\n#> 2          30    Linda   New York\n#> 3          10    Stacy   New York\n#> 4          22     Mary   Michigan\n#> 5           1      Tom      Texas\n#> 6          12     Anna       Ohio\n#> 7          40      Bob    Arizona\n#> 8          55 Jeniffer    Florida\n#> 9          15    Lucas   Nebraska\n#> 10         22      Amy    Indiana\n#> 11         20     Jack      Texas\n\n# Re-ordering rows in a data frame\n\ndf_3[order(df_3$EXPERIENCE), ]     # Ascending order\n#>        NAME      STATE EXPERIENCE\n#> 5       Tom      Texas          1\n#> 1     James California          2\n#> 3     Stacy   New York         10\n#> 6      Anna       Ohio         12\n#> 9     Lucas   Nebraska         15\n#> 11     Jack      Texas         20\n#> 4      Mary   Michigan         22\n#> 10      Amy    Indiana         22\n#> 2     Linda   New York         30\n#> 7       Bob    Arizona         40\n#> 8  Jeniffer    Florida         55\n\ndf_3[order(df_3$EXPERIENCE, decreasing = TRUE), ] # Descending order\n#>        NAME      STATE EXPERIENCE\n#> 8  Jeniffer    Florida         55\n#> 7       Bob    Arizona         40\n#> 2     Linda   New York         30\n#> 4      Mary   Michigan         22\n#> 10      Amy    Indiana         22\n#> 11     Jack      Texas         20\n#> 9     Lucas   Nebraska         15\n#> 6      Anna       Ohio         12\n#> 3     Stacy   New York         10\n#> 1     James California          2\n#> 5       Tom      Texas          1"},{"path":"module-2.html","id":"checking-dimensions-of-a-data-frame","chapter":"Module 2","heading":"Checking Dimensions of a Data Frame","text":"","code":"\n\n# Data frame dimensions\n\ndim(df)\n#> [1] 10  5\n\n# Number of columns in a data frame\n\nncol(df)\n#> [1] 5\n\n# Number of rows in a data frame\n\nnrow(df)\n#> [1] 10"},{"path":"module-2.html","id":"factors","chapter":"Module 2","heading":"Factors","text":"Factor special type vectors used categorize data store levels. can store character integer types data. useful columns limited number unique values. instance, Female Male, TRUE FALSE etc.","code":""},{"path":"module-2.html","id":"creating-factors","chapter":"Module 2","heading":"Creating Factors","text":"Use factor() function R create factor:create ordered factor, use order argument inside factor() function:can convert numeric variable factor dividing intervals (segments) using cut() function:can even add labels groups:","code":"\n\nvec1 <- c(\"YES\", \"NO\", \"YES\", \"YES\", \"YES\", \"NO\", \"NO\", \"YES\")\n\nprint(vec1)\n#> [1] \"YES\" \"NO\"  \"YES\" \"YES\" \"YES\" \"NO\"  \"NO\"  \"YES\"\n\nis.factor(vec1)\n#> [1] FALSE\n\nfac1 <- factor(vec1)\n\nprint(fac1)\n#> [1] YES NO  YES YES YES NO  NO  YES\n#> Levels: NO YES\n\nis.factor(fac1)\n#> [1] TRUE\n\n\n#############\n\n\nvec2 <- c(\"Jazz\", \"Rock\", \"Classic\", \"Pop\", \"Classic\", \"Jazz\", \"Jazz\", \"Rock\")\n\nfac2 <- factor(vec2)\n\nprint(fac2)\n#> [1] Jazz    Rock    Classic Pop     Classic Jazz    Jazz   \n#> [8] Rock   \n#> Levels: Classic Jazz Pop Rock\n\n\n#############\n\n\nvec3 <- c(1, 2, 3, 2, 2, 3, 1, 3, 2, 3, 1, 1)\n\nfac3 <- factor(vec3)\n\nprint(fac3)\n#>  [1] 1 2 3 2 2 3 1 3 2 3 1 1\n#> Levels: 1 2 3\n\nfac4 <- factor(vec3, ordered = TRUE)\n\nprint(fac4)\n#>  [1] 1 2 3 2 2 3 1 3 2 3 1 1\n#> Levels: 1 < 2 < 3\n\nage_factored <- cut(df_4$AGE, 3)\n\nprint(age_factored)\n#>  [1] (18.9,36.7] (54.3,72.1] (18.9,36.7] (36.7,54.3]\n#>  [5] (18.9,36.7] (18.9,36.7] (54.3,72.1] (54.3,72.1]\n#>  [9] (36.7,54.3] (36.7,54.3] (36.7,54.3]\n#> Levels: (18.9,36.7] (36.7,54.3] (54.3,72.1]\n\nage_factored <- cut(df_4$AGE, 3, labels = c(\"Group1\", \"Group2\", \"Group3\"))\n\nprint(age_factored)\n#>  [1] Group1 Group3 Group1 Group2 Group1 Group1 Group3 Group3\n#>  [9] Group2 Group2 Group2\n#> Levels: Group1 Group2 Group3"},{"path":"module-2.html","id":"factor-levels","chapter":"Module 2","heading":"Factor Levels","text":"Use levels() function see levels factor variable :can also set levels adding levels argument inside factor() function:can change order levels passing level argument factor function desired order levels:","code":"\n\nlevels(fac1)\n#> [1] \"NO\"  \"YES\"\n\nlevels(fac2)\n#> [1] \"Classic\" \"Jazz\"    \"Pop\"     \"Rock\"\n\nlevels(fac3)\n#> [1] \"1\" \"2\" \"3\"\n\nlevels(fac4)\n#> [1] \"1\" \"2\" \"3\"\n\n\nvec2 <- c(\"Jazz\", \"Rock\", \"Classic\", \"Pop\", \"Classic\", \"Jazz\", \"Jazz\", \"Rock\")\n\nfac5 <- factor(vec2, levels = c(\"Classic\", \"Jazz\", \"Pop\", \"Rock\", \"Other\"))\n\nprint(fac5)\n#> [1] Jazz    Rock    Classic Pop     Classic Jazz    Jazz   \n#> [8] Rock   \n#> Levels: Classic Jazz Pop Rock Other\n\n\nprint(fac3)\n#>  [1] 1 2 3 2 2 3 1 3 2 3 1 1\n#> Levels: 1 2 3\n\nfac6 <- factor(vec3, levels = c(3, 1, 2))\n\nprint(fac6)\n#>  [1] 1 2 3 2 2 3 1 3 2 3 1 1\n#> Levels: 3 1 2"},{"path":"module-2.html","id":"accessing-factor-elements","chapter":"Module 2","heading":"Accessing Factor Elements","text":"can access elements stored factor way done vectors, using [].","code":""},{"path":"module-2.html","id":"assigningchanging-values-toof-factor-elements","chapter":"Module 2","heading":"Assigning/Changing Values to/of Factor Elements","text":"can assign new value factor elements using assignment sign <-:happens assign new value already specified factor levels?generate NA, Opera option among levels specified variable. add value, first need add levels:","code":"\n\nprint(fac2)\n#> [1] Jazz    Rock    Classic Pop     Classic Jazz    Jazz   \n#> [8] Rock   \n#> Levels: Classic Jazz Pop Rock\n\nfac2[1] <- \"Classic\"\n\nprint(fac2)\n#> [1] Classic Rock    Classic Pop     Classic Jazz    Jazz   \n#> [8] Rock   \n#> Levels: Classic Jazz Pop Rock\n\nprint(fac2)\n#> [1] Classic Rock    Classic Pop     Classic Jazz    Jazz   \n#> [8] Rock   \n#> Levels: Classic Jazz Pop Rock\n\nfac2[1] <- \"Opera\"\n#> Warning in `[<-.factor`(`*tmp*`, 1, value = \"Opera\"):\n#> invalid factor level, NA generated\n\nprint(fac2)\n#> [1] <NA>    Rock    Classic Pop     Classic Jazz    Jazz   \n#> [8] Rock   \n#> Levels: Classic Jazz Pop Rock\n\nfac7 <- factor(fac2, levels = c(\"Classic\", \"Jazz\", \"Pop\", \"Rock\", \"Other\", \"Opera\"))\n\nfac7[1] <- \"Opera\"\n\nprint(fac7)\n#> [1] Opera   Rock    Classic Pop     Classic Jazz    Jazz   \n#> [8] Rock   \n#> Levels: Classic Jazz Pop Rock Other Opera"},{"path":"module-2.html","id":"generating-factors","chapter":"Module 2","heading":"Generating Factors","text":"can generate factor levels using gl() function. takes two integers input indicates many levels many times level.","code":"\n\nfac8 <- gl(4, 5, labels = c(\"Fall\", \"Winter\", \"Spring\", \"Summer\"))\n\nprint(fac8)\n#>  [1] Fall   Fall   Fall   Fall   Fall   Winter Winter Winter\n#>  [9] Winter Winter Spring Spring Spring Spring Spring Summer\n#> [17] Summer Summer Summer Summer\n#> Levels: Fall Winter Spring Summer"},{"path":"module-2.html","id":"counting-factor-elementsfrequency-of-levels","chapter":"Module 2","heading":"Counting Factor Elements/Frequency of Levels","text":"","code":"\n\n# Calculating a number of elements stored in a factor\n\nlength(fac2)\n#> [1] 8\n\n# Displaying a frequency of each level of a factor\n\ntable(fac2)\n#> fac2\n#> Classic    Jazz     Pop    Rock \n#>       2       2       1       2"},{"path":"module-2.html","id":"converting-numeric-data-into-factors-and-back","chapter":"Module 2","heading":"Converting Numeric Data into Factors and Back","text":"","code":"\n\n# Converting numeric data into factors using as.factor() function\n\nvec3 <- c(0, 1, 2, 2, 1, 0, 2, 1, 0)\n\nfac9 <- as.factor(vec3)\n\nprint(fac9)\n#> [1] 0 1 2 2 1 0 2 1 0\n#> Levels: 0 1 2\n\n# Converting factors back into numeric data using as.numeric() function (part I)\n\nas.numeric(fac9)\n#> [1] 1 2 3 3 2 1 3 2 1\n\n# Converting factors back into numeric data using as.numeric() function (part II)\n\nas.numeric(levels(fac9)[fac9])\n#> [1] 0 1 2 2 1 0 2 1 0"},{"path":"module-3.html","id":"module-3","chapter":"Module 3","heading":"Module 3","text":" ","code":""},{"path":"module-3.html","id":"conditional-statements-and-loops","chapter":"Module 3","heading":"Conditional Statements and Loops","text":" Control structures R used control flow execution various R expressions. require programmer specify one conditions evaluated tested program, along statement statements executed condition determined TRUE, optionally, statements executed condition determined FALSE. words, control structures allow respond inputs features data execute different R expressions accordingly.module discuss several commonly used control structures -else statements, loops, well break next commands. move topics, first let’s discuss relational logical operators.","code":""},{"path":"module-3.html","id":"relational-and-logical-operations","chapter":"Module 3","heading":"Relational and Logical Operations","text":"","code":""},{"path":"module-3.html","id":"comparison-operators","chapter":"Module 3","heading":"Comparison Operators","text":" basic relational operators called comparison operators listed table :possible outputs operations either TRUE FALSE. examples comparison operators:applied vectors, operators element-wise comparisons (first element first vector compared first element second vector ). Suppose following two vectors:,","code":"\n\nprint (5 == 5)\n#> [1] TRUE\n\nprint(5 == 7)\n#> [1] FALSE\n\nprint(5 != 5)\n#> [1] FALSE\n\nprint(5 != 10)\n#> [1] TRUE\n\nprint(5 < 2)\n#> [1] FALSE\n\nprint(5 <= 4)\n#> [1] FALSE\n\nx <- c(1, 2, 3, 4)\n\nprint(x)\n#> [1] 1 2 3 4\n\ny <- c(4, 2, 3, 1)\n\nprint(y)\n#> [1] 4 2 3 1\n\nprint(x == y)\n#> [1] FALSE  TRUE  TRUE FALSE\n\nprint(x != y)\n#> [1]  TRUE FALSE FALSE  TRUE\n\nprint(x >= y)\n#> [1] FALSE  TRUE  TRUE  TRUE"},{"path":"module-3.html","id":"logical-operators","chapter":"Module 3","heading":"Logical Operators","text":" Logical operators used combine conditional statements:examples:","code":"\n\n##  & Operator\n\nprint(TRUE & TRUE)\n#> [1] TRUE\n\nprint (TRUE & FALSE)\n#> [1] FALSE\n\nprint(FALSE & FALSE)\n#> [1] FALSE\n\nprint (5 == 5 & 10 < 6)\n#> [1] FALSE\n\nprint(4!= 3 & 2 < 9)\n#> [1] TRUE\n\nprint(x == y & x < y)\n#> [1] FALSE FALSE FALSE FALSE\n\n\n##  | Operator\n\nprint(TRUE | TRUE)\n#> [1] TRUE\n\nprint (TRUE | FALSE)\n#> [1] TRUE\n\nprint(FALSE | FALSE)\n#> [1] FALSE\n\nprint (5 == 5 | 10 < 6)\n#> [1] TRUE\n\nprint(4!= 3 | 2 < 9)\n#> [1] TRUE\n\nprint(x == y | x < y)\n#> [1]  TRUE  TRUE  TRUE FALSE\n\n\n##  ! Operator\n\nprint (!TRUE)\n#> [1] FALSE\n\nprint(!FALSE)\n#> [1] TRUE\n\nprint(!(4<2))\n#> [1] TRUE\n\nprint(!(2 == 2 & 3 < 4))\n#> [1] FALSE"},{"path":"module-3.html","id":"conditional-statements","chapter":"Module 3","heading":"Conditional Statements","text":"","code":""},{"path":"module-3.html","id":"if-statement","chapter":"Module 3","heading":"IF Statement","text":"“statement” written keyword, used specify block code executed condition TRUE:code executed conditional statement inside parentheses FALSE. Check :","code":"\n\nif (5 > 2) {\n  \n  print(\"5 is greater than 2\")\n  \n}\n#> [1] \"5 is greater than 2\"\n\nif (5 < 2) {\n  \n  print(\"5 is greater than 2\")\n  \n}"},{"path":"module-3.html","id":"if---else-statement","chapter":"Module 3","heading":"IF - ELSE Statement","text":"-else combination probably commonly used control structure R. structure allows test condition act depending whether ’s TRUE FALSE. condition TRUE, code given curly brackets clause executed. FALSE, code curly brackets else clause executed:Now try example:can pass many conditions like adding else clause:Try different values:","code":"\n\na <- 5 ; b <- 2\n\n\nif (b > a) {\n  \n  print (\"b is greater than a\")\n  \n} else {\n  \n  print(\"b is not greater than a\")\n}\n#> [1] \"b is not greater than a\"\n\na <- 2 ; b <- 5\n\n\nif (b > a) {\n  \n  print (\"b is greater than a\")\n  \n} else {\n  \n  print(\"b is not greater than a\")\n}\n#> [1] \"b is greater than a\"\nif (b > a) {\n  \n  print (\"b is greater than a\")\n  \n} else if (a == b) {\n  \n  print (\"a and b are equal\")\n  \n} else {\n  \n  print (\"a is greater than b\")\n  \n}\n#> [1] \"b is greater than a\"\na <- 2; b <- 2\n\nif (b > a) {\n  \n  print (\"b is greater than a\")\n  \n} else if (a == b) {\n  \n  print (\"a and b are equal\")\n  \n} else {\n  \n  print (\"a is greater than b\")\n  \n}\n#> [1] \"a and b are equal\""},{"path":"module-3.html","id":"nested-if-else-statements","chapter":"Module 3","heading":"Nested IF-ELSE Statements","text":"can also statements inside statements, called nested statements.Now try x = 15 x = 5:can multiple conditional statements -else clause combined together:","code":"\n\nx <- 50\n\nif (x > 10) {\n  \n  print(\"Above ten\")\n  \n  if (x > 20) {\n    \n    print(\"and also above 20!\")\n    \n  } else {\n    \n    print(\"but not above 20.\")\n    \n  }\n  \n} else {\n  \n  print(\"below 10.\")\n  \n}\n#> [1] \"Above ten\"\n#> [1] \"and also above 20!\"\n\nx <- 15\n\nif (x > 10) {\n  \n  print(\"Above ten\")\n  \n  if (x > 20) {\n    \n    print(\"and also above 20!\")\n    \n  } else {\n    \n    print(\"but not above 20.\")\n    \n  }\n  \n} else {\n  \n  print(\"below 10.\")\n  \n}\n#> [1] \"Above ten\"\n#> [1] \"but not above 20.\"\n\nx <- 5\n\nif (x > 10) {\n  \n  print(\"Above ten\")\n  \n  if (x > 20) {\n    \n    print(\"and also above 20!\")\n    \n  } else {\n    \n    print(\"but not above 20.\")\n    \n  }\n  \n} else {\n  \n  print(\"below 10.\")\n  \n}\n#> [1] \"below 10.\"\n\na <- 200; b <- 33; c <- 500\n\n\n##  &\n\nif (a > b & c == a) {\n  \n  print(\"Both conditions are true\")\n  \n} else {\n  \n  print (\"At least one is false\")\n}\n#> [1] \"At least one is false\"\n\n\n\n##  |\n\nif (a > b | c == a) {\n  \n  print(\"At least one is true\")\n  \n} else {\n  \n  print (\"Both conditions are false\")\n}\n#> [1] \"At least one is true\""},{"path":"module-3.html","id":"ifelse-function","chapter":"Module 3","heading":"ifelse() Function","text":"Given works single TRUE FALSE, might wonder vector logical values. ifelse() can handle vectors logical values. first argument ifelse() function vector logical values,second argument value produces element logical vector TRUE, third argument value produces element logical vector FALSE. Check example :","code":"\nx <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n\nifelse(x %% 2 == 0, \"even\", \"odd\")\n#>  [1] \"odd\"  \"even\" \"odd\"  \"even\" \"odd\"  \"even\" \"odd\"  \"even\"\n#>  [9] \"odd\"  \"even\""},{"path":"module-3.html","id":"some-useful-functions-any-and-all","chapter":"Module 3","heading":"Some Useful Functions: any() and all()","text":"() () functions come handy work conditional statement. examples:","code":"\nx <- c(-2, -1, 0, 1, 2)\n\n## all(). It return TRUE if all elements of a vector satisfy the condition\n\nprint(all(x > 0))\n#> [1] FALSE\n\n## any(). It return TRUE if at least one of elements in a vector satisfies the condition\n\nprint(any(x > 0))\n#> [1] TRUE\n\n\n## Here is an example \n\nif(all(x < 0)) {\n  \n  print(\"all are negative\")\n  \n} else {\n  \n  print (\"not all of them are negative\")\n  \n}\n#> [1] \"not all of them are negative\""},{"path":"module-3.html","id":"for-loops","chapter":"Module 3","heading":"For Loops","text":"may situation need execute block code multiple times. general, statements executed sequentially. first statement function executed first, followed second, .Programming languages provide various control structures allow complicated execution paths. loop statement allows us execute statement groups statements multiple times (iterate). sequence instructions repeated certain condition reached. basic commonly used type loops loop. general format loop follows:three key aspects loops: loop object, loop vector, loop code:Loop object: object change iteration loop. usually letter like .Loop vector: vector specifying values loop object take loop. can specify values way ’d like (long ’s vector).Loop code: code executed values loop vector.can find examples loops can utilized:","code":"\n\nfor(loop.object in loop.vector) {\n\n  LOOP.CODE\n\n  }\n\n## Printing numbers from 1 to 10\n\nfor (i in 1:10){\n  \n  print (i)\n  \n}\n#> [1] 1\n#> [1] 2\n#> [1] 3\n#> [1] 4\n#> [1] 5\n#> [1] 6\n#> [1] 7\n#> [1] 8\n#> [1] 9\n#> [1] 10\n\n## Printing elements of the vector x\n\nx <- c(10, 20, 30, 40, 50)\n\nfor (i in 1:length(x)){\n  \n  print(x[i])\n  \n}\n#> [1] 10\n#> [1] 20\n#> [1] 30\n#> [1] 40\n#> [1] 50\n\n## Creating and populating an empty vector z\n\nz <- c()   # creating an empty vector.\n\nfor (i in 1:5){\n  \n  z[i] <- 2*i\n  \n}\n\nprint(z)\n#> [1]  2  4  6  8 10\n\n## Creating and populating an empty list\n\na <- list()   # creating an empty list\n\nfor (i in 1:4){\n  \n  a[[i]] <- rnorm(i)\n  \n}\n\nprint(a)\n#> [[1]]\n#> [1] -0.9442083\n#> \n#> [[2]]\n#> [1] -0.7743609  1.4411184\n#> \n#> [[3]]\n#> [1]  1.3028153  0.3930268 -1.1296306\n#> \n#> [[4]]\n#> [1] -0.1225170  1.1980069  0.3987786 -0.7221396\n\n## Updating elements of the vector x\n\nx <- c(1, 2, 3, 4, 5)\n\n\nfor (i in 1:length(x)){\n  \n  x[i] <- x[i] ^ 2\n  \n}\n\nprint(x)\n#> [1]  1  4  9 16 25\n## Summing up numbers from 1 to 100\n\ncurrent.sum <- 0\n\n\nfor(i in 1:100) {\n  \n  current.sum <- current.sum + i\n  \n}"},{"path":"module-3.html","id":"break-statement","chapter":"Module 3","heading":"Break Statement","text":"Loop control statements change execution normal sequence. Break statement stops execution loop condition specified met. words, stops looped items example,","code":"\n\nfor(i in 1:60) {\n  \n  if(i > 15){\n    \n    break\n    \n  }\n  \n  print(i)\n  \n}\n#> [1] 1\n#> [1] 2\n#> [1] 3\n#> [1] 4\n#> [1] 5\n#> [1] 6\n#> [1] 7\n#> [1] 8\n#> [1] 9\n#> [1] 10\n#> [1] 11\n#> [1] 12\n#> [1] 13\n#> [1] 14\n#> [1] 15"},{"path":"module-3.html","id":"next-statement","chapter":"Module 3","heading":"Next Statement","text":"next statement, can skip undesired iteration without terminating loop:","code":"\n## Skipping even numbers\n\nfor(i in 1:100) {\n  \n  if(i %% 2 == 0){\n    \n    next\n    \n  }\n  \n  print(i)\n  \n}\n#> [1] 1\n#> [1] 3\n#> [1] 5\n#> [1] 7\n#> [1] 9\n#> [1] 11\n#> [1] 13\n#> [1] 15\n#> [1] 17\n#> [1] 19\n#> [1] 21\n#> [1] 23\n#> [1] 25\n#> [1] 27\n#> [1] 29\n#> [1] 31\n#> [1] 33\n#> [1] 35\n#> [1] 37\n#> [1] 39\n#> [1] 41\n#> [1] 43\n#> [1] 45\n#> [1] 47\n#> [1] 49\n#> [1] 51\n#> [1] 53\n#> [1] 55\n#> [1] 57\n#> [1] 59\n#> [1] 61\n#> [1] 63\n#> [1] 65\n#> [1] 67\n#> [1] 69\n#> [1] 71\n#> [1] 73\n#> [1] 75\n#> [1] 77\n#> [1] 79\n#> [1] 81\n#> [1] 83\n#> [1] 85\n#> [1] 87\n#> [1] 89\n#> [1] 91\n#> [1] 93\n#> [1] 95\n#> [1] 97\n#> [1] 99"},{"path":"module-3.html","id":"for-loops-combined-with-if-else-statements","chapter":"Module 3","heading":"For Loops Combined with If-Else Statements","text":"can even combine loops -else statements:","code":"\n\nx <- 1:10\n\nfor (i in 1:length(x)){\n  \n  if(x[i] %% 2 == 0){\n    \n    print(paste(\"The number\", x[i], \"is even\"))\n    \n  } else {\n    \n    print(paste(\"The number\", x[i], \"is odd\"))\n    \n  }\n  \n}\n#> [1] \"The number 1 is odd\"\n#> [1] \"The number 2 is even\"\n#> [1] \"The number 3 is odd\"\n#> [1] \"The number 4 is even\"\n#> [1] \"The number 5 is odd\"\n#> [1] \"The number 6 is even\"\n#> [1] \"The number 7 is odd\"\n#> [1] \"The number 8 is even\"\n#> [1] \"The number 9 is odd\"\n#> [1] \"The number 10 is even\""},{"path":"module-3.html","id":"nested-for-loops","chapter":"Module 3","heading":"Nested For Loops","text":"Nested loops commonly needed multidimensional hierarchical data structures (e.g. matrices, lists). Nesting beyond 2 3 levels often makes difficult read/understand code. find need large number nested loops, may want break loops using functions (discussed next lecture). example nested loop:","code":"\n\n## Creating and populating an empty matrix\n\nmatrix1 <- matrix(ncol = 4, nrow = 5) # creating an empty matrix\n\n\nfor (i in 1:dim(matrix1)[1]){\n  \n  for (j in 1:dim(matrix1)[2]){\n    \n    matrix1[i, j] <- i*j\n    \n  }\n}\n\nprint(matrix1)\n#>      [,1] [,2] [,3] [,4]\n#> [1,]    1    2    3    4\n#> [2,]    2    4    6    8\n#> [3,]    3    6    9   12\n#> [4,]    4    8   12   16\n#> [5,]    5   10   15   20"},{"path":"module-3.html","id":"while-loops","chapter":"Module 3","heading":"While Loops","text":"loops begin testing condition. TRUE, execute loop body. loop body executed, condition tested , forth, condition FALSE, loop exits.","code":"\n\ni <- 1\n\nwhile (i < 10){\n  \n  print(i)\n  \n  i <- i + 1\n  \n}\n#> [1] 1\n#> [1] 2\n#> [1] 3\n#> [1] 4\n#> [1] 5\n#> [1] 6\n#> [1] 7\n#> [1] 8\n#> [1] 9"},{"path":"module-3.html","id":"while-loops-with-next-statements","chapter":"Module 3","heading":"While Loops with Next Statements","text":"loops can combined next statements:loops can potentially result infinite loops written properly. Use care! accidentally created executed infinite loops, run forever take storage R. stop infinite loop, press red stop sign shows top right corner console. Can check tell wrong loops given :","code":"\n\n# Printing odd numbers that are less than 15\n\ni <- 0\n\nwhile (i < 15){\n  \n  i <- i + 1\n  \n  if(i %% 2 == 0){\n    \n    next\n  }\n  \n  print(i)\n  \n}\n#> [1] 1\n#> [1] 3\n#> [1] 5\n#> [1] 7\n#> [1] 9\n#> [1] 11\n#> [1] 13\n#> [1] 15\n\ni <- 1\n\nwhile (i < 15){\n  \n  if(i %% 2 == 0){\n    \n    next\n  }\n\n  print(i)\n    \n  i <- i + 1\n  \n}\n\ni <- 1\n\nwhile (i < 15){\n  \n  print(i)\n  \n  if(i %% 2 == 0){\n    \n    next\n  }\n  \n  i <- i + 1\n  \n}\n\ni <- 1\n\nwhile (i < 15){\n  \n  print(i)\n  \n  i <- i + 1\n  \n  if(i %% 2 == 0){\n    \n    next\n  }\n  \n}"},{"path":"module-3.html","id":"while-loops-with-break-statements","chapter":"Module 3","heading":"While Loops with Break Statements","text":"Similarly, loops can combined break statements:Can tell output loops without running ?","code":"\n\ni <- 1\n\nwhile (i < 20){\n  \n  print (i)\n  \n  if (i == 5){\n    \n    break\n    \n  }\n  \n  i <- i + 1\n  \n  \n}\n#> [1] 1\n#> [1] 2\n#> [1] 3\n#> [1] 4\n#> [1] 5\n\ni <- 1\n\nwhile (i < 20){\n  \n  print (i)\n  \n  if (i == 5){\n    \n    break\n    \n  }\n  \n  i <- i + 1\n  \n  \n}\n#> [1] 1\n#> [1] 2\n#> [1] 3\n#> [1] 4\n#> [1] 5\n\ni <- 1\n\nwhile (i < 20){\n  \n  if (i == 5){\n    \n    break\n    \n  }\n  \n  print (i)\n  \n  i <- i + 1\n  \n}\n#> [1] 1\n#> [1] 2\n#> [1] 3\n#> [1] 4"},{"path":"module-4.html","id":"module-4","chapter":"Module 4","heading":"Module 4","text":" ","code":""},{"path":"module-4.html","id":"functions","chapter":"Module 4","heading":"Functions","text":"Now, ’s time discuss one essential concepts R programming, , R functions. Writing functions core activity R programmer. Functions often used encapsulate sequence expressions need executed numerous times, perhaps slightly different conditions. words, functions allow us automate common tasks powerful general way simply copy--pasting. also often written code must shared others public.consider writing function whenever ’ve copied pasted block code twice. module, learn create customized (user-defined) functions discuss essential tools R functions equipped .","code":""},{"path":"module-4.html","id":"creating-a-function","chapter":"Module 4","heading":"Creating a Function","text":"function set statements organized together perform specific task. R large number -built functions user can create functions. R, function object R interpreter able pass control function, along arguments may necessary function accomplish actions.R function created using function() function (Yeah, many functions). basic syntax R function follows:main components R function :Function Name - name function. stored R environment object name.Arguments - argument placeholder. function invoked, pass value argument. Arguments optional; , function may contain arguments. Also arguments can default values. example, arguments arg_1, arg_2 etc.Function Body − function body contains collection statements defines function .Return Value − return value function last expression function body evaluated.example simple function prints \"Hello class 2102!\":call function , use function name followed parenthesis:another example simple function:check collection statements function contains, use function name without parenthesis:","code":"\nfunction_name <- function(arg_1, arg_2, ...) {\n  \n   Function body \n}\n\nfirst_function <- function() { \n  \n  print(\"Hello class 2102!\")\n  \n}\n\nfirst_function()\n#> [1] \"Hello class 2102!\"\n\nnew_function <- function(){\n  \n  for(i in 1:5) {\n    \n    print(i^2)\n    \n  }\n  \n}\n\nnew_function()\n#> [1] 1\n#> [1] 4\n#> [1] 9\n#> [1] 16\n#> [1] 25\n\nnew_function\n#> function(){\n#>   \n#>   for(i in 1:5) {\n#>     \n#>     print(i^2)\n#>     \n#>   }\n#>   \n#> }\n#> <bytecode: 0x000001b51aaf4440>"},{"path":"module-4.html","id":"function-arguments","chapter":"Module 4","heading":"Function Arguments","text":"Information can passed functions arguments. Arguments specified function name, inside parentheses. can add many arguments want, just separate comma. example function single argument:Now let’s create function two arguments:","code":"\n\nfun_1 <- function(x){\n  \n  return(x^2)\n  \n}\n\nfun_1(x = 5)\n#> [1] 25\n\nfun_2 <- function(x, y){\n  \n  return(x - y)\n  \n}\n\nfun_2(x = 5, y = 7)\n#> [1] -2"},{"path":"module-4.html","id":"argument-matching","chapter":"Module 4","heading":"Argument Matching","text":"Calling R function arguments can done variety ways. may confusing first, ’s really handing interactive work command line. R functions arguments can matched name position.matched position, R assigns first value first argument, second value second argument . example, fun_2(5, 7) means R assign 5 x argument 7 y.Now try way around:specifying function arguments name, doesn’t matter order specify :","code":"\n\nfun_2(5, 7)\n#> [1] -2\n\nfun_2(7, 5)\n#> [1] 2\n\nfun_2(x = 5, y = 7)\n#> [1] -2\n\nfun_2(y = 7, x = 5)\n#> [1] -2"},{"path":"module-4.html","id":"number-of-arguments","chapter":"Module 4","heading":"Number of Arguments","text":"default, function must called correct number arguments. Meaning function expects 2 arguments, call function 2 arguments, , less. Try examples see get:","code":"\n\nfun_2(7)\n#> Error in fun_2(7): argument \"y\" is missing, with no default\n\nfun_2(7, 5, 3)\n#> Error in fun_2(7, 5, 3): unused argument (3)"},{"path":"module-4.html","id":"arguments-with-default-values","chapter":"Module 4","heading":"Arguments with Default Values","text":"can assign default values arguments function. call function without argument, uses default value:can still pass new values arguments default settings:R objects various data structures can passed function arguments. instance, pass vectors vec1 vec2 function fun_4:","code":"\n\nfun_3 <- function(x = 2, y){\n  \n  return (x - y)\n  \n}\n\nfun_3(y = 4)\n#> [1] -2\n\nfun_3(x = 10, y = 3)\n#> [1] 7\n\nvec1 <- c(1, 2, 3, 4, 5)\n\nvec2 <- 1:5\n\nfun_4 <- function(x, y){\n  \n  return(x + y)\n  \n}\n\nfun_4(x = vec1, y = vec2)\n#> [1]  2  4  6  8 10"},{"path":"module-4.html","id":"lazy-evaluation","chapter":"Module 4","heading":"Lazy Evaluation","text":"Arguments functions evaluated lazily, evaluated needed body function. example, function fun_5 two arguments, uses one (argument x).calling fun_5(x = 5) produce error, missing argument y used inside body function.omit argument x calling function fun_5, produce error, body function uses x argument produce output:","code":"\n\nfun_5 <- function(x, y){\n  \n  return(x + 2)\n}\n\nfun_5(x = 3)\n#> [1] 5\n\nfun_5(y = 3)\n#> Error in fun_5(y = 3): argument \"x\" is missing, with no default"},{"path":"module-4.html","id":"function-environments-and-global-variables","chapter":"Module 4","heading":"Function Environments and Global Variables","text":"R tries bind value symbol, searches series environments find appropriate value. environment collection (symbol, value) pairs, .e. x symbol 3.14 might value. class, consider two environments: Global Environment Functional Environment.global environment user’s workspace stores R objects create working R. contrast global environment, functional environment contains objects created inside function.call R function, first searches objects function’s environment global environment. instance, compare functions given . output case?another example given , variable b exists environment func_8 . , try print b object separately, R throw error, object exist global environment:Now, want create object inside function accessibly global environment well, use <<- operator:","code":"\n\na <- 5                        # this variable exists in the global environment\n\nfun_6 <- function(x){\n  \n  return(x + a)\n  \n}\n\n\nfun_6(x  = 2)\n#> [1] 7\n\na <- 5                        # this variable exists in the global environment\n\nfun_7 <- function(x){\n  \n  a <- 10                    # this variable exists in the environment of fun_7\n  \n  return(x + a)\n  \n}\n\n\nfun_7(x = 2)\n#> [1] 12\n\nfun_8 <- function(x){\n  \n  a <- 10                   # this variable exists in the environment of fun_8\n  \n  b <- 20                   # this variable exists in the environment of fun_8\n  \n  return(x + a + b)\n  \n}\n\nprint(b)\n#> Error in print(b): object 'b' not found\n\nfun_8 <- function(x){\n  \n  a <- 10                   # this variable exists in the environment of fun_8\n  \n  b <<- 20                   # this variable will exist in both global \n                             # and functional environments\n  \n  return(x + a + b)\n  \n}"},{"path":"module-4.html","id":"nested-function","chapter":"Module 4","heading":"Nested Function","text":"Like loops, can produce nested functions putting one function another. example nested function:","code":"\n\nfun_10 <- function(x, y){\n  \n  func_11 <- function(){\n    \n    return(x + y)\n    \n  }\n  \n  return(2*func_11())\n  \n}\n\nfun_10(2, 3)\n#> [1] 10"},{"path":"problem-set-1.html","id":"problem-set-1","chapter":"Problem Set 1","heading":"Problem Set 1","text":" ","code":""},{"path":"problem-set-1.html","id":"problem-1","chapter":"Problem Set 1","heading":"Problem 1","text":" Create vectors containing {3.1, 4.1, 5.1, 6.1, 7.1, 8.1} elements three different ways using following functions: c(), seq() argument, seq() length.argument. Name vector1, vector2, vector3, respectively. Add three new elements vector1: 10, 20, 30. 10 first element vector, 20 3rd element vector given 10 already added , 30 6th element vector given 10 20 already added vector. Create new vector containing {2, 3, 6, 10, 15, 18, 22, 25, 27, 30, 31, 35, 42} elements. Name vector4. Extract/Select elements greater 5 divisible 3 using logical statement create new vector vector5 elements. Check whether element 27 vector5 using logical operator. ","code":""},{"path":"problem-set-1.html","id":"problem-2","chapter":"Problem Set 1","heading":"Problem 2","text":" Create list following elements: [1, 50, 88], [“yesterday”, “today”, “tomorrow”], 22.5, [33.8, 42], “class_0001”. Name list1. Apply unlist() function list1. data type data structure output? think got specific data type? Create new list (name list2) removing third element first element list1. extract/select second third elements second element list2. Create new list following elements: 23, “new”, 45.7. Name list3. Now create new list (name list4) merging list2 list3 c(). many elements list4 contain (use built-function count). Extract first element list4 list vector. ","code":""},{"path":"problem-set-1.html","id":"problem-3","chapter":"Problem Set 1","heading":"Problem 3","text":" Create data frame (name df1) following variables:\nName - {“James”, “Linda”, “Stacy”, “Mary”, “Tom”, “Anna”, “Bob”, “Jeniffer”, “Lucas”, “Amy”, “Jim”}\nMajor - {“Math”, “Math”, “Genetics”, “Statistics”, “Accounting”, “Art”, “Music”, “Business”, “Finance”, “Finance”, “Math”}\nGrad_Year - {2023, 2025, 2025, 2024, 2026, 2024, 2025, 2025, 2023, 2026, 2024}\nGPA - {3.9, 3.75, 4.0, 4.0, 3.4, 3.9, 3.3, 3.8, 3.55, 4.0, 3.6}\nCreate data frame (name df1) following variables:Name - {“James”, “Linda”, “Stacy”, “Mary”, “Tom”, “Anna”, “Bob”, “Jeniffer”, “Lucas”, “Amy”, “Jim”}Major - {“Math”, “Math”, “Genetics”, “Statistics”, “Accounting”, “Art”, “Music”, “Business”, “Finance”, “Finance”, “Math”}Grad_Year - {2023, 2025, 2025, 2024, 2026, 2024, 2025, 2025, 2023, 2026, 2024}GPA - {3.9, 3.75, 4.0, 4.0, 3.4, 3.9, 3.3, 3.8, 3.55, 4.0, 3.6} created df1, capitalize column names. Get 6-number summary GPA column. data type GRAD_YEAR column? ? Convert correct data type. Display frequency elements. Use simple ifelse statement add new column NEXT_YEAR df1. boolean column, indicating TRUE student graduating next year (2024) FALSE (Check GRAD_YEAR column see year student plans graduate). Extract/Select students df1 majoring Math going graduate year (2023). ","code":""},{"path":"problem-set-1.html","id":"problem-4","chapter":"Problem Set 1","heading":"Problem 4","text":" Create matrix 5 columns filled columns following elements: 10, 3, 6, 23, -5, -4, 13, 17, 5, 6, -7, -10, 13, 39, 20, 2, 1, 9, 11, -22, 23, -15, -3, 6, 12. Name matrix1. Use loop replace elements matrix1 follows: element negative value, replace 0, element greater equal 10, replace 10, element greater equal 0 less 10, replace 5. Create empty vector vector6. Use loop populate vector6 follows: populate vector6 odd numbers greater 0 less 30 skipping odd numbers divisible 3. ","code":""},{"path":"problem-set-1.html","id":"problem-5","chapter":"Problem Set 1","heading":"Problem 5","text":" Create function (name fun1) take numeric vector input extract elements input vector greater 10. two ways: using loop combined conditional statement, without (using logical extraction operators). Test function following vector: [1, 4, 45, 23, 7, 9, 12, 15, 33] Create function (name fun2) take two matrices inputs (mat1 mat2) produce another matrix elements populated follows: element mat1 greater corresponding element mat2, corresponding element output matrix \"Greater \"; element mat1 less corresponding element mat2, corresponding element output matrix \"Less \"; element mat1 equal corresponding element mat2, corresponding element output matrix \"Equal \".\nexample, mat1[1, 1] = 10 mat2[1, 1] = 5, output matrix \"Greater \" element [1, 1] position. Test function following matrices: [1, 4, 9, 5, 2, 7, 4, 3, 10], 3 rows filled row; [2, 3, 10, 9, 1, 4, 4, 3, 9], 3 rows filled row.Create function (name fun2) take two matrices inputs (mat1 mat2) produce another matrix elements populated follows: element mat1 greater corresponding element mat2, corresponding element output matrix \"Greater \"; element mat1 less corresponding element mat2, corresponding element output matrix \"Less \"; element mat1 equal corresponding element mat2, corresponding element output matrix \"Equal \".example, mat1[1, 1] = 10 mat2[1, 1] = 5, output matrix \"Greater \" element [1, 1] position. Test function following matrices: [1, 4, 9, 5, 2, 7, 4, 3, 10], 3 rows filled row; [2, 3, 10, 9, 1, 4, 4, 3, 9], 3 rows filled row.","code":""},{"path":"ps-1-solutions.html","id":"ps-1-solutions","chapter":"PS 1 Solutions","heading":"PS 1 Solutions","text":" ","code":""},{"path":"ps-1-solutions.html","id":"problem-1-1","chapter":"PS 1 Solutions","heading":"Problem 1","text":" Create vectors containing {3.1, 4.1, 5.1, 6.1, 7.1, 8.1} elements three different ways using following functions: c(), seq() argument, seq() length.argument. Name vector1, vector2, vector3, respectively. Add three new elements vector1: 10, 20, 30. 10 first element vector, 20 3rd element vector given 10 already added , 30 6th element vector given 10 20 already added vector. Create new vector containing {2, 3, 6, 10, 15, 18, 22, 25, 27, 30, 31, 35, 42} elements. Name vector4. Extract/Select elements greater 5 divisible 3 using logical statement create new vector vector5 elements. Check whether element 27 vector5 using logical operator. ","code":"\nvector1 <- c(3.1, 4.1, 5.1, 6.1, 7.1, 8.1)\n\nprint(vector1)\n#> [1] 3.1 4.1 5.1 6.1 7.1 8.1\n\nvector2 <- seq(3.1, 8.1, by=1)\n\nprint(vector2)\n#> [1] 3.1 4.1 5.1 6.1 7.1 8.1\n\nvector3 <- seq(3.1, 8.1, length.out=6)\n\nprint(vector3)\n#> [1] 3.1 4.1 5.1 6.1 7.1 8.1\nvector1 <- append(vector1, 10, after=0)\n\nvector1 <- append(vector1, 20, after=2)\n\nvector1 <- append(vector1, 30, after=5)\n\nprint(vector1)\n#> [1] 10.0  3.1 20.0  4.1  5.1 30.0  6.1  7.1  8.1\nvector4 <- c(2, 3, 6, 10, 15, 18, 22, 25, 27, 30, 31, 35, 42)\n\nvector5 <- vector4[vector4>5 & vector4%%3==0]\n\nprint(vector5)\n#> [1]  6 15 18 27 30 42\n\n27 %in% vector5\n#> [1] TRUE"},{"path":"ps-1-solutions.html","id":"problem-2-1","chapter":"PS 1 Solutions","heading":"Problem 2","text":" Create list following elements: [1, 50, 88], [“yesterday”, “today”, “tomorrow”], 22.5, [33.8, 42], “class_0001”. Name list1. Apply unlist() function list1. data type data structure output? think got specific data type?unlisted list1 vector contains elements “character” type. unlist function returns vector “character” type list consists data different types, c(1, 50, 88) c(\"yesterday\", \"today\", \"tomorrow\"). Create new list (name list2) removing third element first element list1. extract/select second third elements second element list2. Create new list following elements: 23, “new”, 45.7. Name list3. Now create new list (name list4) merging list2 list3 c(). many elements list4 contain (use built-function count). Extract first element list4 list vector. ","code":"\nlist1 <- list(c(1, 50, 88), c(\"yesterday\", \"today\", \"tomorrow\"), 22.5, c(33.8, 42), \"class_0001\")\n\nprint(list1)\n#> [[1]]\n#> [1]  1 50 88\n#> \n#> [[2]]\n#> [1] \"yesterday\" \"today\"     \"tomorrow\" \n#> \n#> [[3]]\n#> [1] 22.5\n#> \n#> [[4]]\n#> [1] 33.8 42.0\n#> \n#> [[5]]\n#> [1] \"class_0001\"\nunlist(list1)\n#>  [1] \"1\"          \"50\"         \"88\"         \"yesterday\" \n#>  [5] \"today\"      \"tomorrow\"   \"22.5\"       \"33.8\"      \n#>  [9] \"42\"         \"class_0001\"\n\nclass(unlist(list1))\n#> [1] \"character\"\n\nstr(unlist(list1))\n#>  chr [1:10] \"1\" \"50\" \"88\" \"yesterday\" \"today\" ...\nlist2 <- list1\n\nlist2[[1]] <- list2[[1]][-3]\n\nprint(list2)\n#> [[1]]\n#> [1]  1 50\n#> \n#> [[2]]\n#> [1] \"yesterday\" \"today\"     \"tomorrow\" \n#> \n#> [[3]]\n#> [1] 22.5\n#> \n#> [[4]]\n#> [1] 33.8 42.0\n#> \n#> [[5]]\n#> [1] \"class_0001\"\n\nlist2[[2]][c(2,3)]\n#> [1] \"today\"    \"tomorrow\"\nlist3 <- list(23, \"new\", 45.7)\n\nprint(list3)\n#> [[1]]\n#> [1] 23\n#> \n#> [[2]]\n#> [1] \"new\"\n#> \n#> [[3]]\n#> [1] 45.7\n\n# merge\n\nlist4 <- c(list2, list3)\n\nprint(list4)\n#> [[1]]\n#> [1]  1 50\n#> \n#> [[2]]\n#> [1] \"yesterday\" \"today\"     \"tomorrow\" \n#> \n#> [[3]]\n#> [1] 22.5\n#> \n#> [[4]]\n#> [1] 33.8 42.0\n#> \n#> [[5]]\n#> [1] \"class_0001\"\n#> \n#> [[6]]\n#> [1] 23\n#> \n#> [[7]]\n#> [1] \"new\"\n#> \n#> [[8]]\n#> [1] 45.7\n\nlength(list4)\n#> [1] 8\n\n# Extract as a list\n\nlist(list4[[1]])\n#> [[1]]\n#> [1]  1 50\n\n# Extract as a vector\n\nlist4[[1]]\n#> [1]  1 50"},{"path":"ps-1-solutions.html","id":"problem-3-1","chapter":"PS 1 Solutions","heading":"Problem 3","text":" Create data frame (name df1) following variables:\nName - {“James”, “Linda”, “Stacy”, “Mary”, “Tom”, “Anna”, “Bob”, “Jeniffer”, “Lucas”, “Amy”, “Jim”}\nMajor - {“Math”, “Math”, “Genetics”, “Statistics”, “Accounting”, “Art”, “Music”, “Business”, “Finance”, “Finance”, “Math”}\nGrad_Year - {2023, 2025, 2025, 2024, 2026, 2024, 2025, 2025, 2023, 2026, 2024}\nGPA - {3.9, 3.75, 4.0, 4.0, 3.4, 3.9, 3.3, 3.8, 3.55, 4.0, 3.6}\nCreate data frame (name df1) following variables:Name - {“James”, “Linda”, “Stacy”, “Mary”, “Tom”, “Anna”, “Bob”, “Jeniffer”, “Lucas”, “Amy”, “Jim”}Major - {“Math”, “Math”, “Genetics”, “Statistics”, “Accounting”, “Art”, “Music”, “Business”, “Finance”, “Finance”, “Math”}Grad_Year - {2023, 2025, 2025, 2024, 2026, 2024, 2025, 2025, 2023, 2026, 2024}GPA - {3.9, 3.75, 4.0, 4.0, 3.4, 3.9, 3.3, 3.8, 3.55, 4.0, 3.6} created df1, capitalize column names. Get 6-number summary GPA column. data type GRAD_YEAR column? Convert correct data structure. Display frequency elements.GRAD_YEAR column factor type, since represents meaningful year number, simply numbers. Use simple ifelse statement add new column NEXT_YEAR df1. boolean column, indicating TRUE student graduating next year (2024) FALSE (Check GRAD_YEAR column see year student plans graduate). Extract/Select students df1 majoring Math going graduate year (2023). ","code":"\nName <- c(\"James\", \"Linda\", \"Stacy\", \"Mary\", \"Tom\", \"Anna\", \"Bob\", \"Jeniffer\", \"Lucas\", \"Amy\", \"Jim\")\n\nMajor <- c(\"Math\", \"Math\", \"Genetics\", \"Statistics\", \"Accounting\", \"Art\", \"Music\", \"Business\", \"Finance\", \"Finance\", \"Math\")\n\nGrad_Year <- c(2023, 2025, 2025, 2024, 2026, 2024, 2025, 2025, 2023, 2026, 2024)\n\nGPA <- c(3.9, 3.75, 4.0, 4.0, 3.4, 3.9, 3.3, 3.8, 3.55, 4.0, 3.6)\n\ndf1 <- data.frame(Name, Major, Grad_Year, GPA)\n\nprint(df1)\n#>        Name      Major Grad_Year  GPA\n#> 1     James       Math      2023 3.90\n#> 2     Linda       Math      2025 3.75\n#> 3     Stacy   Genetics      2025 4.00\n#> 4      Mary Statistics      2024 4.00\n#> 5       Tom Accounting      2026 3.40\n#> 6      Anna        Art      2024 3.90\n#> 7       Bob      Music      2025 3.30\n#> 8  Jeniffer   Business      2025 3.80\n#> 9     Lucas    Finance      2023 3.55\n#> 10      Amy    Finance      2026 4.00\n#> 11      Jim       Math      2024 3.60\ncolnames(df1) <- c(\"NAME\", \"MAJOR\", \"GRAD_YEAR\", \"GPA\")\n\nsummary(df1$GPA)\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#>   3.300   3.575   3.800   3.745   3.950   4.000\n\nclass(df1$GRAD_YEAR)\n#> [1] \"numeric\"\n\ndf1$GRAD_YEAR <- as.factor(df1$GRAD_YEAR)\n\nsummary(df1$GRAD_YEAR)\n#> 2023 2024 2025 2026 \n#>    2    3    4    2\ndf1$NEXT_YEAR <- ifelse(df1$GRAD_YEAR==2024, TRUE, FALSE)\n\nprint(df1)\n#>        NAME      MAJOR GRAD_YEAR  GPA NEXT_YEAR\n#> 1     James       Math      2023 3.90     FALSE\n#> 2     Linda       Math      2025 3.75     FALSE\n#> 3     Stacy   Genetics      2025 4.00     FALSE\n#> 4      Mary Statistics      2024 4.00      TRUE\n#> 5       Tom Accounting      2026 3.40     FALSE\n#> 6      Anna        Art      2024 3.90      TRUE\n#> 7       Bob      Music      2025 3.30     FALSE\n#> 8  Jeniffer   Business      2025 3.80     FALSE\n#> 9     Lucas    Finance      2023 3.55     FALSE\n#> 10      Amy    Finance      2026 4.00     FALSE\n#> 11      Jim       Math      2024 3.60      TRUE\ndf1[df1$MAJOR==\"Math\" & df1$GRAD_YEAR!=\"2023\", ]\n#>     NAME MAJOR GRAD_YEAR  GPA NEXT_YEAR\n#> 2  Linda  Math      2025 3.75     FALSE\n#> 11   Jim  Math      2024 3.60      TRUE"},{"path":"ps-1-solutions.html","id":"problem-4-1","chapter":"PS 1 Solutions","heading":"Problem 4","text":" Create matrix 5 columns filled columns following elements: 10, 3, 6, 23, -5, -4, 13, 17, 5, 6, -7, -10, 13, 39, 20, 2, 1, 9, 11, -22, 23, -15, -3, 6, 12. Name matrix1. Use loop replace elements matrix1 follows: element negative value, replace 0, element greater equal 10, replace 10, element greater equal 0 less 10, replace 5. Create empty vector vector6. Use loop populate vector6 follows: populate vector6 odd numbers greater 0 less 30 skipping odd numbers divisible 3. ","code":"\nmatrix1 <- matrix(c(10, 3, 6, 23, -5, -4, 13, 17, 5, 6, -7, -10, 13, 39, 20, 2, 1, 9, 11, -22, 23, -15, -3, 6, 12), ncol=5)\n\nprint(matrix1)\n#>      [,1] [,2] [,3] [,4] [,5]\n#> [1,]   10   -4   -7    2   23\n#> [2,]    3   13  -10    1  -15\n#> [3,]    6   17   13    9   -3\n#> [4,]   23    5   39   11    6\n#> [5,]   -5    6   20  -22   12\nfor (i in 1:dim(matrix1)[1]) {\n  \n  for (j in 1:dim(matrix1)[2]) {\n    \n    if (matrix1[i,j] < 0) {\n      \n      matrix1[i, j] = 0\n      \n    }\n    \n    else if (matrix1[i,j] >= 10) {\n      \n      matrix1[i,j] = 10\n      \n    }\n    \n    else {\n      \n      matrix1[i,j] = 5\n    }\n  }\n}\n\nprint(matrix1)\n#>      [,1] [,2] [,3] [,4] [,5]\n#> [1,]   10    0    0    5   10\n#> [2,]    5   10    0    5    0\n#> [3,]    5   10   10    5    0\n#> [4,]   10    5   10   10    5\n#> [5,]    0    5   10    0   10\nvector6 <- c()\n\ni <- 0\n\nwhile (i < 30) {\n  \n  i <- i + 1\n  \n  if (i%%2==0 || i%%3==0) {\n    \n    next\n    \n  }\n  \n  vector6 <- c(vector6, i)\n  \n}\n\nprint(vector6)\n#>  [1]  1  5  7 11 13 17 19 23 25 29"},{"path":"ps-1-solutions.html","id":"problem-5-1","chapter":"PS 1 Solutions","heading":"Problem 5","text":" Create function (name fun1) take numeric vector input extract elements input vector greater 10. two ways: using loop combined conditional statement, without (using logical extraction operators). Test function following vector: [1, 4, 45, 23, 7, 9, 12, 15, 33] Create function (name fun2) take two matrices inputs (mat1 mat2) produce another matrix elements populated follows: element mat1 greater corresponding element mat2, corresponding element output matrix \"Greater \"; element mat1 less corresponding element mat2, corresponding element output matrix \"Less \"; element mat1 equal corresponding element mat2, corresponding element output matrix \"Equal \".\nexample, mat1[1, 1] = 10 mat2[1, 1] = 5, output matrix \"Greater \" element [1, 1] position. Test function following matrices: [1, 4, 9, 5, 2, 7, 4, 3, 10], 3 rows filled row; [2, 3, 10, 9, 1, 4, 4, 3, 9], 3 rows filled row.Create function (name fun2) take two matrices inputs (mat1 mat2) produce another matrix elements populated follows: element mat1 greater corresponding element mat2, corresponding element output matrix \"Greater \"; element mat1 less corresponding element mat2, corresponding element output matrix \"Less \"; element mat1 equal corresponding element mat2, corresponding element output matrix \"Equal \".example, mat1[1, 1] = 10 mat2[1, 1] = 5, output matrix \"Greater \" element [1, 1] position. Test function following matrices: [1, 4, 9, 5, 2, 7, 4, 3, 10], 3 rows filled row; [2, 3, 10, 9, 1, 4, 4, 3, 9], 3 rows filled row.","code":"\nvector <- c(1, 4, 45, 23, 7, 9, 12, 15, 33)\n\nfun1 <- function(vec) {\n  \n  result <- c()\n  \n  for (i in 1:length(vec)) {\n    \n    if (vec[i] > 10) {\n      \n      result <- c(result, vec[i])\n      \n    }\n  }\n  \n  return(result)\n}\n\nfun1(vector)\n#> [1] 45 23 12 15 33\n\nfun1 <- function(vec) {\n  \n  return(vec[vec>10])\n  \n}\n\nfun1(vector)\n#> [1] 45 23 12 15 33\nmat1 <- matrix(c(1, 4, 9, 5, 2, 7, 4, 3, 10), nrow=3, byrow=TRUE)\n\nmat2 <- matrix(c(2, 3, 10, 9, 1, 4, 4, 3, 9), nrow=3, byrow=TRUE)\n\nfun2 <- function(mat1, mat2) {\n  \n  mat3 <- matrix(nrow=dim(mat1)[1], ncol=dim(mat1)[2])\n  \n  for (i in 1:dim(mat1)[1]) {\n    \n    for (j in 1:dim(mat1)[2]) {\n      \n      if (mat1[i,j]>mat2[i,j]) {\n        \n        mat3[i,j] <- \"Greater than\"\n        \n      }\n      \n      else if (mat1[i,j]<mat2[i,j]) {\n        \n        mat3[i,j] <- \"Less than\"\n      }\n      \n      else {\n        \n        mat3[i,j] <- \"Equal to\"\n      }\n    }\n  }\n  \n  return(mat3)\n}\n\nfun2(mat1, mat2)\n#>      [,1]        [,2]           [,3]          \n#> [1,] \"Less than\" \"Greater than\" \"Less than\"   \n#> [2,] \"Less than\" \"Greater than\" \"Greater than\"\n#> [3,] \"Equal to\"  \"Equal to\"     \"Greater than\""},{"path":"module-5.html","id":"module-5","chapter":"Module 5","heading":"Module 5","text":" ","code":""},{"path":"module-5.html","id":"functional-programming-importingexporting-data","chapter":"Module 5","heading":"Functional Programming & Importing/Exporting Data","text":"","code":""},{"path":"module-5.html","id":"importingexporting-data-intofrom-r","chapter":"Module 5","heading":"Importing/Exporting Data into/from R","text":"","code":""},{"path":"module-5.html","id":"importing-data-into-r","chapter":"Module 5","heading":"Importing Data into R","text":"Working small examples given previous modules good way learn basic functionalities R, point want stop learning start working data. module, learn import data (reading data) R save data (writing data) computer done .R, can read data files stored outside R environment. can also write data files stored accessed operating system. R can read write various file formats like csv, excel, txt etc. working mostly tabular data (data given rows columns). many function can use import data R, consider following two functions: read.table() read.csv().","code":""},{"path":"module-5.html","id":"read.table","chapter":"Module 5","heading":"read.table()","text":"One commonly used functions importing data R read.table() function (discuss alternatives later class). read.table() function flexible function shed load arguments, ’s quite simple use. read.table() function important arguments:file - name file, connectionheader - logical indicating file header line (used specify column names data frame)sep - string indicating columns separated (example, \"\", \",\", \"\\t\", \"/\")stringAsFactors - logical indicating whether character variables coded factors.Now let’s import data set lung_capacity.txt available Courseworks (download computer). order import data R, need following information: path file (location computer, note: code shows direct path windows system; slightly different Mac users), whether column names (data column names, pass TRUE header argument, header = TRUE), column separation method (columns data created separating white space, use sep = \"\"):Now data imported R available global environment. view , use View() function:data stored working directory, can simply pass name file without specifying exact path . see working directory located, use getwd() function:want change location working directory, passing path location setwd() function:Now working directory desktop. file stored desktop can imported R passing just name read.table() function:","code":"\n\ndata1 <- read.table(file = \"C:/Users/alexp/OneDrive/Desktop/R Bootcamp/R_bootcamp/lung_capacity.txt\", header = T, sep = \"\")\n\nView(data1)\n\ngetwd()\n#> [1] \"C:/Users/alexp/OneDrive/Desktop/R Bootcamp/R_bootcamp\"\n\nsetwd(\"C:/Users/alexp/OneDrive/Desktop/R Bootcamp/R_bootcamp\")\n\ndata1 <- read.table(file = \"lung_capacity.txt\", header = T, sep = \"\")"},{"path":"module-5.html","id":"read.csv","chapter":"Module 5","heading":"read.csv()","text":"file trying import R can comma-delimited (columns separated comma). Normally, files .csv file extensions. common file extension statisticians use frequently, R separate function allows import files. function called read.csv():can see, longer required specify sep argument R already knows comma-delimited file. Thus, two ways importing .csv files R: 1) using read.table() function sep = \",\" 2) using read.csv() function directly.method choose.","code":"\n\ndata2 <- read.csv(file = \"C:/Users/alexp/OneDrive/Desktop/R Bootcamp/R_bootcamp/lung_capacity_2.csv\", header = T)"},{"path":"module-5.html","id":"exporting-data-from-r","chapter":"Module 5","heading":"Exporting Data from R","text":"","code":""},{"path":"module-5.html","id":"write.table","chapter":"Module 5","heading":"write.table()","text":"manipulating data R (example, adding removing columns/row, modifying existing columns, ), might want save modified data computer. can using write.table() function, following arguments:x - name object trying savefile - name extension file data stored computercol.names - logical indicating file contain column names (almost always want assign TRUE argument)row.names - logical indicating file contain row index (almost always want assign FALSE argument)sep - string indicating columns separated (example, \"\", \",\", \"\\t\", \"/\")instance, let’s save data2 data set computer new_data name:","code":"\n\nwrite.table(data2, file = \"new_data.csv\", col.names = TRUE, row.names = FALSE, sep = \",\")"},{"path":"module-5.html","id":"write.csv","chapter":"Module 5","heading":"write.csv()","text":"Like read.csv() function, can use write.csv() function save data csv extension (comma-delimited file):Now, don’t need specify sep argument R already knows type file create. ","code":"\n\nwrite.csv(data2, file = \"new_data_2.csv\", row.names = FALSE)"},{"path":"module-5.html","id":"basic-statistics-built-in-functions","chapter":"Module 5","heading":"Basic Statistics Built-in Functions","text":"R built-functions large number summary statistics. module, consider summary statistics numerical/quantitative variables. Let’s use Age variable data1 data set ’ve already imported R.","code":""},{"path":"module-5.html","id":"summary","chapter":"Module 5","heading":"Summary","text":"summary() function provides basic summary statistics numerical data:","code":"\n\nsummary(data1$Age)\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#>    3.00    9.00   13.00   12.33   15.00   19.00"},{"path":"module-5.html","id":"central-tendency","chapter":"Module 5","heading":"Central Tendency","text":"","code":""},{"path":"module-5.html","id":"mean","chapter":"Module 5","heading":"Mean","text":"name suggests, mean() function computes mean value numeric variable:Type ?mean() console see arguments mean() function .","code":"\n\nmean(data1$Age)\n#> [1] 12.3269"},{"path":"module-5.html","id":"median","chapter":"Module 5","heading":"Median","text":"median() function computes median numerical variable:","code":"\n\nmedian(data1$Age)\n#> [1] 13"},{"path":"module-5.html","id":"spread","chapter":"Module 5","heading":"Spread","text":"","code":""},{"path":"module-5.html","id":"variance","chapter":"Module 5","heading":"Variance","text":"var() function computes variance numerical variable:","code":"\n\nvar(data1$Age)\n#> [1] 16.03802"},{"path":"module-5.html","id":"standard-deviation","chapter":"Module 5","heading":"Standard Deviation","text":"sd() function computes standard deviation numerical variable:Another way computing standard deviation taking square root variance:","code":"\n\nsd(data1$Age)\n#> [1] 4.00475\n\nsqrt(var(data1$Age))\n#> [1] 4.00475"},{"path":"module-5.html","id":"quantiles","chapter":"Module 5","heading":"Quantiles","text":"can use quantile() function calculate quantiles (.k.quartiles, .k.percentiles) numerical variable. default, gives basic quantiles:can make quantile() function compute specific quantiles. examples, let’s compute 0.30 0.80 quantiles (, 30-th 80-th percentiles):","code":"\n\nquantile(data1$Age)\n#>   0%  25%  50%  75% 100% \n#>    3    9   13   15   19\n\nquantile(data1$Age, c(0.3, 0.8))\n#> 30% 80% \n#>  10  16"},{"path":"module-5.html","id":"inverse-quantiles","chapter":"Module 5","heading":"Inverse Quantiles","text":"Suppose given observation x data, want know corresponding quantile. , want know fraction data less x. example, let’s find corresponding quantile 11 Age variable:expression data1$Age < 11 compares every element Age variable 11 returns vector logical values, n-th logical value TRUE data1$Age[n] < 11. mean function converts logical values 0 1: 0 FALSE 1 TRUE. average 1s 0s fraction Age variable less 11, inverse quantile 11.","code":"\n\nmean(data1$Age < 11)\n#> [1] 0.3213793"},{"path":"module-5.html","id":"iqr-inter-quartile-range","chapter":"Module 5","heading":"IQR (Inter-Quartile Range)","text":"IQR difference Q3 (third quartile, 75-th percentile) Q1 (first quartile, 25-th percentile):Another way computing IQR using quantile() functions:","code":"\n\nIQR(data1$Age)\n#> [1] 6\n\nquantile(data1$Age, 0.75) - quantile(data1$Age, 0.25)\n#> 75% \n#>   6"},{"path":"module-5.html","id":"minimum","chapter":"Module 5","heading":"Minimum","text":"min() function calculates minimum value numerical variable:","code":"\n\nmin(data1$Age)\n#> [1] 3"},{"path":"module-5.html","id":"which.min","chapter":"Module 5","heading":"which.min()","text":"can use .min() function find index position minimum value variable:","code":"\n\nwhich.min(data1$Age)\n#> [1] 114"},{"path":"module-5.html","id":"maximum","chapter":"Module 5","heading":"Maximum","text":"max() function calculates maximum value numerical variable:","code":"\n\nmax(data1$Age)\n#> [1] 19"},{"path":"module-5.html","id":"which.max","chapter":"Module 5","heading":"which.max()","text":"can use .max() function find index position maximum value variable:","code":"\n\nwhich.max(data1$Age)\n#> [1] 11"},{"path":"module-5.html","id":"range","chapter":"Module 5","heading":"Range","text":"Another way calculating maximum minimum numerical variable using range() function.definition, range difference maximum minimum values numerical variable. compute quantity, can utilize max() min() functions:","code":"\n\nrange(data1$Age)\n#> [1]  3 19\n\nmax(data1$Age) - min(data1$Age)\n#> [1] 16"},{"path":"module-5.html","id":"summation","chapter":"Module 5","heading":"Summation","text":"sum() function adds elements numerical variable:Let’s use sum() length() functions compute mean value:","code":"\n\nsum(data1$Age)\n#> [1] 8937\n\nsum(data1$Age)/length(data1$Age)\n#> [1] 12.3269"},{"path":"module-5.html","id":"cumulative-summation","chapter":"Module 5","heading":"Cumulative Summation","text":"cumsum() function produces vector containing cumulative sum input vector (, adds values sequentially displaying results addition). simplicity, let’s use following vector:cumulative summation vector x : ","code":"\n\nx <- c(2, 4, 3, 5, 10)\n\nprint(x)\n#> [1]  2  4  3  5 10\n\ncumsum(x)\n#> [1]  2  6  9 14 24"},{"path":"module-5.html","id":"functional-programming-apply-family-of-functions","chapter":"Module 5","heading":"Functional Programming: apply() Family of Functions","text":"Writing loops useful programming particularly easy working interactively command line. Multi-line expressions curly braces just easy sort working command line.Moreover, loops bad reputation R many people believe slow, real downside loops ’re flexible: loop conveys ’re iterating, done results.Fortunately, R built-functions overcome aforementioned challenges. implement looping compact form make life easier. module, consider several functions can combined family function called apply() family function.apply() functions use functional programming, implies using functions arguments functions (yeah, many functions). Let’s start basic ones:","code":""},{"path":"module-5.html","id":"apply-function","chapter":"Module 5","heading":"apply() Function","text":"apply() function enables applying function rows columns matrix data frame. Depending function specify using apply function, get back either vector matrix. general structure apply() function follows:X - object pass function (either matrix data frame)MARGIN - argument uses values 1 2, 1 rows 2 columns.FUN - function command want apply either rows columns... - can add additional instructions appropriate command/function applyingFor example, let’s create matrix 5x4 dimensions:Now, suppose want calculate mean value column matrix. can using apply() function:can thing row-wise:can even pass user-defined function. example, first let’s create function calculates range:Now, let’s apply function columns matrix1:","code":"\n\napply(X, MARGIN, FUN, ...)\n\nmatrix1 <- matrix(1:20, nrow = 5, byrow = T)\n\nprint(matrix1)\n#>      [,1] [,2] [,3] [,4]\n#> [1,]    1    2    3    4\n#> [2,]    5    6    7    8\n#> [3,]    9   10   11   12\n#> [4,]   13   14   15   16\n#> [5,]   17   18   19   20\n\napply(matrix1, 2, mean)\n#> [1]  9 10 11 12\n\napply(matrix1, 1, mean)\n#> [1]  2.5  6.5 10.5 14.5 18.5\n\nfunction_1 <- function(x){\n  \n  range <- max(x) - min(x)\n  \n  return(range)\n}\n\napply(matrix1, 2, function_1)\n#> [1] 16 16 16 16"},{"path":"module-5.html","id":"lapply-function","chapter":"Module 5","heading":"lapply() Function","text":"use apply() function lists, throw error. Suppose list:now want calculate length element list1. use apply() function, cause error:Instead use lapply() function:","code":"\n\nlist1 <- list(c(1, 4, 10), 24, 1:5)\n\nprint(list1)\n#> [[1]]\n#> [1]  1  4 10\n#> \n#> [[2]]\n#> [1] 24\n#> \n#> [[3]]\n#> [1] 1 2 3 4 5\n\napply(list1, 2, length)\n#> Error in apply(list1, 2, length): dim(X) must have a positive length\n\nlapply(list1, length)\n#> [[1]]\n#> [1] 3\n#> \n#> [[2]]\n#> [1] 1\n#> \n#> [[3]]\n#> [1] 5"},{"path":"module-5.html","id":"sapply-function","chapter":"Module 5","heading":"sapply() Function","text":"noticed, previous command returned list. want output vector, use sapply() function:","code":"\n\nsapply(list1, length)\n#> [1] 3 1 5"},{"path":"module-5.html","id":"mapply-function","chapter":"Module 5","heading":"mapply() Function","text":"mapply() function multivariate apply() function applies function parallel set arguments. used iterate multiple R objects parallel. mapply() function different argument order lapply() function apply comes first rather object iterate . example, want create following list:Instead, can use mapply() function follows: ’ve learned utilize apply family functions implements looping matrix, data frame, list compact form. want apply function subsets vector? want split vector subsets, compute summary statistics subset return result group form?’s trying , find tapply() aggregate() functions useful. come handy start analyzing data. Now, let’s see functions work. using data set (Lung Capacity data set).","code":"\n\nlist(rep(1, 4), rep(2, 3), rep(3, 2), rep(4, 1))\n#> [[1]]\n#> [1] 1 1 1 1\n#> \n#> [[2]]\n#> [1] 2 2 2\n#> \n#> [[3]]\n#> [1] 3 3\n#> \n#> [[4]]\n#> [1] 4\n\nmapply(rep, 1:4, 4:1)\n#> [[1]]\n#> [1] 1 1 1 1\n#> \n#> [[2]]\n#> [1] 2 2 2\n#> \n#> [[3]]\n#> [1] 3 3\n#> \n#> [[4]]\n#> [1] 4"},{"path":"module-5.html","id":"tapply-function","chapter":"Module 5","heading":"tapply() Function","text":"tapply() function another member apply family functions. tapply() used apply function subsets vector. allows create group summaries based factor levels another variables. arguments tapply() function follows:X - input vectorINDEX - factor variable (list factor variables)FUN - function applied... - argumentsNow, suppose want calculate mean value Age male female patients separately. can passing Age Sex variables along mean function tappy():can pass user-defined function well. First, let’s create function_1 returns mean median values vector:Now, let’s pass tapply() function:can even complex scenarios two factor variables. case, factor variables put list:","code":"\n\ntapply(X, INDEX, FUN, ...)\n\ntapply(data1$Age, data1$Sex, mean)\n#>   FEMALE     MALE \n#> 12.44972 12.20708\n\nfunction_1 <- function(x){\n  \n  return(c(Mean = mean(x), Median = median(x)))\n  \n}\n\ntapply(data1$Age, data1$Sex, function_1)\n#> $FEMALE\n#>     Mean   Median \n#> 12.44972 13.00000 \n#> \n#> $MALE\n#>     Mean   Median \n#> 12.20708 12.00000\n\ntapply(data1$Age, list(data1$Sex, data1$Smoke), mean)\n#>              NO      YES\n#> FEMALE 12.12739 14.75000\n#> MALE   11.94910 14.81818\n\ntapply(data1$Age, list(data1$Sex, data1$Smoke, data1$Status), mean)\n#> , , HEALTHY\n#> \n#>              NO      YES\n#> FEMALE 11.89326 15.00000\n#> MALE   12.13408 14.69231\n#> \n#> , , STAGE_1\n#> \n#>              NO      YES\n#> FEMALE 12.23529 13.87500\n#> MALE   11.69231 15.33333\n#> \n#> , , STAGE_2\n#> \n#>              NO YES\n#> FEMALE 12.54545  14\n#> MALE   11.72093  NA\n#> \n#> , , STAGE_3\n#> \n#>              NO      YES\n#> FEMALE 13.16667 15.33333\n#> MALE   11.95238 15.00000"},{"path":"module-5.html","id":"aggregate-function","chapter":"Module 5","heading":"aggregate() Function","text":"Another way splitting vectors subsets computing summary statistics subset using aggregate() function. useful performing aggregate operations like sum, count, mean, median, . arguments aggregate() function follows:X - input objectby - list grouping elements, subsets grouped byFUN - function applied... - argumentsHere examples:","code":"\n\naggregate(X, by, FUN, ...)\n\naggregate(data1$LungCap, list(data1$Smoke), median)\n#>   Group.1    x\n#> 1      NO 7.90\n#> 2     YES 8.65\n\naggregate(data1$LungCap, list(data1$Smoke, data1$Sex), median)\n#>   Group.1 Group.2      x\n#> 1      NO  FEMALE 7.6000\n#> 2     YES  FEMALE 8.1625\n#> 3      NO    MALE 8.2125\n#> 4     YES    MALE 9.3500\n\naggregate(data1$LungCap, list(data1$Smoke, data1$Sex, data1$Status), median)\n#>    Group.1 Group.2 Group.3       x\n#> 1       NO  FEMALE HEALTHY  7.4375\n#> 2      YES  FEMALE HEALTHY  8.2375\n#> 3       NO    MALE HEALTHY  8.2000\n#> 4      YES    MALE HEALTHY  9.0750\n#> 5       NO  FEMALE STAGE_1  7.7500\n#> 6      YES  FEMALE STAGE_1  7.8375\n#> 7       NO    MALE STAGE_1  8.0750\n#> 8      YES    MALE STAGE_1 10.1000\n#> 9       NO  FEMALE STAGE_2  8.2750\n#> 10     YES  FEMALE STAGE_2  7.9500\n#> 11      NO    MALE STAGE_2  8.3500\n#> 12      NO  FEMALE STAGE_3  7.7250\n#> 13     YES  FEMALE STAGE_3  8.1250\n#> 14      NO    MALE STAGE_3  7.8250\n#> 15     YES    MALE STAGE_3  9.8750\n\naggregate(data1$LungCap, list(data1$Smoke, data1$Sex, data1$Status), function_1)\n#>    Group.1 Group.2 Group.3    x.Mean  x.Median\n#> 1       NO  FEMALE HEALTHY  7.212258  7.437500\n#> 2      YES  FEMALE HEALTHY  8.341667  8.237500\n#> 3       NO    MALE HEALTHY  8.385335  8.200000\n#> 4      YES    MALE HEALTHY  9.144231  9.075000\n#> 5       NO  FEMALE STAGE_1  7.208529  7.750000\n#> 6      YES  FEMALE STAGE_1  7.575000  7.837500\n#> 7       NO    MALE STAGE_1  8.153297  8.075000\n#> 8      YES    MALE STAGE_1  9.875000 10.100000\n#> 9       NO  FEMALE STAGE_2  7.681061  8.275000\n#> 10     YES  FEMALE STAGE_2  7.716667  7.950000\n#> 11      NO    MALE STAGE_2  7.811047  8.350000\n#> 12      NO  FEMALE STAGE_3  7.913889  7.725000\n#> 13     YES  FEMALE STAGE_3  8.275000  8.125000\n#> 14      NO    MALE STAGE_3  7.802381  7.825000\n#> 15     YES    MALE STAGE_3  9.875000  9.875000\n\naggregate(data1[ ,c(\"Age\", \"LungCap\")], list(data1$Smoke), median)\n#>   Group.1 Age LungCap\n#> 1      NO  12    7.90\n#> 2     YES  15    8.65"},{"path":"module-6.html","id":"module-6","chapter":"Module 6","heading":"Module 6","text":" ","code":""},{"path":"module-6.html","id":"tidyverse-family-of-packages","chapter":"Module 6","heading":"Tidyverse Family of Packages","text":"data frame key data structure statistics R. basic structure data frame one observation per row column represents variable, measure, feature, characteristic observation. can conduct analyses draw conclusions, often need reorganize data. Tidyverse collection R packages (developed RStudio’s chief scientist Hadley Wickham) provides efficient, fast, well-documented workflow general data modeling, wrangling, visualization tasks.Tidyverse introduces set useful data analysis packages help streamline work R. particular, Tidyverse designed address top three common issues arise dealing data analysis base R: (1) Results obtained base R function often depend type data used; (2) R expressions used non-standard way, can confuse beginners; (3) Hidden arguments often various default operations beginners unaware .core Tidyverse includes packages ’re likely use everyday data analyses.ggplot2 - ggplot2 system declaratively creating graphics, based Grammar Graphics. provide data, tell ggplot2 map variables aesthetics, graphical primitives use, takes care details.ggplot2 - ggplot2 system declaratively creating graphics, based Grammar Graphics. provide data, tell ggplot2 map variables aesthetics, graphical primitives use, takes care details.dplyr - dplyr provides grammar data manipulation, providing consistent set verbs solve common data manipulation challenges.dplyr - dplyr provides grammar data manipulation, providing consistent set verbs solve common data manipulation challenges.tidyr - tidyr provides set functions help get tidy data. Tidy data data consistent form: brief, every variable goes column, every column variable.tidyr - tidyr provides set functions help get tidy data. Tidy data data consistent form: brief, every variable goes column, every column variable.readr - readr provides fast friendly way read rectangular data (like csv, tsv, fwf). designed flexibly parse many types data found wild, still cleanly failing data unexpectedly changes.readr - readr provides fast friendly way read rectangular data (like csv, tsv, fwf). designed flexibly parse many types data found wild, still cleanly failing data unexpectedly changes.purrr - purrr enhances R’s functional programming (FP) toolkit providing complete consistent set tools working functions vectors. master basic concepts, purrr allows replace many loops code easier write expressive.purrr - purrr enhances R’s functional programming (FP) toolkit providing complete consistent set tools working functions vectors. master basic concepts, purrr allows replace many loops code easier write expressive.tibble - tibble modern re-imagining data frame, keeping time proven effective, throwing . Tibbles data.frames lazy surly: less complain forcing confront problems earlier, typically leading cleaner, expressive code.tibble - tibble modern re-imagining data frame, keeping time proven effective, throwing . Tibbles data.frames lazy surly: less complain forcing confront problems earlier, typically leading cleaner, expressive code.stringr - stringr provides cohesive set functions designed make working strings easy possible. built top stringi, uses ICU C library provide fast, correct implementations common string manipulations.stringr - stringr provides cohesive set functions designed make working strings easy possible. built top stringi, uses ICU C library provide fast, correct implementations common string manipulations.forcats - forcats provides suite useful tools solve common problems factors. R uses factors handle categorical variables, variables fixed known set possible values.forcats - forcats provides suite useful tools solve common problems factors. R uses factors handle categorical variables, variables fixed known set possible values.Tidyverse also includes many packages specialized usage. loaded automatically Tidyverse, ’ll need load one call.install Tidyverse packages run following code console:Now Tidyverse available R, activated yet. Whenever start new R session plan use Tidyverse packages, need activate package calling library(tidyverse) function console:start learning Tidyverse family packages introducing dplyr package.working nyc_flights data set provides information flights departed New York City 2013 (data set available Courseworks). contains 336 776 observations (rows) 19 variables (columns). Let’s import data set R:Let’s convert data frame tibble data frame (don’t worry function; use module just better representation results): ","code":"\n\ninstall.packages(\"tidyverse\")\n\nlibrary(tidyverse)\n#> ── Attaching packages ─────────────────── tidyverse 1.3.2 ──\n#> ✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n#> ✔ tibble  3.1.8      ✔ dplyr   1.0.10\n#> ✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n#> ✔ readr   2.1.3      ✔ forcats 0.5.2 \n#> ── Conflicts ────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n\nflights <- read.csv(file = \"C:/Users/alexp/OneDrive/Desktop/R Bootcamp/R_bootcamp/nyc_flights.csv\", header = T)\n\nflights <- as_tibble(flights)"},{"path":"module-6.html","id":"dplyr-package","chapter":"Module 6","heading":"dplyr Package","text":"mentioned earlier, dplyr provides grammar data manipulation, providing consistent set verbs solve common data manipulation challenges selecting important variables, filtering key observations, creating new variables, computing summaries, .module going learn key dplyr functions allow solve vast majority data manipulation challenges. functions discuss common characteristics. particular,first argument data frameThe first argument data frameThe subsequent arguments describe data frame specified first argument, can refer columns data frame directly without using $ operator (just use column names)subsequent arguments describe data frame specified first argument, can refer columns data frame directly without using $ operator (just use column names)return result function new data frameThe return result function new data framedplyr aims provide function basic verb data manipulation. verbs can organised three categories based component data set work :Rows:\nfilter() - chooses rows based column values\nslice() - chooses rows based location\narrange() - changes order rows\nRows:filter() - chooses rows based column valuesslice() - chooses rows based locationarrange() - changes order rowsColumns:\nselect() - changes whether column included\nrename() - changes name columns\nmutate() - changes values columns creates new columns\nrelocate() - changes order columns\nColumns:select() - changes whether column includedrename() - changes name columnsmutate() - changes values columns creates new columnsrelocate() - changes order columnsGroups rows:\ngroup_by() - changes scope function operating entire data set operating group--group\nsummarize() - collapses group single row\nGroups rows:group_by() - changes scope function operating entire data set operating group--groupsummarize() - collapses group single row","code":""},{"path":"module-6.html","id":"filter-function","chapter":"Module 6","heading":"filter() Function","text":"filter() allows subset observations based values. first argument name data frame, second subsequent arguments expressions filter data frame. instance, let’s select flights January 1st:run line code, dplyr executes filtering operation returns new data frame. dplyr functions never modify inputs, want save result, ’ll need use assignment operator, <- :Let’s find flights departed November December:operation using %% operator:","code":"\n\nfilter(flights, month == 1, day == 1)\n#> # A tibble: 842 × 19\n#>     year month   day dep_t…¹ sched…² dep_d…³ arr_t…⁴ sched…⁵\n#>    <int> <int> <int>   <int>   <int>   <int>   <int>   <int>\n#>  1  2013     1     1     517     515       2     830     819\n#>  2  2013     1     1     533     529       4     850     830\n#>  3  2013     1     1     542     540       2     923     850\n#>  4  2013     1     1     544     545      -1    1004    1022\n#>  5  2013     1     1     554     600      -6     812     837\n#>  6  2013     1     1     554     558      -4     740     728\n#>  7  2013     1     1     555     600      -5     913     854\n#>  8  2013     1     1     557     600      -3     709     723\n#>  9  2013     1     1     557     600      -3     838     846\n#> 10  2013     1     1     558     600      -2     753     745\n#> # … with 832 more rows, 11 more variables: arr_delay <int>,\n#> #   carrier <chr>, flight <int>, tailnum <chr>,\n#> #   origin <chr>, dest <chr>, air_time <int>,\n#> #   distance <int>, hour <int>, minute <int>,\n#> #   time_hour <chr>, and abbreviated variable names\n#> #   ¹​dep_time, ²​sched_dep_time, ³​dep_delay, ⁴​arr_time,\n#> #   ⁵​sched_arr_time\n\njan1 <- filter(flights, month == 1, day == 1)\n\nfilter(flights, month == 11 | month == 12)\n#> # A tibble: 55,403 × 19\n#>     year month   day dep_t…¹ sched…² dep_d…³ arr_t…⁴ sched…⁵\n#>    <int> <int> <int>   <int>   <int>   <int>   <int>   <int>\n#>  1  2013    11     1       5    2359       6     352     345\n#>  2  2013    11     1      35    2250     105     123    2356\n#>  3  2013    11     1     455     500      -5     641     651\n#>  4  2013    11     1     539     545      -6     856     827\n#>  5  2013    11     1     542     545      -3     831     855\n#>  6  2013    11     1     549     600     -11     912     923\n#>  7  2013    11     1     550     600     -10     705     659\n#>  8  2013    11     1     554     600      -6     659     701\n#>  9  2013    11     1     554     600      -6     826     827\n#> 10  2013    11     1     554     600      -6     749     751\n#> # … with 55,393 more rows, 11 more variables:\n#> #   arr_delay <int>, carrier <chr>, flight <int>,\n#> #   tailnum <chr>, origin <chr>, dest <chr>,\n#> #   air_time <int>, distance <int>, hour <int>,\n#> #   minute <int>, time_hour <chr>, and abbreviated variable\n#> #   names ¹​dep_time, ²​sched_dep_time, ³​dep_delay,\n#> #   ⁴​arr_time, ⁵​sched_arr_time\n\nfilter(flights, month %in% c(11, 12))\n#> # A tibble: 55,403 × 19\n#>     year month   day dep_t…¹ sched…² dep_d…³ arr_t…⁴ sched…⁵\n#>    <int> <int> <int>   <int>   <int>   <int>   <int>   <int>\n#>  1  2013    11     1       5    2359       6     352     345\n#>  2  2013    11     1      35    2250     105     123    2356\n#>  3  2013    11     1     455     500      -5     641     651\n#>  4  2013    11     1     539     545      -6     856     827\n#>  5  2013    11     1     542     545      -3     831     855\n#>  6  2013    11     1     549     600     -11     912     923\n#>  7  2013    11     1     550     600     -10     705     659\n#>  8  2013    11     1     554     600      -6     659     701\n#>  9  2013    11     1     554     600      -6     826     827\n#> 10  2013    11     1     554     600      -6     749     751\n#> # … with 55,393 more rows, 11 more variables:\n#> #   arr_delay <int>, carrier <chr>, flight <int>,\n#> #   tailnum <chr>, origin <chr>, dest <chr>,\n#> #   air_time <int>, distance <int>, hour <int>,\n#> #   minute <int>, time_hour <chr>, and abbreviated variable\n#> #   names ¹​dep_time, ²​sched_dep_time, ³​dep_delay,\n#> #   ⁴​arr_time, ⁵​sched_arr_time"},{"path":"module-6.html","id":"slice-function","chapter":"Module 6","heading":"slice() Function","text":"slice() function allows index rows (integer) locations. can select, remove, duplicate rows.instance, let’s get observations rows 5 10:Let’s select rows except first four (option can used drop observations data set):Similar head() tail() functions, slice_head() slice_tail() can used display top bottom rows data set, respectively. Let’s print first last 3 rows flights data set:Use slice_sample() function randomly select rows. Use option prop choose certain proportion cases:Use replace = TRUE take sample replacement.","code":"\n\nslice(flights, 5:10)\n#> # A tibble: 6 × 19\n#>    year month   day dep_time sched…¹ dep_d…² arr_t…³ sched…⁴\n#>   <int> <int> <int>    <int>   <int>   <int>   <int>   <int>\n#> 1  2013     1     1      554     600      -6     812     837\n#> 2  2013     1     1      554     558      -4     740     728\n#> 3  2013     1     1      555     600      -5     913     854\n#> 4  2013     1     1      557     600      -3     709     723\n#> 5  2013     1     1      557     600      -3     838     846\n#> 6  2013     1     1      558     600      -2     753     745\n#> # … with 11 more variables: arr_delay <int>, carrier <chr>,\n#> #   flight <int>, tailnum <chr>, origin <chr>, dest <chr>,\n#> #   air_time <int>, distance <int>, hour <int>,\n#> #   minute <int>, time_hour <chr>, and abbreviated variable\n#> #   names ¹​sched_dep_time, ²​dep_delay, ³​arr_time,\n#> #   ⁴​sched_arr_time\n\nslice(flights, -(1:4))\n#> # A tibble: 336,772 × 19\n#>     year month   day dep_t…¹ sched…² dep_d…³ arr_t…⁴ sched…⁵\n#>    <int> <int> <int>   <int>   <int>   <int>   <int>   <int>\n#>  1  2013     1     1     554     600      -6     812     837\n#>  2  2013     1     1     554     558      -4     740     728\n#>  3  2013     1     1     555     600      -5     913     854\n#>  4  2013     1     1     557     600      -3     709     723\n#>  5  2013     1     1     557     600      -3     838     846\n#>  6  2013     1     1     558     600      -2     753     745\n#>  7  2013     1     1     558     600      -2     849     851\n#>  8  2013     1     1     558     600      -2     853     856\n#>  9  2013     1     1     558     600      -2     924     917\n#> 10  2013     1     1     558     600      -2     923     937\n#> # … with 336,762 more rows, 11 more variables:\n#> #   arr_delay <int>, carrier <chr>, flight <int>,\n#> #   tailnum <chr>, origin <chr>, dest <chr>,\n#> #   air_time <int>, distance <int>, hour <int>,\n#> #   minute <int>, time_hour <chr>, and abbreviated variable\n#> #   names ¹​dep_time, ²​sched_dep_time, ³​dep_delay,\n#> #   ⁴​arr_time, ⁵​sched_arr_time\n\nslice_head(flights, n = 3)\n#> # A tibble: 3 × 19\n#>    year month   day dep_time sched…¹ dep_d…² arr_t…³ sched…⁴\n#>   <int> <int> <int>    <int>   <int>   <int>   <int>   <int>\n#> 1  2013     1     1      517     515       2     830     819\n#> 2  2013     1     1      533     529       4     850     830\n#> 3  2013     1     1      542     540       2     923     850\n#> # … with 11 more variables: arr_delay <int>, carrier <chr>,\n#> #   flight <int>, tailnum <chr>, origin <chr>, dest <chr>,\n#> #   air_time <int>, distance <int>, hour <int>,\n#> #   minute <int>, time_hour <chr>, and abbreviated variable\n#> #   names ¹​sched_dep_time, ²​dep_delay, ³​arr_time,\n#> #   ⁴​sched_arr_time\n\nslice_tail(flights, n = 3)\n#> # A tibble: 3 × 19\n#>    year month   day dep_time sched…¹ dep_d…² arr_t…³ sched…⁴\n#>   <int> <int> <int>    <int>   <int>   <int>   <int>   <int>\n#> 1  2013     9    30       NA    1210      NA      NA    1330\n#> 2  2013     9    30       NA    1159      NA      NA    1344\n#> 3  2013     9    30       NA     840      NA      NA    1020\n#> # … with 11 more variables: arr_delay <int>, carrier <chr>,\n#> #   flight <int>, tailnum <chr>, origin <chr>, dest <chr>,\n#> #   air_time <int>, distance <int>, hour <int>,\n#> #   minute <int>, time_hour <chr>, and abbreviated variable\n#> #   names ¹​sched_dep_time, ²​dep_delay, ³​arr_time,\n#> #   ⁴​sched_arr_time\n\nslice_sample(flights, n = 10)\n#> # A tibble: 10 × 19\n#>     year month   day dep_t…¹ sched…² dep_d…³ arr_t…⁴ sched…⁵\n#>    <int> <int> <int>   <int>   <int>   <int>   <int>   <int>\n#>  1  2013    11     6    1714    1505     129    1917    1735\n#>  2  2013    11     7    1800    1805      -5    2103    2059\n#>  3  2013     7    14    1327    1330      -3    1558    1558\n#>  4  2013     7    15    1746    1755      -9    1900    1921\n#>  5  2013     1     3    2036    1935      61    2345    2240\n#>  6  2013     9    12      NA    1800      NA      NA    1915\n#>  7  2013     8    12    2032    2040      -8    2138    2154\n#>  8  2013    12    16     749     752      -3    1028    1046\n#>  9  2013     4    11     821     825      -4    1108    1122\n#> 10  2013    10     3     755     759      -4    1028    1049\n#> # … with 11 more variables: arr_delay <int>, carrier <chr>,\n#> #   flight <int>, tailnum <chr>, origin <chr>, dest <chr>,\n#> #   air_time <int>, distance <int>, hour <int>,\n#> #   minute <int>, time_hour <chr>, and abbreviated variable\n#> #   names ¹​dep_time, ²​sched_dep_time, ³​dep_delay,\n#> #   ⁴​arr_time, ⁵​sched_arr_time\n\nslice_sample(flights, prop = 0.001)\n#> # A tibble: 336 × 19\n#>     year month   day dep_t…¹ sched…² dep_d…³ arr_t…⁴ sched…⁵\n#>    <int> <int> <int>   <int>   <int>   <int>   <int>   <int>\n#>  1  2013    11    18    1617    1620      -3    1817    1835\n#>  2  2013     4    20    1707    1710      -3    1912    1915\n#>  3  2013    10    27     750     754      -4     902     913\n#>  4  2013    11     4    1006    1010      -4    1240    1243\n#>  5  2013    10     6    1723    1729      -6    1848    1900\n#>  6  2013     6    25    2056    1903     113    2212    2025\n#>  7  2013    12    12    1907    1815      52    2203    2127\n#>  8  2013     6    12    1708    1555      73    1946    1749\n#>  9  2013     4    17    1441    1445      -4    1704    1709\n#> 10  2013    12     3    1458    1500      -2    1749    1806\n#> # … with 326 more rows, 11 more variables: arr_delay <int>,\n#> #   carrier <chr>, flight <int>, tailnum <chr>,\n#> #   origin <chr>, dest <chr>, air_time <int>,\n#> #   distance <int>, hour <int>, minute <int>,\n#> #   time_hour <chr>, and abbreviated variable names\n#> #   ¹​dep_time, ²​sched_dep_time, ³​dep_delay, ⁴​arr_time,\n#> #   ⁵​sched_arr_time"},{"path":"module-6.html","id":"arrange-function","chapter":"Module 6","heading":"arrange() Function","text":"arrange() function used change order rows data set. takes data frame set column names (complicated expressions) order . provide one column name, additional column used break ties values preceding columns:Use desc() re-order column descending order:","code":"\n\narrange(flights, year, month, day)\n#> # A tibble: 336,776 × 19\n#>     year month   day dep_t…¹ sched…² dep_d…³ arr_t…⁴ sched…⁵\n#>    <int> <int> <int>   <int>   <int>   <int>   <int>   <int>\n#>  1  2013     1     1     517     515       2     830     819\n#>  2  2013     1     1     533     529       4     850     830\n#>  3  2013     1     1     542     540       2     923     850\n#>  4  2013     1     1     544     545      -1    1004    1022\n#>  5  2013     1     1     554     600      -6     812     837\n#>  6  2013     1     1     554     558      -4     740     728\n#>  7  2013     1     1     555     600      -5     913     854\n#>  8  2013     1     1     557     600      -3     709     723\n#>  9  2013     1     1     557     600      -3     838     846\n#> 10  2013     1     1     558     600      -2     753     745\n#> # … with 336,766 more rows, 11 more variables:\n#> #   arr_delay <int>, carrier <chr>, flight <int>,\n#> #   tailnum <chr>, origin <chr>, dest <chr>,\n#> #   air_time <int>, distance <int>, hour <int>,\n#> #   minute <int>, time_hour <chr>, and abbreviated variable\n#> #   names ¹​dep_time, ²​sched_dep_time, ³​dep_delay,\n#> #   ⁴​arr_time, ⁵​sched_arr_time\n\narrange(flights, desc(dep_delay))\n#> # A tibble: 336,776 × 19\n#>     year month   day dep_t…¹ sched…² dep_d…³ arr_t…⁴ sched…⁵\n#>    <int> <int> <int>   <int>   <int>   <int>   <int>   <int>\n#>  1  2013     1     9     641     900    1301    1242    1530\n#>  2  2013     6    15    1432    1935    1137    1607    2120\n#>  3  2013     1    10    1121    1635    1126    1239    1810\n#>  4  2013     9    20    1139    1845    1014    1457    2210\n#>  5  2013     7    22     845    1600    1005    1044    1815\n#>  6  2013     4    10    1100    1900     960    1342    2211\n#>  7  2013     3    17    2321     810     911     135    1020\n#>  8  2013     6    27     959    1900     899    1236    2226\n#>  9  2013     7    22    2257     759     898     121    1026\n#> 10  2013    12     5     756    1700     896    1058    2020\n#> # … with 336,766 more rows, 11 more variables:\n#> #   arr_delay <int>, carrier <chr>, flight <int>,\n#> #   tailnum <chr>, origin <chr>, dest <chr>,\n#> #   air_time <int>, distance <int>, hour <int>,\n#> #   minute <int>, time_hour <chr>, and abbreviated variable\n#> #   names ¹​dep_time, ²​sched_dep_time, ³​dep_delay,\n#> #   ⁴​arr_time, ⁵​sched_arr_time"},{"path":"module-6.html","id":"select-function","chapter":"Module 6","heading":"select() Function","text":"Often work large data sets many columns actually interest . select() function allows rapidly zoom useful subset. can select columns name:can select columns two variables (inclusive):can select columns except :can operation ! operator:can use column indexes column selection:number helper functions can use within select(). example, starts_with(), ends_with(), matches() contains(). let quickly match larger blocks variables meet criterion.Let’s select columns start “sched”:can select columns data set end “time”:suppose want select columns data set contain “ar”:can even combine arguments:","code":"\n\nselect(flights, year, month, day)\n#> # A tibble: 336,776 × 3\n#>     year month   day\n#>    <int> <int> <int>\n#>  1  2013     1     1\n#>  2  2013     1     1\n#>  3  2013     1     1\n#>  4  2013     1     1\n#>  5  2013     1     1\n#>  6  2013     1     1\n#>  7  2013     1     1\n#>  8  2013     1     1\n#>  9  2013     1     1\n#> 10  2013     1     1\n#> # … with 336,766 more rows\n\nselect(flights, year:day)\n#> # A tibble: 336,776 × 3\n#>     year month   day\n#>    <int> <int> <int>\n#>  1  2013     1     1\n#>  2  2013     1     1\n#>  3  2013     1     1\n#>  4  2013     1     1\n#>  5  2013     1     1\n#>  6  2013     1     1\n#>  7  2013     1     1\n#>  8  2013     1     1\n#>  9  2013     1     1\n#> 10  2013     1     1\n#> # … with 336,766 more rows\n\nselect(flights, -(year:day))\n#> # A tibble: 336,776 × 16\n#>    dep_time sched_…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n#>       <int>    <int>   <int>   <int>   <int>   <int> <chr>  \n#>  1      517      515       2     830     819      11 UA     \n#>  2      533      529       4     850     830      20 UA     \n#>  3      542      540       2     923     850      33 AA     \n#>  4      544      545      -1    1004    1022     -18 B6     \n#>  5      554      600      -6     812     837     -25 DL     \n#>  6      554      558      -4     740     728      12 UA     \n#>  7      555      600      -5     913     854      19 B6     \n#>  8      557      600      -3     709     723     -14 EV     \n#>  9      557      600      -3     838     846      -8 B6     \n#> 10      558      600      -2     753     745       8 AA     \n#> # … with 336,766 more rows, 9 more variables: flight <int>,\n#> #   tailnum <chr>, origin <chr>, dest <chr>,\n#> #   air_time <int>, distance <int>, hour <int>,\n#> #   minute <int>, time_hour <chr>, and abbreviated variable\n#> #   names ¹​sched_dep_time, ²​dep_delay, ³​arr_time,\n#> #   ⁴​sched_arr_time, ⁵​arr_delay\n\nselect(flights, !(year:day))\n#> # A tibble: 336,776 × 16\n#>    dep_time sched_…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵ carrier\n#>       <int>    <int>   <int>   <int>   <int>   <int> <chr>  \n#>  1      517      515       2     830     819      11 UA     \n#>  2      533      529       4     850     830      20 UA     \n#>  3      542      540       2     923     850      33 AA     \n#>  4      544      545      -1    1004    1022     -18 B6     \n#>  5      554      600      -6     812     837     -25 DL     \n#>  6      554      558      -4     740     728      12 UA     \n#>  7      555      600      -5     913     854      19 B6     \n#>  8      557      600      -3     709     723     -14 EV     \n#>  9      557      600      -3     838     846      -8 B6     \n#> 10      558      600      -2     753     745       8 AA     \n#> # … with 336,766 more rows, 9 more variables: flight <int>,\n#> #   tailnum <chr>, origin <chr>, dest <chr>,\n#> #   air_time <int>, distance <int>, hour <int>,\n#> #   minute <int>, time_hour <chr>, and abbreviated variable\n#> #   names ¹​sched_dep_time, ²​dep_delay, ³​arr_time,\n#> #   ⁴​sched_arr_time, ⁵​arr_delay\n\nselect(flights, c(1, 5, 8))\n#> # A tibble: 336,776 × 3\n#>     year sched_dep_time sched_arr_time\n#>    <int>          <int>          <int>\n#>  1  2013            515            819\n#>  2  2013            529            830\n#>  3  2013            540            850\n#>  4  2013            545           1022\n#>  5  2013            600            837\n#>  6  2013            558            728\n#>  7  2013            600            854\n#>  8  2013            600            723\n#>  9  2013            600            846\n#> 10  2013            600            745\n#> # … with 336,766 more rows\n\nselect(flights, starts_with(\"sched\"))\n#> # A tibble: 336,776 × 2\n#>    sched_dep_time sched_arr_time\n#>             <int>          <int>\n#>  1            515            819\n#>  2            529            830\n#>  3            540            850\n#>  4            545           1022\n#>  5            600            837\n#>  6            558            728\n#>  7            600            854\n#>  8            600            723\n#>  9            600            846\n#> 10            600            745\n#> # … with 336,766 more rows\n\nselect(flights, ends_with(\"time\"))\n#> # A tibble: 336,776 × 5\n#>    dep_time sched_dep_time arr_time sched_arr_time air_time\n#>       <int>          <int>    <int>          <int>    <int>\n#>  1      517            515      830            819      227\n#>  2      533            529      850            830      227\n#>  3      542            540      923            850      160\n#>  4      544            545     1004           1022      183\n#>  5      554            600      812            837      116\n#>  6      554            558      740            728      150\n#>  7      555            600      913            854      158\n#>  8      557            600      709            723       53\n#>  9      557            600      838            846      140\n#> 10      558            600      753            745      138\n#> # … with 336,766 more rows\n\nselect(flights, contains(\"ar\"))\n#> # A tibble: 336,776 × 5\n#>     year arr_time sched_arr_time arr_delay carrier\n#>    <int>    <int>          <int>     <int> <chr>  \n#>  1  2013      830            819        11 UA     \n#>  2  2013      850            830        20 UA     \n#>  3  2013      923            850        33 AA     \n#>  4  2013     1004           1022       -18 B6     \n#>  5  2013      812            837       -25 DL     \n#>  6  2013      740            728        12 UA     \n#>  7  2013      913            854        19 B6     \n#>  8  2013      709            723       -14 EV     \n#>  9  2013      838            846        -8 B6     \n#> 10  2013      753            745         8 AA     \n#> # … with 336,766 more rows\n\nselect(flights, starts_with(\"sched\") & ends_with(\"time\"))\n#> # A tibble: 336,776 × 2\n#>    sched_dep_time sched_arr_time\n#>             <int>          <int>\n#>  1            515            819\n#>  2            529            830\n#>  3            540            850\n#>  4            545           1022\n#>  5            600            837\n#>  6            558            728\n#>  7            600            854\n#>  8            600            723\n#>  9            600            846\n#> 10            600            745\n#> # … with 336,766 more rows"},{"path":"module-6.html","id":"rename-function","chapter":"Module 6","heading":"rename() Function","text":"Use rename() function rename columns data frame. Suppose want rename “year” “month” variables make uppercase:","code":"\n\nrename(flights, YEAR = year, MONTH = month)\n#> # A tibble: 336,776 × 19\n#>     YEAR MONTH   day dep_t…¹ sched…² dep_d…³ arr_t…⁴ sched…⁵\n#>    <int> <int> <int>   <int>   <int>   <int>   <int>   <int>\n#>  1  2013     1     1     517     515       2     830     819\n#>  2  2013     1     1     533     529       4     850     830\n#>  3  2013     1     1     542     540       2     923     850\n#>  4  2013     1     1     544     545      -1    1004    1022\n#>  5  2013     1     1     554     600      -6     812     837\n#>  6  2013     1     1     554     558      -4     740     728\n#>  7  2013     1     1     555     600      -5     913     854\n#>  8  2013     1     1     557     600      -3     709     723\n#>  9  2013     1     1     557     600      -3     838     846\n#> 10  2013     1     1     558     600      -2     753     745\n#> # … with 336,766 more rows, 11 more variables:\n#> #   arr_delay <int>, carrier <chr>, flight <int>,\n#> #   tailnum <chr>, origin <chr>, dest <chr>,\n#> #   air_time <int>, distance <int>, hour <int>,\n#> #   minute <int>, time_hour <chr>, and abbreviated variable\n#> #   names ¹​dep_time, ²​sched_dep_time, ³​dep_delay,\n#> #   ⁴​arr_time, ⁵​sched_arr_time"},{"path":"module-6.html","id":"relocate-function","chapter":"Module 6","heading":"relocate() Function","text":"relocate() function allows change positions columns data frame. two useful arguments ..helps precisely select location variable:","code":"\n\nrelocate(flights, year, .after = month)\n#> # A tibble: 336,776 × 19\n#>    month  year   day dep_t…¹ sched…² dep_d…³ arr_t…⁴ sched…⁵\n#>    <int> <int> <int>   <int>   <int>   <int>   <int>   <int>\n#>  1     1  2013     1     517     515       2     830     819\n#>  2     1  2013     1     533     529       4     850     830\n#>  3     1  2013     1     542     540       2     923     850\n#>  4     1  2013     1     544     545      -1    1004    1022\n#>  5     1  2013     1     554     600      -6     812     837\n#>  6     1  2013     1     554     558      -4     740     728\n#>  7     1  2013     1     555     600      -5     913     854\n#>  8     1  2013     1     557     600      -3     709     723\n#>  9     1  2013     1     557     600      -3     838     846\n#> 10     1  2013     1     558     600      -2     753     745\n#> # … with 336,766 more rows, 11 more variables:\n#> #   arr_delay <int>, carrier <chr>, flight <int>,\n#> #   tailnum <chr>, origin <chr>, dest <chr>,\n#> #   air_time <int>, distance <int>, hour <int>,\n#> #   minute <int>, time_hour <chr>, and abbreviated variable\n#> #   names ¹​dep_time, ²​sched_dep_time, ³​dep_delay,\n#> #   ⁴​arr_time, ⁵​sched_arr_time\n\nrelocate(flights, c(year, month), .before = dep_delay)\n#> # A tibble: 336,776 × 19\n#>      day dep_t…¹ sched…²  year month dep_d…³ arr_t…⁴ sched…⁵\n#>    <int>   <int>   <int> <int> <int>   <int>   <int>   <int>\n#>  1     1     517     515  2013     1       2     830     819\n#>  2     1     533     529  2013     1       4     850     830\n#>  3     1     542     540  2013     1       2     923     850\n#>  4     1     544     545  2013     1      -1    1004    1022\n#>  5     1     554     600  2013     1      -6     812     837\n#>  6     1     554     558  2013     1      -4     740     728\n#>  7     1     555     600  2013     1      -5     913     854\n#>  8     1     557     600  2013     1      -3     709     723\n#>  9     1     557     600  2013     1      -3     838     846\n#> 10     1     558     600  2013     1      -2     753     745\n#> # … with 336,766 more rows, 11 more variables:\n#> #   arr_delay <int>, carrier <chr>, flight <int>,\n#> #   tailnum <chr>, origin <chr>, dest <chr>,\n#> #   air_time <int>, distance <int>, hour <int>,\n#> #   minute <int>, time_hour <chr>, and abbreviated variable\n#> #   names ¹​dep_time, ²​sched_dep_time, ³​dep_delay,\n#> #   ⁴​arr_time, ⁵​sched_arr_time\n\nrelocate(flights, c(year, month), .after = last_col())\n#> # A tibble: 336,776 × 19\n#>      day dep_time sched_de…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵\n#>    <int>    <int>      <int>   <int>   <int>   <int>   <int>\n#>  1     1      517        515       2     830     819      11\n#>  2     1      533        529       4     850     830      20\n#>  3     1      542        540       2     923     850      33\n#>  4     1      544        545      -1    1004    1022     -18\n#>  5     1      554        600      -6     812     837     -25\n#>  6     1      554        558      -4     740     728      12\n#>  7     1      555        600      -5     913     854      19\n#>  8     1      557        600      -3     709     723     -14\n#>  9     1      557        600      -3     838     846      -8\n#> 10     1      558        600      -2     753     745       8\n#> # … with 336,766 more rows, 12 more variables:\n#> #   carrier <chr>, flight <int>, tailnum <chr>,\n#> #   origin <chr>, dest <chr>, air_time <int>,\n#> #   distance <int>, hour <int>, minute <int>,\n#> #   time_hour <chr>, year <int>, month <int>, and\n#> #   abbreviated variable names ¹​sched_dep_time, ²​dep_delay,\n#> #   ³​arr_time, ⁴​sched_arr_time, ⁵​arr_delay\n\nrelocate(flights, dep_delay, .before = everything())\n#> # A tibble: 336,776 × 19\n#>    dep_d…¹  year month   day dep_t…² sched…³ arr_t…⁴ sched…⁵\n#>      <int> <int> <int> <int>   <int>   <int>   <int>   <int>\n#>  1       2  2013     1     1     517     515     830     819\n#>  2       4  2013     1     1     533     529     850     830\n#>  3       2  2013     1     1     542     540     923     850\n#>  4      -1  2013     1     1     544     545    1004    1022\n#>  5      -6  2013     1     1     554     600     812     837\n#>  6      -4  2013     1     1     554     558     740     728\n#>  7      -5  2013     1     1     555     600     913     854\n#>  8      -3  2013     1     1     557     600     709     723\n#>  9      -3  2013     1     1     557     600     838     846\n#> 10      -2  2013     1     1     558     600     753     745\n#> # … with 336,766 more rows, 11 more variables:\n#> #   arr_delay <int>, carrier <chr>, flight <int>,\n#> #   tailnum <chr>, origin <chr>, dest <chr>,\n#> #   air_time <int>, distance <int>, hour <int>,\n#> #   minute <int>, time_hour <chr>, and abbreviated variable\n#> #   names ¹​dep_delay, ²​dep_time, ³​sched_dep_time,\n#> #   ⁴​arr_time, ⁵​sched_arr_time"},{"path":"module-6.html","id":"mutate-function","chapter":"Module 6","heading":"mutate() Function","text":"’s often useful add new columns functions existing columns. ’s mutate() function .mutate() always adds new columns end data set ’ll start creating narrower data set can see new variables:Now let’s add “gain” “speed” columns data frame:Note can refer columns ’ve just created:want keep new variable, use transmute() function:","code":"\n\nflights_2 <- select(flights, month, ends_with(\"delay\"), distance, air_time)\n\nmutate(flights_2, gain = dep_delay - arr_delay, speed = distance / air_time * 60)\n#> # A tibble: 336,776 × 7\n#>    month dep_delay arr_delay distance air_time  gain speed\n#>    <int>     <int>     <int>    <int>    <int> <int> <dbl>\n#>  1     1         2        11     1400      227    -9  370.\n#>  2     1         4        20     1416      227   -16  374.\n#>  3     1         2        33     1089      160   -31  408.\n#>  4     1        -1       -18     1576      183    17  517.\n#>  5     1        -6       -25      762      116    19  394.\n#>  6     1        -4        12      719      150   -16  288.\n#>  7     1        -5        19     1065      158   -24  404.\n#>  8     1        -3       -14      229       53    11  259.\n#>  9     1        -3        -8      944      140     5  405.\n#> 10     1        -2         8      733      138   -10  319.\n#> # … with 336,766 more rows\n\nmutate(flights_2, gain = dep_delay - arr_delay, hours = air_time/60, gain_per_hour = gain/hours)\n#> # A tibble: 336,776 × 8\n#>    month dep_d…¹ arr_d…² dista…³ air_t…⁴  gain hours gain_…⁵\n#>    <int>   <int>   <int>   <int>   <int> <int> <dbl>   <dbl>\n#>  1     1       2      11    1400     227    -9 3.78    -2.38\n#>  2     1       4      20    1416     227   -16 3.78    -4.23\n#>  3     1       2      33    1089     160   -31 2.67   -11.6 \n#>  4     1      -1     -18    1576     183    17 3.05     5.57\n#>  5     1      -6     -25     762     116    19 1.93     9.83\n#>  6     1      -4      12     719     150   -16 2.5     -6.4 \n#>  7     1      -5      19    1065     158   -24 2.63    -9.11\n#>  8     1      -3     -14     229      53    11 0.883   12.5 \n#>  9     1      -3      -8     944     140     5 2.33     2.14\n#> 10     1      -2       8     733     138   -10 2.3     -4.35\n#> # … with 336,766 more rows, and abbreviated variable names\n#> #   ¹​dep_delay, ²​arr_delay, ³​distance, ⁴​air_time,\n#> #   ⁵​gain_per_hour\n\ntransmute(flights_2, gain = dep_delay - arr_delay, hours = air_time/60, gain_per_hour = gain/hours)\n#> # A tibble: 336,776 × 3\n#>     gain hours gain_per_hour\n#>    <int> <dbl>         <dbl>\n#>  1    -9 3.78          -2.38\n#>  2   -16 3.78          -4.23\n#>  3   -31 2.67         -11.6 \n#>  4    17 3.05           5.57\n#>  5    19 1.93           9.83\n#>  6   -16 2.5           -6.4 \n#>  7   -24 2.63          -9.11\n#>  8    11 0.883         12.5 \n#>  9     5 2.33           2.14\n#> 10   -10 2.3           -4.35\n#> # … with 336,766 more rows"},{"path":"module-6.html","id":"pipe-operator","chapter":"Module 6","heading":"%>% Pipe Operator","text":"dplyr functions functional sense function calls don’t side-effects. must always save results. doesn’t lead particularly elegant code, especially want many operations . either step--step don’t want name intermediate results, need wrap function calls inside , lead messy complex code:difficult read order operations inside . Thus, arguments long way away function. get around problem, dplyr provides %>% operator. pipe operator, %>%, comes magrittr package Stefan Milton Bache. Packages tidyverse load %>% automatically, don’t usually load magrittr explicitly.x %>% f(y) turns f(x, y) can use rewrite multiple operations can read left--right, top--bottom (reading pipe operator “”):Try understand following code :","code":"\n\nselect(filter(flights, month == 11 | month == 12), starts_with(\"sched\") & ends_with(\"time\"))\n#> # A tibble: 55,403 × 2\n#>    sched_dep_time sched_arr_time\n#>             <int>          <int>\n#>  1           2359            345\n#>  2           2250           2356\n#>  3            500            651\n#>  4            545            827\n#>  5            545            855\n#>  6            600            923\n#>  7            600            659\n#>  8            600            701\n#>  9            600            827\n#> 10            600            751\n#> # … with 55,393 more rows\n\nflights %>% \n  \n  filter(month == 11 | month == 12) %>%\n  \n  select( starts_with(\"sched\") & ends_with(\"time\"))\n#> # A tibble: 55,403 × 2\n#>    sched_dep_time sched_arr_time\n#>             <int>          <int>\n#>  1           2359            345\n#>  2           2250           2356\n#>  3            500            651\n#>  4            545            827\n#>  5            545            855\n#>  6            600            923\n#>  7            600            659\n#>  8            600            701\n#>  9            600            827\n#> 10            600            751\n#> # … with 55,393 more rows\n\nflights %>% \n  \n  filter(month %in% c(10, 11, 12), arr_delay < 10) %>%\n  \n  slice(1:30) %>%\n  \n  arrange(desc(arr_delay)) %>%\n  \n  select(-c(1,4))\n#> # A tibble: 30 × 17\n#>    month   day sched_dep_t…¹ dep_d…² arr_t…³ sched…⁴ arr_d…⁵\n#>    <int> <int>         <int>   <int>   <int>   <int>   <int>\n#>  1    10     1           600      -9     727     730      -3\n#>  2    10     1           600      -2     743     751      -8\n#>  3    10     1           600     -10     649     659     -10\n#>  4    10     1           610      -7     735     745     -10\n#>  5    10     1           600      -9     710     721     -11\n#>  6    10     1           600      -2     650     701     -11\n#>  7    10     1           600      -1     719     730     -11\n#>  8    10     1           600       0     706     717     -11\n#>  9    10     1           600     -10     648     700     -12\n#> 10    10     1           600      -9     655     708     -13\n#> # … with 20 more rows, 10 more variables: carrier <chr>,\n#> #   flight <int>, tailnum <chr>, origin <chr>, dest <chr>,\n#> #   air_time <int>, distance <int>, hour <int>,\n#> #   minute <int>, time_hour <chr>, and abbreviated variable\n#> #   names ¹​sched_dep_time, ²​dep_delay, ³​arr_time,\n#> #   ⁴​sched_arr_time, ⁵​arr_delay"},{"path":"module-6.html","id":"group_by-summarise-and-across-functions","chapter":"Module 6","heading":"group_by(), summarise(), and across() Functions","text":"data operations done groups defined variables. dplyr verbs particularly powerful apply grouped data frames. important grouping verb group_by(). takes existing data frame converts grouped data frame operations performed “group”. words, takes data frame one variables group :Grouping change data looks apart listing grouped.Grouping useful used conjunction summarise() function. summarise() creates new data frame. returns one row combination grouping variables; grouping variables, output single row summarizing observations input. contain one column grouping variable one column summary statistics specified. Thus, changes unit analysis complete dataset individual groups. Together group_by() summarise() provide one tools ’ll use commonly working dplyr: grouped summaries.instance, let’s calculate average arrival delay time group by_origin grouped data:can even pass several variables :table displays useful functions frequently used summarise():group_by() summarise() functions can combined single table verbs:need remove grouping return operations ungrouped data, use ungroup():’s often useful perform operation multiple columns, copying pasting tedious error prone. example:Instead, can use across() function, lets rewrite previous code succinctly:across() two primary arguments: (1) first argument, .col, selects columns want operate ; (2) second argument, .fns, function list functions apply column. examples:can transform variable one function supplying named list functions lambda functions second argument:can control names created .names argument:","code":"\n\nby_origin <- flights %>% group_by(origin)\n\nby_origin\n#> # A tibble: 336,776 × 19\n#> # Groups:   origin [3]\n#>     year month   day dep_t…¹ sched…² dep_d…³ arr_t…⁴ sched…⁵\n#>    <int> <int> <int>   <int>   <int>   <int>   <int>   <int>\n#>  1  2013     1     1     517     515       2     830     819\n#>  2  2013     1     1     533     529       4     850     830\n#>  3  2013     1     1     542     540       2     923     850\n#>  4  2013     1     1     544     545      -1    1004    1022\n#>  5  2013     1     1     554     600      -6     812     837\n#>  6  2013     1     1     554     558      -4     740     728\n#>  7  2013     1     1     555     600      -5     913     854\n#>  8  2013     1     1     557     600      -3     709     723\n#>  9  2013     1     1     557     600      -3     838     846\n#> 10  2013     1     1     558     600      -2     753     745\n#> # … with 336,766 more rows, 11 more variables:\n#> #   arr_delay <int>, carrier <chr>, flight <int>,\n#> #   tailnum <chr>, origin <chr>, dest <chr>,\n#> #   air_time <int>, distance <int>, hour <int>,\n#> #   minute <int>, time_hour <chr>, and abbreviated variable\n#> #   names ¹​dep_time, ²​sched_dep_time, ³​dep_delay,\n#> #   ⁴​arr_time, ⁵​sched_arr_time\n\nby_origin_carrier <- flights %>% group_by(origin, carrier)\n\nby_origin_carrier\n#> # A tibble: 336,776 × 19\n#> # Groups:   origin, carrier [35]\n#>     year month   day dep_t…¹ sched…² dep_d…³ arr_t…⁴ sched…⁵\n#>    <int> <int> <int>   <int>   <int>   <int>   <int>   <int>\n#>  1  2013     1     1     517     515       2     830     819\n#>  2  2013     1     1     533     529       4     850     830\n#>  3  2013     1     1     542     540       2     923     850\n#>  4  2013     1     1     544     545      -1    1004    1022\n#>  5  2013     1     1     554     600      -6     812     837\n#>  6  2013     1     1     554     558      -4     740     728\n#>  7  2013     1     1     555     600      -5     913     854\n#>  8  2013     1     1     557     600      -3     709     723\n#>  9  2013     1     1     557     600      -3     838     846\n#> 10  2013     1     1     558     600      -2     753     745\n#> # … with 336,766 more rows, 11 more variables:\n#> #   arr_delay <int>, carrier <chr>, flight <int>,\n#> #   tailnum <chr>, origin <chr>, dest <chr>,\n#> #   air_time <int>, distance <int>, hour <int>,\n#> #   minute <int>, time_hour <chr>, and abbreviated variable\n#> #   names ¹​dep_time, ²​sched_dep_time, ³​dep_delay,\n#> #   ⁴​arr_time, ⁵​sched_arr_time\n\nby_origin %>% summarise(Mean = mean(arr_delay, na.rm = T))\n#> # A tibble: 3 × 2\n#>   origin  Mean\n#>   <chr>  <dbl>\n#> 1 EWR     9.11\n#> 2 JFK     5.55\n#> 3 LGA     5.78\n\nby_origin %>% \n  \n  summarise(Mean = mean(arr_delay, na.rm = T),\n            \n            Median = median(arr_delay, na.rm = T),\n            \n            Count = n())\n#> # A tibble: 3 × 4\n#>   origin  Mean Median  Count\n#>   <chr>  <dbl>  <dbl>  <int>\n#> 1 EWR     9.11     -4 120835\n#> 2 JFK     5.55     -6 111279\n#> 3 LGA     5.78     -5 104662\n\nby_carrier <- flights %>% group_by(carrier)\n\nby_carrier %>%\n  \n  summarise (Count = n(), Distance_sd = sd(distance)) %>%\n  \n  filter(Count < 10000) %>%\n  \n  arrange(desc(Distance_sd))\n#> # A tibble: 7 × 3\n#>   carrier Count Distance_sd\n#>   <chr>   <int>       <dbl>\n#> 1 OO         32       206. \n#> 2 FL       3260       161. \n#> 3 YV        601       160. \n#> 4 VX       5162        88.0\n#> 5 AS        714         0  \n#> 6 F9        685         0  \n#> 7 HA        342         0\n\nby_carrier %>%\n  \n  ungroup() %>%\n  \n  summarise(flights = n())\n#> # A tibble: 1 × 1\n#>   flights\n#>     <int>\n#> 1  336776\n\nflights %>% \n  \n  group_by(origin, carrier) %>%\n  \n  summarise(Mean_dep_delay = mean(dep_delay, na.rm = T),\n            \n            Mean_arrival_delay = mean(arr_delay, na.rm = T),\n            \n            Mean_air_time = mean(air_time, na.rm = T))\n#> `summarise()` has grouped output by 'origin'. You can\n#> override using the `.groups` argument.\n#> # A tibble: 35 × 5\n#> # Groups:   origin [3]\n#>    origin carrier Mean_dep_delay Mean_arrival_delay Mean_a…¹\n#>    <chr>  <chr>            <dbl>              <dbl>    <dbl>\n#>  1 EWR    9E                5.95              1.62     103. \n#>  2 EWR    AA               10.0               0.978    196. \n#>  3 EWR    AS                5.80             -9.93     326. \n#>  4 EWR    B6               13.1               9.39     118. \n#>  5 EWR    DL               12.1               8.78     125. \n#>  6 EWR    EV               20.2              17.0       94.0\n#>  7 EWR    MQ               17.5              16.3      112. \n#>  8 EWR    OO               20.8              21.5      137. \n#>  9 EWR    UA               12.5               3.48     207. \n#> 10 EWR    US                3.74              0.977    138. \n#> # … with 25 more rows, and abbreviated variable name\n#> #   ¹​Mean_air_time\n\nflights %>% \n  \n  group_by(origin, carrier) %>%\n  \n  summarise(across(\n    \n    c(dep_delay, arr_delay, air_time),\n    \n    ~ mean(.x, na.rm = T)\n    \n  ))\n#> `summarise()` has grouped output by 'origin'. You can\n#> override using the `.groups` argument.\n#> # A tibble: 35 × 5\n#> # Groups:   origin [3]\n#>    origin carrier dep_delay arr_delay air_time\n#>    <chr>  <chr>       <dbl>     <dbl>    <dbl>\n#>  1 EWR    9E           5.95     1.62     103. \n#>  2 EWR    AA          10.0      0.978    196. \n#>  3 EWR    AS           5.80    -9.93     326. \n#>  4 EWR    B6          13.1      9.39     118. \n#>  5 EWR    DL          12.1      8.78     125. \n#>  6 EWR    EV          20.2     17.0       94.0\n#>  7 EWR    MQ          17.5     16.3      112. \n#>  8 EWR    OO          20.8     21.5      137. \n#>  9 EWR    UA          12.5      3.48     207. \n#> 10 EWR    US           3.74     0.977    138. \n#> # … with 25 more rows\n\nflights %>% \n  \n  summarise(across(where(is.factor), n_distinct))\n#> # A tibble: 1 × 0\n\nflights %>% \n  \n  group_by(origin) %>%\n  \n  summarise(across(where(is.numeric), ~ mean(.x, na.rm = TRUE)))\n#> # A tibble: 3 × 15\n#>   origin  year month   day dep_time sched_…¹ dep_d…² arr_t…³\n#>   <chr>  <dbl> <dbl> <dbl>    <dbl>    <dbl>   <dbl>   <dbl>\n#> 1 EWR     2013  6.49  15.7    1337.    1322.    15.1   1492.\n#> 2 JFK     2013  6.50  15.7    1399.    1402.    12.1   1520.\n#> 3 LGA     2013  6.67  15.7    1310.    1308.    10.3   1494.\n#> # … with 7 more variables: sched_arr_time <dbl>,\n#> #   arr_delay <dbl>, flight <dbl>, air_time <dbl>,\n#> #   distance <dbl>, hour <dbl>, minute <dbl>, and\n#> #   abbreviated variable names ¹​sched_dep_time, ²​dep_delay,\n#> #   ³​arr_time\n\n\nmin_max <- list(\n  \n  min = ~min(.x, na.rm = TRUE), \n  \n  max = ~max(.x, na.rm = TRUE)\n)\n\nflights %>% \n  \n  group_by(origin) %>%\n  \n  summarise(across(where(is.numeric), min_max))\n#> # A tibble: 3 × 29\n#>   origin year_min year_max month_min month…¹ day_min day_max\n#>   <chr>     <int>    <int>     <int>   <int>   <int>   <int>\n#> 1 EWR        2013     2013         1      12       1      31\n#> 2 JFK        2013     2013         1      12       1      31\n#> 3 LGA        2013     2013         1      12       1      31\n#> # … with 22 more variables: dep_time_min <int>,\n#> #   dep_time_max <int>, sched_dep_time_min <int>,\n#> #   sched_dep_time_max <int>, dep_delay_min <int>,\n#> #   dep_delay_max <int>, arr_time_min <int>,\n#> #   arr_time_max <int>, sched_arr_time_min <int>,\n#> #   sched_arr_time_max <int>, arr_delay_min <int>,\n#> #   arr_delay_max <int>, flight_min <int>, …\n\nflights %>% \n  \n  group_by(origin) %>%\n  \n  summarise(across(where(is.numeric), min_max,\n                   \n                   .names = \"{.fn}.{.col}\"\n                   \n                   ))\n#> # A tibble: 3 × 29\n#>   origin min.year max.year min.month max.m…¹ min.day max.day\n#>   <chr>     <int>    <int>     <int>   <int>   <int>   <int>\n#> 1 EWR        2013     2013         1      12       1      31\n#> 2 JFK        2013     2013         1      12       1      31\n#> 3 LGA        2013     2013         1      12       1      31\n#> # … with 22 more variables: min.dep_time <int>,\n#> #   max.dep_time <int>, min.sched_dep_time <int>,\n#> #   max.sched_dep_time <int>, min.dep_delay <int>,\n#> #   max.dep_delay <int>, min.arr_time <int>,\n#> #   max.arr_time <int>, min.sched_arr_time <int>,\n#> #   max.sched_arr_time <int>, min.arr_delay <int>,\n#> #   max.arr_delay <int>, min.flight <int>, …"},{"path":"module-6.html","id":"relational-data-two-table-verbs","chapter":"Module 6","heading":"Relational Data: Two-Table Verbs","text":"’s rare data analysis involves single table data. practice, ’ll normally many tables contribute analysis, need flexible tools combine .dplyr, three families verbs work two tables time:Mutating joins, add new variables one table matching rows anotherFiltering joins, filter observations one table based whether match observation tableSet operations, combine observations data sets set elements","code":""},{"path":"module-6.html","id":"mutating-joins","chapter":"Module 6","heading":"Mutating joins","text":"Mutating joins allow combine variables multiple tables. first matches observations keys, copies across variables one table . four types mutating join, differ behavior match found. :inner_join()left_join()right_join()full_join()functions input arguments. focusing following arguments:x y - tables dataframes combined (x known primary table y secondary table)- join key, variable variables /used match rows x y tables. words, controls variables used match observations two tables.keep - logical operator indicating whether join keys x y tables preserved output. default value FALSE.output always new table. default, observation x matches multiple observations y, matching observations y returned. occurs, normally warning thrown stating multiple matches detected since usually surprising.illustrative functions work, using following toy data frames:","code":"\n\ndf1 <- data.frame(\n  \n  a = c(1, 2, 3, 2, 4),\n  \n  b = c(10, 20, 30, 35, 40),\n  \n  c  = c(100, 200, 300, 350, 400)\n  \n)\n\nprint(df1)\n#>   a  b   c\n#> 1 1 10 100\n#> 2 2 20 200\n#> 3 3 30 300\n#> 4 2 35 350\n#> 5 4 40 400\n\ndf2 <- data.frame(\n  \n  a =  c(1, 2, 5, 4, 6, 2),\n  \n  b  =  c(10, 40, 50, 40, 60, 50),\n  \n  x = c(15, 25, 35, 45, 55, 65),\n  \n  z = c(150, 200, 350, 400, 550, 270)\n\n)\n\nprint(df2)\n#>   a  b  x   z\n#> 1 1 10 15 150\n#> 2 2 40 25 200\n#> 3 5 50 35 350\n#> 4 4 40 45 400\n#> 5 6 60 55 550\n#> 6 2 50 65 270"},{"path":"module-6.html","id":"inner_join","chapter":"Module 6","heading":"inner_join()","text":"simplest type join inner join. inner join matches pairs observations whenever keys equal. output inner join new data frame contains key, x values, y values. important property inner join unmatched rows either input included result.examples inner join:","code":"\n\n# Merging tables by the \"a\" variable\n\ndf1 %>%\n  \n  inner_join(df2, by = \"a\")\n#>   a b.x   c b.y  x   z\n#> 1 1  10 100  10 15 150\n#> 2 2  20 200  40 25 200\n#> 3 2  20 200  50 65 270\n#> 4 2  35 350  40 25 200\n#> 5 2  35 350  50 65 270\n#> 6 4  40 400  40 45 400\n\n# Merging tables by the \"a\" and \"b\" variable\n\ndf1 %>%\n  \n  inner_join(df2, by = c(\"a\", \"b\"))\n#>   a  b   c  x   z\n#> 1 1 10 100 15 150\n#> 2 4 40 400 45 400\n\n## Merging tables by the \"c\" and \"z\" variable (Have different variable names)\n\ndf1 %>%\n  \n  inner_join(df2, by = c(\"c\" = \"z\"))\n#>   a.x b.x   c a.y b.y  x\n#> 1   2  20 200   2  40 25\n#> 2   2  35 350   5  50 35\n#> 3   4  40 400   4  40 45\n\n## Merging tables by the \"c\" and \"z\" variable (Have different variable names) and keeping both key variables in the output table\n\ndf1 %>%\n  \n  inner_join(df2, by = c(\"c\" = \"z\"), keep = T)\n#>   a.x b.x   c a.y b.y  x   z\n#> 1   2  20 200   2  40 25 200\n#> 2   2  35 350   5  50 35 350\n#> 3   4  40 400   4  40 45 400"},{"path":"module-6.html","id":"left_join","chapter":"Module 6","heading":"left_join()","text":"left_join() includes observations x, regardless whether match . commonly used join ensures don’t lose observations primary table:","code":"\n\n# Merging tables by the \"a\" variable\n\ndf1 %>%\n  \n  left_join(df2, by = \"a\")\n#>   a b.x   c b.y  x   z\n#> 1 1  10 100  10 15 150\n#> 2 2  20 200  40 25 200\n#> 3 2  20 200  50 65 270\n#> 4 3  30 300  NA NA  NA\n#> 5 2  35 350  40 25 200\n#> 6 2  35 350  50 65 270\n#> 7 4  40 400  40 45 400\n\n# Merging tables by the \"a\" and \"b\" variable\n\ndf1 %>%\n  \n  left_join(df2, by = c(\"a\", \"b\"))\n#>   a  b   c  x   z\n#> 1 1 10 100 15 150\n#> 2 2 20 200 NA  NA\n#> 3 3 30 300 NA  NA\n#> 4 2 35 350 NA  NA\n#> 5 4 40 400 45 400\n\n## Merging tables by the \"c\" and \"z\" variable (Have different variable names)\n\ndf1 %>%\n  \n  left_join(df2, by = c(\"c\" = \"z\"))\n#>   a.x b.x   c a.y b.y  x\n#> 1   1  10 100  NA  NA NA\n#> 2   2  20 200   2  40 25\n#> 3   3  30 300  NA  NA NA\n#> 4   2  35 350   5  50 35\n#> 5   4  40 400   4  40 45"},{"path":"module-6.html","id":"right_join","chapter":"Module 6","heading":"right_join()","text":"right_join() includes observations y:","code":"\n\n# Merging tables by the \"a\" variable\n\ndf1 %>%\n  \n  right_join(df2, by = \"a\")\n#>   a b.x   c b.y  x   z\n#> 1 1  10 100  10 15 150\n#> 2 2  20 200  40 25 200\n#> 3 2  20 200  50 65 270\n#> 4 2  35 350  40 25 200\n#> 5 2  35 350  50 65 270\n#> 6 4  40 400  40 45 400\n#> 7 5  NA  NA  50 35 350\n#> 8 6  NA  NA  60 55 550\n\n# Merging tables by the \"a\" and \"b\" variable\n\ndf1 %>%\n  \n  right_join(df2, by = c(\"a\", \"b\"))\n#>   a  b   c  x   z\n#> 1 1 10 100 15 150\n#> 2 4 40 400 45 400\n#> 3 2 40  NA 25 200\n#> 4 5 50  NA 35 350\n#> 5 6 60  NA 55 550\n#> 6 2 50  NA 65 270\n\n## Merging tables by the \"c\" and \"z\" variable (Have different variable names)\n\ndf1 %>%\n  \n  right_join(df2, by = c(\"c\" = \"z\"))\n#>   a.x b.x   c a.y b.y  x\n#> 1   2  20 200   2  40 25\n#> 2   2  35 350   5  50 35\n#> 3   4  40 400   4  40 45\n#> 4  NA  NA 150   1  10 15\n#> 5  NA  NA 550   6  60 55\n#> 6  NA  NA 270   2  50 65"},{"path":"module-6.html","id":"full_join","chapter":"Module 6","heading":"full_join()","text":"full_join() includes observations x y:","code":"\n\n# Merging tables by the \"a\" variable\n\ndf1 %>%\n  \n  full_join(df2, by = \"a\")\n#>   a b.x   c b.y  x   z\n#> 1 1  10 100  10 15 150\n#> 2 2  20 200  40 25 200\n#> 3 2  20 200  50 65 270\n#> 4 3  30 300  NA NA  NA\n#> 5 2  35 350  40 25 200\n#> 6 2  35 350  50 65 270\n#> 7 4  40 400  40 45 400\n#> 8 5  NA  NA  50 35 350\n#> 9 6  NA  NA  60 55 550\n\n# Merging tables by the \"a\" and \"b\" variable\n\ndf1 %>%\n  \n  full_join(df2, by = c(\"a\", \"b\"))\n#>   a  b   c  x   z\n#> 1 1 10 100 15 150\n#> 2 2 20 200 NA  NA\n#> 3 3 30 300 NA  NA\n#> 4 2 35 350 NA  NA\n#> 5 4 40 400 45 400\n#> 6 2 40  NA 25 200\n#> 7 5 50  NA 35 350\n#> 8 6 60  NA 55 550\n#> 9 2 50  NA 65 270\n\n## Merging tables by the \"c\" and \"z\" variable (Have different variable names)\n\ndf1 %>%\n  \n  full_join(df2, by = c(\"c\" = \"z\"))\n#>   a.x b.x   c a.y b.y  x\n#> 1   1  10 100  NA  NA NA\n#> 2   2  20 200   2  40 25\n#> 3   3  30 300  NA  NA NA\n#> 4   2  35 350   5  50 35\n#> 5   4  40 400   4  40 45\n#> 6  NA  NA 150   1  10 15\n#> 7  NA  NA 550   6  60 55\n#> 8  NA  NA 270   2  50 65"},{"path":"module-6.html","id":"filtering-joins","chapter":"Module 6","heading":"Filtering joins","text":"Filtering joins match observations way mutating joins, affect observations, variables. two types:semi_join(x, y) - keeps observations x match yanti_join(x, y) - drops observations x match y","code":"\n\ndf1 %>%\n  \n  semi_join(df2, by = \"a\")\n#>   a  b   c\n#> 1 1 10 100\n#> 2 2 20 200\n#> 3 2 35 350\n#> 4 4 40 400\n\ndf1 %>%\n  \n  semi_join(df2, by = c(\"a\", \"b\"))\n#>   a  b   c\n#> 1 1 10 100\n#> 2 4 40 400\n\ndf1 %>%\n  \n  anti_join(df2, by = \"a\")\n#>   a  b   c\n#> 1 3 30 300\n\ndf1 %>%\n  \n  anti_join(df2, by = c(\"a\", \"b\"))\n#>   a  b   c\n#> 1 2 20 200\n#> 2 3 30 300\n#> 3 2 35 350"},{"path":"module-6.html","id":"set-operations","chapter":"Module 6","heading":"Set Operations","text":"Set operations expect x y tables variables, treat observations sets:itersect(x, y) - returns observations x yunion(x, y) - returns unique observations x ysetdiff(x, y) - returns observations x, yWe first create toy data frames apply functions :","code":"\n\ndf1 <- data.frame(\n  \n  a = c(1, 2, 3, 4, 5),\n  \n  b = c(10, 20, 30, 40, 50)\n  \n)\n\ndf1\n#>   a  b\n#> 1 1 10\n#> 2 2 20\n#> 3 3 30\n#> 4 4 40\n#> 5 5 50\n\ndf2 <- data.frame(\n  \n  a = c(1, 2, 3, 4, 5),\n  \n  b = c(10, 15, 30, 45, 65)\n  \n)\n\ndf2\n#>   a  b\n#> 1 1 10\n#> 2 2 15\n#> 3 3 30\n#> 4 4 45\n#> 5 5 65\n\nintersect(df1, df2)\n#>   a  b\n#> 1 1 10\n#> 2 3 30\n\nunion(df1, df2)\n#>   a  b\n#> 1 1 10\n#> 2 2 20\n#> 3 3 30\n#> 4 4 40\n#> 5 5 50\n#> 6 2 15\n#> 7 4 45\n#> 8 5 65\n\nsetdiff(df1, df2)\n#>   a  b\n#> 1 2 20\n#> 2 4 40\n#> 3 5 50\n\nsetdiff(df2, df1)\n#>   a  b\n#> 1 2 15\n#> 2 4 45\n#> 3 5 65"},{"path":"module-6.html","id":"practice-data-sets","chapter":"Module 6","heading":"Practice Data Sets","text":"two data sets can use practice two-table verbs:","code":"\n\ndata1 <- data.frame(\n  \n  Name = c(\"James\", \"Linda\", \"Jim\", \"Margo\", \"Nick\", \"Stacy\", \"Mary\", \"Tom\", \"Anna\", \"Bob\", \"Jeniffer\", \"Lucas\", \"Amy\"),\n  \n  Age = c(22, 56, 34, 48, 19, 25, 31, 68, 72, 42, 39, 52, 39),\n  \n  State = c(\"California\", \"New York\", \"New York\", \"California\", \"Michigan\", \"Texas\", \"Ohio\", \"Arizona\", \"Texas\", \"Florida\", \"Nebraska\", \"Indiana\", \"Florida\"),\n  \n  state_abr = c(\"CA\", \"NY\", \"NY\", \"CA\", \"MI\", \"TX\", \"OH\", \"AZ\", \"TX\", \"FL\", \"NE\", \"IN\", \"FL\"),\n  \n  City = c(\"Los Angeles\", \"New York\", \"Buffalo\", \"San Diego\", \"Detroit\", \"Austin\", \"Cleveland\", \"Phoenix\", \"Houston\", \"Tampa\", \"Lincoln\", \"Indianapolis\", \"Miami\"),\n  \n  Salary = c(30000, 96500, 72000, 59000, 54300, 25000, 61000, 64000, 74700, 40000, 83000, 92400, 82000)\n  \n)\n\ndata1\n#>        Name Age      State state_abr         City Salary\n#> 1     James  22 California        CA  Los Angeles  30000\n#> 2     Linda  56   New York        NY     New York  96500\n#> 3       Jim  34   New York        NY      Buffalo  72000\n#> 4     Margo  48 California        CA    San Diego  59000\n#> 5      Nick  19   Michigan        MI      Detroit  54300\n#> 6     Stacy  25      Texas        TX       Austin  25000\n#> 7      Mary  31       Ohio        OH    Cleveland  61000\n#> 8       Tom  68    Arizona        AZ      Phoenix  64000\n#> 9      Anna  72      Texas        TX      Houston  74700\n#> 10      Bob  42    Florida        FL        Tampa  40000\n#> 11 Jeniffer  39   Nebraska        NE      Lincoln  83000\n#> 12    Lucas  52    Indiana        IN Indianapolis  92400\n#> 13      Amy  39    Florida        FL        Miami  82000\n\ndata2 <- data.frame(\n  \n  State = c(\"Washington\", \"Florida\", \"Nebraska\", \"Indiana\", \"Florida\",\"California\", \"New York\", \"New York\", \"California\", \"Michigan\", \"Texas\", \"Ohio\", \"Arizona\", \"Utah\"),\n  \n  state_abbriviation = c(\"WA\", \"FL\", \"NE\", \"IN\", \"FL\",\"CA\", \"NY\", \"NY\", \"CA\", \"MI\", \"TX\", \"OH\", \"AZ\", \"UT\"),\n  \n  City = c( \"Seatle\", \"Tampa\", \"Lincoln\", \"Indianapolis\", \"Miami\",\"Los Angeles\", \"New York\", \"Ithaca\", \"San Francisco\", \"Detroit\", \"Dallas\", \"Cleveland\", \"Phoenix\", \"Salt Lake City\"),\n  \n  Average_salary = c(63500, 53900, 59900, 59800, 57900, 79000, 80000, 75000, 85000, 54000, 63800, 57000, 61000, 58600)\n  \n) \n\ndata2\n#>         State state_abbriviation           City\n#> 1  Washington                 WA         Seatle\n#> 2     Florida                 FL          Tampa\n#> 3    Nebraska                 NE        Lincoln\n#> 4     Indiana                 IN   Indianapolis\n#> 5     Florida                 FL          Miami\n#> 6  California                 CA    Los Angeles\n#> 7    New York                 NY       New York\n#> 8    New York                 NY         Ithaca\n#> 9  California                 CA  San Francisco\n#> 10   Michigan                 MI        Detroit\n#> 11      Texas                 TX         Dallas\n#> 12       Ohio                 OH      Cleveland\n#> 13    Arizona                 AZ        Phoenix\n#> 14       Utah                 UT Salt Lake City\n#>    Average_salary\n#> 1           63500\n#> 2           53900\n#> 3           59900\n#> 4           59800\n#> 5           57900\n#> 6           79000\n#> 7           80000\n#> 8           75000\n#> 9           85000\n#> 10          54000\n#> 11          63800\n#> 12          57000\n#> 13          61000\n#> 14          58600"},{"path":"module-7.html","id":"module-7","chapter":"Module 7","heading":"Module 7","text":" ","code":""},{"path":"module-7.html","id":"tidyr-package","chapter":"Module 7","heading":"tidyr Package","text":"Normally 80% data analysis spent cleaning preparing data. ’s just first step, must repeated many times course analysis new problems come light new data collected. module learn organize data R, organization called tidy data.principles tidy data provide standard way organize data values within dataset. tidy data standard designed facilitate initial exploration analysis data, simplify development data analysis tools work well together. Tidy datasets provide standardized way link structure dataset (physical layout) semantics (meaning).statistical datasets data frames made rows columns. dataset collection values, usually either numbers (quantitative) strings (qualitative). Values organised two ways. Every value belongs variable observation. variable contains values measure underlying attribute across units. observation contains values measured unit across attributes. instance, consider following datasets (datasets available Courseworks Module_07_data file):show data organised four different ways. dataset shows values four variables country, year, population, cases, dataset organises values different way. Even though representations underlying data, equally easy use. One dataset, tidy dataset, much easier work inside tidyverse.three interrelated rules make dataset tidy:variable must columnEach observation must rowEach value must cellThere two main advantages working tidy data:’s general advantage picking one consistent way storing data. consistent data structure, ’s easier learn tools work underlying uniformity.’s general advantage picking one consistent way storing data. consistent data structure, ’s easier learn tools work underlying uniformity.’s specific advantage placing variables columns allows R’s vectorised nature shine.’s specific advantage placing variables columns allows R’s vectorised nature shine.","code":"\n\nprint(table1)\n#> # A tibble: 6 × 4\n#>   country      year  cases population\n#>   <chr>       <int>  <int>      <int>\n#> 1 Afghanistan  1999    745   19987071\n#> 2 Afghanistan  2000   2666   20595360\n#> 3 Brazil       1999  37737  172006362\n#> 4 Brazil       2000  80488  174504898\n#> 5 China        1999 212258 1272915272\n#> 6 China        2000 213766 1280428583\n\nprint(table2)\n#> # A tibble: 12 × 4\n#>    country      year type            count\n#>    <chr>       <int> <chr>           <int>\n#>  1 Afghanistan  1999 cases             745\n#>  2 Afghanistan  1999 population   19987071\n#>  3 Afghanistan  2000 cases            2666\n#>  4 Afghanistan  2000 population   20595360\n#>  5 Brazil       1999 cases           37737\n#>  6 Brazil       1999 population  172006362\n#>  7 Brazil       2000 cases           80488\n#>  8 Brazil       2000 population  174504898\n#>  9 China        1999 cases          212258\n#> 10 China        1999 population 1272915272\n#> 11 China        2000 cases          213766\n#> 12 China        2000 population 1280428583\n\nprint(table3)\n#> # A tibble: 6 × 3\n#>   country      year rate             \n#> * <chr>       <int> <chr>            \n#> 1 Afghanistan  1999 745/19987071     \n#> 2 Afghanistan  2000 2666/20595360    \n#> 3 Brazil       1999 37737/172006362  \n#> 4 Brazil       2000 80488/174504898  \n#> 5 China        1999 212258/1272915272\n#> 6 China        2000 213766/1280428583\n\nprint(table4a) # cases\n#> # A tibble: 3 × 3\n#>   country     `1999` `2000`\n#> * <chr>        <int>  <int>\n#> 1 Afghanistan    745   2666\n#> 2 Brazil       37737  80488\n#> 3 China       212258 213766\n\nprint(table4b) # population\n#> # A tibble: 3 × 3\n#>   country         `1999`     `2000`\n#> * <chr>            <int>      <int>\n#> 1 Afghanistan   19987071   20595360\n#> 2 Brazil       172006362  174504898\n#> 3 China       1272915272 1280428583"},{"path":"module-7.html","id":"pivoting","chapter":"Module 7","heading":"Pivoting","text":"","code":""},{"path":"module-7.html","id":"pivot_longer-function","chapter":"Module 7","heading":"pivot_longer() function","text":"Unfortunately, data encounter untidy. example, consider table4a:dataset column names names variables, values variable. Specifically, column names 1999 2000 represent values year variable, values 1999 2000 columns represent values cases variable, row represents two observations, one.tidy dataset like , need pivot offending columns new pair variables. describe operation need three parameters:set columns whose names values, variables. example, columns 1999 2000The name variable move column names . yearThe name variable move column values . ’s casesTogether parameters generate call pivot_longer() function:Let’s repeat procedure table4b:Now let’s put together create complete dataset:","code":"\n\nprint(table4a) # cases\n#> # A tibble: 3 × 3\n#>   country     `1999` `2000`\n#> * <chr>        <int>  <int>\n#> 1 Afghanistan    745   2666\n#> 2 Brazil       37737  80488\n#> 3 China       212258 213766\n\ntable4a %>% \n  \n  pivot_longer(c(`1999`, `2000`), names_to = \"year\", values_to = \"cases\")\n#> # A tibble: 6 × 3\n#>   country     year   cases\n#>   <chr>       <chr>  <int>\n#> 1 Afghanistan 1999     745\n#> 2 Afghanistan 2000    2666\n#> 3 Brazil      1999   37737\n#> 4 Brazil      2000   80488\n#> 5 China       1999  212258\n#> 6 China       2000  213766\n\ntable4b %>%\n  \n  pivot_longer(c(`1999`, `2000`), names_to = \"year\", values_to = \"population\")\n#> # A tibble: 6 × 3\n#>   country     year  population\n#>   <chr>       <chr>      <int>\n#> 1 Afghanistan 1999    19987071\n#> 2 Afghanistan 2000    20595360\n#> 3 Brazil      1999   172006362\n#> 4 Brazil      2000   174504898\n#> 5 China       1999  1272915272\n#> 6 China       2000  1280428583\n\ntidy4a <- table4a %>% \n  \n  pivot_longer(c(`1999`, `2000`), names_to = \"year\", values_to = \"cases\")\n\n\n\ntidy4b <- table4b %>% \n  \n  pivot_longer(c(`1999`, `2000`), names_to = \"year\", values_to = \"population\")\n\n\ntidy_4a_4b <- left_join(tidy4a, tidy4b)\n#> Joining, by = c(\"country\", \"year\")\n\nprint(tidy_4a_4b)\n#> # A tibble: 6 × 4\n#>   country     year   cases population\n#>   <chr>       <chr>  <int>      <int>\n#> 1 Afghanistan 1999     745   19987071\n#> 2 Afghanistan 2000    2666   20595360\n#> 3 Brazil      1999   37737  172006362\n#> 4 Brazil      2000   80488  174504898\n#> 5 China       1999  212258 1272915272\n#> 6 China       2000  213766 1280428583"},{"path":"module-7.html","id":"pivot_wider-function","chapter":"Module 7","heading":"pivot_wider() function","text":"pivot_wider() opposite pivot_longer(). use observation scattered across multiple rows. instance, table2 observation country year, observation spread across two rows:tidy , need two parameters:column take variable names . , ’s typeThe column take values . ’s count","code":"\n\nprint(table2)\n#> # A tibble: 12 × 4\n#>    country      year type            count\n#>    <chr>       <int> <chr>           <int>\n#>  1 Afghanistan  1999 cases             745\n#>  2 Afghanistan  1999 population   19987071\n#>  3 Afghanistan  2000 cases            2666\n#>  4 Afghanistan  2000 population   20595360\n#>  5 Brazil       1999 cases           37737\n#>  6 Brazil       1999 population  172006362\n#>  7 Brazil       2000 cases           80488\n#>  8 Brazil       2000 population  174504898\n#>  9 China        1999 cases          212258\n#> 10 China        1999 population 1272915272\n#> 11 China        2000 cases          213766\n#> 12 China        2000 population 1280428583\n\ntable2 %>%\n  \n  pivot_wider(names_from = type, values_from = count)\n#> # A tibble: 6 × 4\n#>   country      year  cases population\n#>   <chr>       <int>  <int>      <int>\n#> 1 Afghanistan  1999    745   19987071\n#> 2 Afghanistan  2000   2666   20595360\n#> 3 Brazil       1999  37737  172006362\n#> 4 Brazil       2000  80488  174504898\n#> 5 China        1999 212258 1272915272\n#> 6 China        2000 213766 1280428583"},{"path":"module-7.html","id":"separating-and-uniting","chapter":"Module 7","heading":"Separating and Uniting","text":"","code":""},{"path":"module-7.html","id":"separate-function","chapter":"Module 7","heading":"separate() Function","text":"separate() pulls apart one column multiple columns, splitting wherever separator character appears. example, table3 rate column contains cases population variables, need split two variables:separate() takes name column separate, names columns separate well specific character separate column:separate() leaves type column . However, can ask try convert better types using convert = TRUE:can also pass vector integers sep. separate() interpret integers positions split . Positive values start 1 far-left strings; negative value start -1 far-right strings. examples:","code":"\n\nprint(table3)\n#> # A tibble: 6 × 3\n#>   country      year rate             \n#> * <chr>       <int> <chr>            \n#> 1 Afghanistan  1999 745/19987071     \n#> 2 Afghanistan  2000 2666/20595360    \n#> 3 Brazil       1999 37737/172006362  \n#> 4 Brazil       2000 80488/174504898  \n#> 5 China        1999 212258/1272915272\n#> 6 China        2000 213766/1280428583\n\ntable3 %>%\n  \n  separate(rate, into = c(\"cases\", \"population\"), sep = \"/\")\n#> # A tibble: 6 × 4\n#>   country      year cases  population\n#>   <chr>       <int> <chr>  <chr>     \n#> 1 Afghanistan  1999 745    19987071  \n#> 2 Afghanistan  2000 2666   20595360  \n#> 3 Brazil       1999 37737  172006362 \n#> 4 Brazil       2000 80488  174504898 \n#> 5 China        1999 212258 1272915272\n#> 6 China        2000 213766 1280428583\n\ntable3 %>% \n  \n  separate(rate, into = c(\"cases\", \"population\"), convert = TRUE)\n#> # A tibble: 6 × 4\n#>   country      year  cases population\n#>   <chr>       <int>  <int>      <int>\n#> 1 Afghanistan  1999    745   19987071\n#> 2 Afghanistan  2000   2666   20595360\n#> 3 Brazil       1999  37737  172006362\n#> 4 Brazil       2000  80488  174504898\n#> 5 China        1999 212258 1272915272\n#> 6 China        2000 213766 1280428583\n\ntable3 %>% \n  \n  separate(year, into = c(\"century\", \"year\"), sep = 2)\n#> # A tibble: 6 × 4\n#>   country     century year  rate             \n#>   <chr>       <chr>   <chr> <chr>            \n#> 1 Afghanistan 19      99    745/19987071     \n#> 2 Afghanistan 20      00    2666/20595360    \n#> 3 Brazil      19      99    37737/172006362  \n#> 4 Brazil      20      00    80488/174504898  \n#> 5 China       19      99    212258/1272915272\n#> 6 China       20      00    213766/1280428583\n\ntable3 %>% \n  \n  separate(year, into = c(\"century\", \"year\"), sep = 3)\n#> # A tibble: 6 × 4\n#>   country     century year  rate             \n#>   <chr>       <chr>   <chr> <chr>            \n#> 1 Afghanistan 199     9     745/19987071     \n#> 2 Afghanistan 200     0     2666/20595360    \n#> 3 Brazil      199     9     37737/172006362  \n#> 4 Brazil      200     0     80488/174504898  \n#> 5 China       199     9     212258/1272915272\n#> 6 China       200     0     213766/1280428583\n\ntable3 %>% \n  \n  separate(year, into = c(\"century\", \"year\"), sep = -3)\n#> # A tibble: 6 × 4\n#>   country     century year  rate             \n#>   <chr>       <chr>   <chr> <chr>            \n#> 1 Afghanistan 1       999   745/19987071     \n#> 2 Afghanistan 2       000   2666/20595360    \n#> 3 Brazil      1       999   37737/172006362  \n#> 4 Brazil      2       000   80488/174504898  \n#> 5 China       1       999   212258/1272915272\n#> 6 China       2       000   213766/1280428583"},{"path":"module-7.html","id":"unite-function","chapter":"Module 7","heading":"unite() Function","text":"unite() inverse separate(): combines multiple columns single column. can use unite() rejoin century year columns table5:unite() takes data frame, name new variable create, set columns combine:default place underscore _ values different columns. Use sep argument specify columns merged:","code":"\n\nprint(table5)\n#> # A tibble: 6 × 4\n#>   country     century year  rate             \n#> * <chr>       <chr>   <chr> <chr>            \n#> 1 Afghanistan 19      99    745/19987071     \n#> 2 Afghanistan 20      00    2666/20595360    \n#> 3 Brazil      19      99    37737/172006362  \n#> 4 Brazil      20      00    80488/174504898  \n#> 5 China       19      99    212258/1272915272\n#> 6 China       20      00    213766/1280428583\n\ntable5 %>% \n  \n  unite(new, century, year)\n#> # A tibble: 6 × 3\n#>   country     new   rate             \n#>   <chr>       <chr> <chr>            \n#> 1 Afghanistan 19_99 745/19987071     \n#> 2 Afghanistan 20_00 2666/20595360    \n#> 3 Brazil      19_99 37737/172006362  \n#> 4 Brazil      20_00 80488/174504898  \n#> 5 China       19_99 212258/1272915272\n#> 6 China       20_00 213766/1280428583\n\ntable5 %>% \n  \n  unite(new, century, year, sep = \"\")\n#> # A tibble: 6 × 3\n#>   country     new   rate             \n#>   <chr>       <chr> <chr>            \n#> 1 Afghanistan 1999  745/19987071     \n#> 2 Afghanistan 2000  2666/20595360    \n#> 3 Brazil      1999  37737/172006362  \n#> 4 Brazil      2000  80488/174504898  \n#> 5 China       1999  212258/1272915272\n#> 6 China       2000  213766/1280428583"},{"path":"module-7.html","id":"missing-values","chapter":"Module 7","heading":"Missing Values","text":"value can missing one two possible ways:Explicitly - flagged NAImplicitly - simply present dataConsider following dataset:two missing values dataset:return fourth quarter 2015 explicitly missing, cell value instead contains NAThe return first quarter 2016 implicitly missing, simply appear datasetWe can make implicit missing values explicit. One way using pivot_wider() function:can simply use complete() function. takes set columns, finds unique combinations. ensures original dataset contains values, filling explicit NAs necessary:can fill missing values fill(). takes set columns want missing values replaced recent non-missing value (sometimes called last observation carried forward):can change direction fill missing values. instance, let’s fill missing values value comes right missing values:replace_na() function allows replace missing values specific values:Finally, can drop missing values dataset:","code":"\n\nstocks <- data.frame(\n  \n  year   = c(2015, 2015, 2015, 2015, 2016, 2016, 2016),\n  \n  qtr    = c(   1,    2,    3,    4,    2,    3,    4),\n  \n  return = c(1.88, 0.59, 0.35,   NA, 0.92, 0.17, 2.66)\n)\n\nprint(stocks)\n#>   year qtr return\n#> 1 2015   1   1.88\n#> 2 2015   2   0.59\n#> 3 2015   3   0.35\n#> 4 2015   4     NA\n#> 5 2016   2   0.92\n#> 6 2016   3   0.17\n#> 7 2016   4   2.66\n\nstocks %>% \n  \n  pivot_wider(names_from = year, values_from = return)\n#> # A tibble: 4 × 3\n#>     qtr `2015` `2016`\n#>   <dbl>  <dbl>  <dbl>\n#> 1     1   1.88  NA   \n#> 2     2   0.59   0.92\n#> 3     3   0.35   0.17\n#> 4     4  NA      2.66\n\nstocks %>% \n  \n  complete(year, qtr)\n#> # A tibble: 8 × 3\n#>    year   qtr return\n#>   <dbl> <dbl>  <dbl>\n#> 1  2015     1   1.88\n#> 2  2015     2   0.59\n#> 3  2015     3   0.35\n#> 4  2015     4  NA   \n#> 5  2016     1  NA   \n#> 6  2016     2   0.92\n#> 7  2016     3   0.17\n#> 8  2016     4   2.66\n\nstocks %>% \n  \n  complete(year, qtr) %>%\n  \n  fill(return)\n#> # A tibble: 8 × 3\n#>    year   qtr return\n#>   <dbl> <dbl>  <dbl>\n#> 1  2015     1   1.88\n#> 2  2015     2   0.59\n#> 3  2015     3   0.35\n#> 4  2015     4   0.35\n#> 5  2016     1   0.35\n#> 6  2016     2   0.92\n#> 7  2016     3   0.17\n#> 8  2016     4   2.66\n\nstocks %>% \n  \n  complete(year, qtr) %>%\n  \n  fill(return, .direction = \"up\")\n#> # A tibble: 8 × 3\n#>    year   qtr return\n#>   <dbl> <dbl>  <dbl>\n#> 1  2015     1   1.88\n#> 2  2015     2   0.59\n#> 3  2015     3   0.35\n#> 4  2015     4   0.92\n#> 5  2016     1   0.92\n#> 6  2016     2   0.92\n#> 7  2016     3   0.17\n#> 8  2016     4   2.66\n\nstocks %>% \n  \n  complete(year, qtr) %>%\n  \n  replace_na(list(return = 0))\n#> # A tibble: 8 × 3\n#>    year   qtr return\n#>   <dbl> <dbl>  <dbl>\n#> 1  2015     1   1.88\n#> 2  2015     2   0.59\n#> 3  2015     3   0.35\n#> 4  2015     4   0   \n#> 5  2016     1   0   \n#> 6  2016     2   0.92\n#> 7  2016     3   0.17\n#> 8  2016     4   2.66\n\nstocks %>% \n  \n  complete(year, qtr) %>%\n  \n  drop_na()\n#> # A tibble: 6 × 3\n#>    year   qtr return\n#>   <dbl> <dbl>  <dbl>\n#> 1  2015     1   1.88\n#> 2  2015     2   0.59\n#> 3  2015     3   0.35\n#> 4  2016     2   0.92\n#> 5  2016     3   0.17\n#> 6  2016     4   2.66"},{"path":"module-7.html","id":"lets-practice","chapter":"Module 7","heading":"Let’s Practice","text":"datasets practice tidyr functions . addition, can find examples function can utilized. Try understand function . datasets available Courseworks (Module_07_data file).","code":""},{"path":"module-7.html","id":"relationship-between-income-and-religion-in-the-us","chapter":"Module 7","heading":"Relationship between Income and Religion in the US","text":"","code":"\n\nrelig_income %>% \n  \n  pivot_longer(-religion, names_to = \"income\", values_to = \"frequency\")\n#> # A tibble: 180 × 3\n#>    religion income             frequency\n#>    <chr>    <chr>                  <dbl>\n#>  1 Agnostic <$10k                     27\n#>  2 Agnostic $10-20k                   34\n#>  3 Agnostic $20-30k                   60\n#>  4 Agnostic $30-40k                   81\n#>  5 Agnostic $40-50k                   76\n#>  6 Agnostic $50-75k                  137\n#>  7 Agnostic $75-100k                 122\n#>  8 Agnostic $100-150k                109\n#>  9 Agnostic >150k                     84\n#> 10 Agnostic Don't know/refused        96\n#> # … with 170 more rows"},{"path":"module-7.html","id":"tuberculosis-data-from-world-health-organization-who","chapter":"Module 7","heading":"Tuberculosis data from World Health Organization (WHO)","text":"","code":"\n\nwho1 <- who %>%\n  \n    pivot_longer(\n    \n    cols = new_sp_m014:newrel_f65,\n    \n    names_to = \"key\",\n    \n    values_to = \"cases\", \n    \n    values_drop_na = TRUE)\n\nprint(who1)\n#> # A tibble: 76,046 × 6\n#>    country     iso2  iso3   year key          cases\n#>    <chr>       <chr> <chr> <int> <chr>        <int>\n#>  1 Afghanistan AF    AFG    1997 new_sp_m014      0\n#>  2 Afghanistan AF    AFG    1997 new_sp_m1524    10\n#>  3 Afghanistan AF    AFG    1997 new_sp_m2534     6\n#>  4 Afghanistan AF    AFG    1997 new_sp_m3544     3\n#>  5 Afghanistan AF    AFG    1997 new_sp_m4554     5\n#>  6 Afghanistan AF    AFG    1997 new_sp_m5564     2\n#>  7 Afghanistan AF    AFG    1997 new_sp_m65       0\n#>  8 Afghanistan AF    AFG    1997 new_sp_f014      5\n#>  9 Afghanistan AF    AFG    1997 new_sp_f1524    38\n#> 10 Afghanistan AF    AFG    1997 new_sp_f2534    36\n#> # … with 76,036 more rows\n\n## just run this code\n\nwho2 <- who1 %>% \n  \n  mutate(key = stringr::str_replace(key, \"newrel\", \"new_rel\"))\n\nwho3 <- who2 %>% \n  \n  separate(key, c(\"new\", \"type\", \"sexage\"), sep = \"_\")\n\nprint(who3)\n#> # A tibble: 76,046 × 8\n#>    country     iso2  iso3   year new   type  sexage cases\n#>    <chr>       <chr> <chr> <int> <chr> <chr> <chr>  <int>\n#>  1 Afghanistan AF    AFG    1997 new   sp    m014       0\n#>  2 Afghanistan AF    AFG    1997 new   sp    m1524     10\n#>  3 Afghanistan AF    AFG    1997 new   sp    m2534      6\n#>  4 Afghanistan AF    AFG    1997 new   sp    m3544      3\n#>  5 Afghanistan AF    AFG    1997 new   sp    m4554      5\n#>  6 Afghanistan AF    AFG    1997 new   sp    m5564      2\n#>  7 Afghanistan AF    AFG    1997 new   sp    m65        0\n#>  8 Afghanistan AF    AFG    1997 new   sp    f014       5\n#>  9 Afghanistan AF    AFG    1997 new   sp    f1524     38\n#> 10 Afghanistan AF    AFG    1997 new   sp    f2534     36\n#> # … with 76,036 more rows\n\nwho4 <- who3 %>%\n  \n  separate(sexage, c(\"sex\", \"age\"), sep = 1)\n\nprint(who4)\n#> # A tibble: 76,046 × 9\n#>    country   iso2  iso3   year new   type  sex   age   cases\n#>    <chr>     <chr> <chr> <int> <chr> <chr> <chr> <chr> <int>\n#>  1 Afghanis… AF    AFG    1997 new   sp    m     014       0\n#>  2 Afghanis… AF    AFG    1997 new   sp    m     1524     10\n#>  3 Afghanis… AF    AFG    1997 new   sp    m     2534      6\n#>  4 Afghanis… AF    AFG    1997 new   sp    m     3544      3\n#>  5 Afghanis… AF    AFG    1997 new   sp    m     4554      5\n#>  6 Afghanis… AF    AFG    1997 new   sp    m     5564      2\n#>  7 Afghanis… AF    AFG    1997 new   sp    m     65        0\n#>  8 Afghanis… AF    AFG    1997 new   sp    f     014       5\n#>  9 Afghanis… AF    AFG    1997 new   sp    f     1524     38\n#> 10 Afghanis… AF    AFG    1997 new   sp    f     2534     36\n#> # … with 76,036 more rows"},{"path":"module-7.html","id":"billboard-charts-data","chapter":"Module 7","heading":"Billboard charts data","text":"","code":"\n\nbillboard2 <- billboard %>% \n  \n  pivot_longer(\n    \n    cols = starts_with(\"wk\"), \n    \n    names_to = \"week\",\n    \n    values_to = \"rank\", \n    \n    values_drop_na = TRUE)\n\nprint(billboard2)\n#> # A tibble: 5,307 × 5\n#>    artist  track                   date.entered week   rank\n#>    <chr>   <chr>                   <date>       <chr> <dbl>\n#>  1 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk1      87\n#>  2 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk2      82\n#>  3 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk3      72\n#>  4 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk4      77\n#>  5 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk5      87\n#>  6 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk6      94\n#>  7 2 Pac   Baby Don't Cry (Keep... 2000-02-26   wk7      99\n#>  8 2Ge+her The Hardest Part Of ... 2000-09-02   wk1      91\n#>  9 2Ge+her The Hardest Part Of ... 2000-09-02   wk2      87\n#> 10 2Ge+her The Hardest Part Of ... 2000-09-02   wk3      92\n#> # … with 5,297 more rows\n\nbillboard3 <- billboard %>% \n  \n  pivot_longer(\n    \n    cols = starts_with(\"wk\"), \n    \n    names_to = \"week\",\n    \n    names_prefix = \"wk\",\n    \n    names_transform = as.integer,\n    \n    values_to = \"rank\", \n    \n    values_drop_na = TRUE)\n\n\nprint(billboard3)\n#> # A tibble: 5,307 × 5\n#>    artist  track                   date.entered  week  rank\n#>    <chr>   <chr>                   <date>       <int> <dbl>\n#>  1 2 Pac   Baby Don't Cry (Keep... 2000-02-26       1    87\n#>  2 2 Pac   Baby Don't Cry (Keep... 2000-02-26       2    82\n#>  3 2 Pac   Baby Don't Cry (Keep... 2000-02-26       3    72\n#>  4 2 Pac   Baby Don't Cry (Keep... 2000-02-26       4    77\n#>  5 2 Pac   Baby Don't Cry (Keep... 2000-02-26       5    87\n#>  6 2 Pac   Baby Don't Cry (Keep... 2000-02-26       6    94\n#>  7 2 Pac   Baby Don't Cry (Keep... 2000-02-26       7    99\n#>  8 2Ge+her The Hardest Part Of ... 2000-09-02       1    91\n#>  9 2Ge+her The Hardest Part Of ... 2000-09-02       2    87\n#> 10 2Ge+her The Hardest Part Of ... 2000-09-02       3    92\n#> # … with 5,297 more rows\n\nbillboard3 %>%\n  \n  arrange(artist, track, week)\n#> # A tibble: 5,307 × 5\n#>    artist  track                   date.entered  week  rank\n#>    <chr>   <chr>                   <date>       <int> <dbl>\n#>  1 2 Pac   Baby Don't Cry (Keep... 2000-02-26       1    87\n#>  2 2 Pac   Baby Don't Cry (Keep... 2000-02-26       2    82\n#>  3 2 Pac   Baby Don't Cry (Keep... 2000-02-26       3    72\n#>  4 2 Pac   Baby Don't Cry (Keep... 2000-02-26       4    77\n#>  5 2 Pac   Baby Don't Cry (Keep... 2000-02-26       5    87\n#>  6 2 Pac   Baby Don't Cry (Keep... 2000-02-26       6    94\n#>  7 2 Pac   Baby Don't Cry (Keep... 2000-02-26       7    99\n#>  8 2Ge+her The Hardest Part Of ... 2000-09-02       1    91\n#>  9 2Ge+her The Hardest Part Of ... 2000-09-02       2    87\n#> 10 2Ge+her The Hardest Part Of ... 2000-09-02       3    92\n#> # … with 5,297 more rows"},{"path":"problem-set-2.html","id":"problem-set-2","chapter":"Problem Set 2","heading":"Problem Set 2","text":" working datasets containing demographic information midwest counties 2000 US census. Dataset_1, Dataset_2, Dataset_3 available Courseworks. Dataset_1 contains following variables:PID - Unique county identifiercounty - County namearea - Area county (units unknown). variable spread across 5 columns (IL - WI)poptotal - Total populationstate - State county belongs  Dataset_2 contains following variables:PID - Unique county identifiercounty - County namerace - Total population racial group (White, Black, American Indians, Asians, races)inmetro - factor levels 0 1 indicate whether county considered metro areacategory - Miscellaneous Dataset_3 contains following variables:PID - Unique county identifiercounty - County namepopadults - Number adultsperchsd - Percent population high school diplomapercollege - Percent college educated populationpercprof - Percent population professional degreepercbelowpoverty - Percent population poverty linepercchildbelowpovert - Percent children poverty linepercadultpoverty - Percent adults poverty linepercelderlypoverty - Percent elderly poverty line Note: original description dataset documented current descriptions (provided tidyverse package) based speculation. ","code":""},{"path":"problem-set-2.html","id":"problem-1-2","chapter":"Problem Set 2","heading":"Problem 1","text":"Dataset_1 area variable spread across multiple columns represent values state variable. Transform/Tidy dataset follows: move column names (IL-WI) state variable column values area variable. , remove missing value dataset. Name new dataset data1. Dataset_2 race variable combines information total population racial group, given following order: White, Black, American Indians, Asians, . Pull apart column multiple columns, splitting wherever separator character appers. Name variables popwhite, popblack, popamerindian, popasian, popother, respectively. Name new dataset data2. Merge data1 data2: joined state variable output result contain observation data1, regardless whether match . dimensions output? many missing values contain?\nRepeat procedure joining datasets state county variables.Merge data1 data2: joined state variable output result contain observation data1, regardless whether match . dimensions output? many missing values contain?Repeat procedure joining datasets state county variables. Merge data1 data2: joined state variable output result contain observation data2, regardless whether match . dimensions output? many missing values contain?\nRepeat procedure joining datasets state county variables.Merge data1 data2: joined state variable output result contain observation data2, regardless whether match . dimensions output? many missing values contain?Repeat procedure joining datasets state county variables. Merge data1 data2: joined state variable output result contain observation data1 data2, regardless whether match . dimensions output? many missing values contain?\nRepeat procedure joining datasets state county variables.Merge data1 data2: joined state variable output result contain observation data1 data2, regardless whether match . dimensions output? many missing values contain?Repeat procedure joining datasets state county variables. Join data1 data2 state county variables unmatched rows either input dataset included result. Name output dataset data. Remove PID category data selecting variables except two. , remove duplicates dataset. Add new variable dataset (name popdensity), represents population density county (order compute population density need divide total population corresponding area).\n, racial group, add new variable dataset represent percentage total population belongs group (name percwhite, percblack, percamerindan, percasian, percother, respectively).Add new variable dataset (name popdensity), represents population density county (order compute population density need divide total population corresponding area)., racial group, add new variable dataset represent percentage total population belongs group (name percwhite, percblack, percamerindan, percasian, percother, respectively). Join data Dataset_3 state county variables unmatched rows either input dataset included result. Add new variables dataset correspond percbelowpoverty percadultpoverty variables represent actual number people belong groups. Name variables popcbelowpoverty, popcadultpoverty, respectively. Move inmetro variable end dataset; change position poptotal variable comes area variables; change position popdensity variable comes poptotal variables. biggest/smallest state total population? biggest/smallest state total area? average population density state? state, compare population densities counties metro area counties . Hint: might want use grouping functions. states combined, average percentage racial group? state separately, average percentage racial group? state separately, compare average percentage racial group metro areas non-metro areas. Discuss results obtained. , state calculate average percentage total population poverty. Now using measurement, compare metro areas non-metro areas state. observe? Now filter counties less 50000 population repeat previous step. observe?","code":""},{"path":"ps-2-solutions.html","id":"ps-2-solutions","chapter":"PS 2 Solutions","heading":"PS 2 Solutions","text":"  Dataset_1 area variable spread across multiple columns represent values state variable. Transform/Tidy dataset follows: move column names (IL-WI) state variable column values area variable. , remove missing value dataset. Name new dataset data1. Dataset_2 race variable combines information total population racial group, given following order: White, Black, American Indians, Asians, . Pull apart column multiple columns, splitting wherever separator character appers. Name variables popwhite, popblack, popamerindian, popasian, popother, respectively. Name new dataset data2. Merge data1 data2: joined state variable output result contain observation data1, regardless whether match . dimensions output? many missing values contain?\nRepeat procedure joining datasets state county variables.Merge data1 data2: joined state variable output result contain observation data1, regardless whether match . dimensions output? many missing values contain?Repeat procedure joining datasets state county variables. Merge data1 data2: joined state variable output result contain observation data2, regardless whether match . dimensions output? many missing values contain?\nRepeat procedure joining datasets state county variables.Merge data1 data2: joined state variable output result contain observation data2, regardless whether match . dimensions output? many missing values contain?Repeat procedure joining datasets state county variables. Merge data1 data2: joined state variable output result contain observation data1 data2, regardless whether match . dimensions output? many missing values contain?\nRepeat procedure joining datasets state county variables.Merge data1 data2: joined state variable output result contain observation data1 data2, regardless whether match . dimensions output? many missing values contain?Repeat procedure joining datasets state county variables. Join data1 data2 state county variables unmatched rows either input dataset included result. Name output dataset data. Remove PID category data selecting variables except two. , remove duplicates dataset. Add new variable dataset (name popdensity), represents population density county (order compute population density need divide total population corresponding area).\n, racial group, add new variable dataset represent percentage total population belongs group (name percwhite, percblack, percamerindan, percasian, percother, respectively).Add new variable dataset (name popdensity), represents population density county (order compute population density need divide total population corresponding area)., racial group, add new variable dataset represent percentage total population belongs group (name percwhite, percblack, percamerindan, percasian, percother, respectively). Join data Dataset_3 state county variables unmatched rows either input dataset included result. Add new variables dataset correspond percbelowpoverty percadultpoverty variables represent actual number people belong groups. Name variables popcbelowpoverty, popcadultpoverty, respectively. Move inmetro variable end dataset; change position poptotal variable comes area variables; change position popdensity variable comes poptotal variables. biggest/smallest state total population? biggest/smallest state total area? average population density state? state, compare population densities counties metro area counties . Hint: might want use grouping functions.state minimum total population “WI”, state maximum total population “IL”.state minimum total area “”, state maximum total area “MI”. states combined, average percentage racial group? state separately, average percentage racial group? state separately, compare average percentage racial group metro areas non-metro areas. Discuss results obtained.Percentages white higher non-metro area. Percentages black higher metro area. Percentages American indian higher non-metro area. Percentages Asian higher metro area. Percentages race groups higher metro area. , state calculate average percentage total population poverty. Now using measurement, compare metro areas non-metro areas state. observe? Now filter counties less 50000 population repeat previous step. observe?Percentages poverty higher non-metro area.significance percentages -poverty non-metro area higher metro area becomes less.","code":"\n\nlibrary(tidyverse)\n#> ── Attaching packages ─────────────────── tidyverse 1.3.2 ──\n#> ✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n#> ✔ tibble  3.1.8      ✔ dplyr   1.0.10\n#> ✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n#> ✔ readr   2.1.3      ✔ forcats 0.5.2 \n#> ── Conflicts ────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n\nDataset_1 <- as_tibble(read.csv(\"C:/Users/alexp/OneDrive/Desktop/R Bootcamp/R_bootcamp/Dataset_1.csv\"))\n\nDataset_2 <- as_tibble(read.csv(\"C:/Users/alexp/OneDrive/Desktop/R Bootcamp/R_bootcamp/Dataset_2.csv\"))\n\nDataset_3 <- as_tibble(read.csv(\"C:/Users/alexp/OneDrive/Desktop/R Bootcamp/R_bootcamp/Dataset_3.csv\"))\n\ndata1 <- Dataset_1 %>%\n  pivot_longer(IL:WI, names_to=\"state\", values_to=\"area\", values_drop_na=T)\ndata1\n#> # A tibble: 457 × 5\n#>      PID county    poptotal state  area\n#>    <int> <chr>        <int> <chr> <dbl>\n#>  1   561 ADAMS        66090 IL    0.052\n#>  2   562 ALEXANDER    10626 IL    0.014\n#>  3   563 BOND         14991 IL    0.022\n#>  4   564 BOONE        30806 IL    0.017\n#>  5   565 BROWN         5836 IL    0.018\n#>  6   566 BUREAU       35688 IL    0.05 \n#>  7   567 CALHOUN       5322 IL    0.017\n#>  8   568 CARROLL      16805 IL    0.027\n#>  9   569 CASS         13437 IL    0.024\n#> 10   570 CHAMPAIGN   173025 IL    0.058\n#> # … with 447 more rows\ndata2 <- Dataset_2 %>%\n  separate(race, into=c(\"popwhite\", \"popblack\", \"popamerindian\", \"popasian\", \"popother\"), sep=\"/\", convert=T)\ndata2\n#> # A tibble: 487 × 9\n#>    county    state popwhite popblack popam…¹ popas…² popot…³\n#>    <chr>     <chr>    <int>    <int>   <int>   <int>   <int>\n#>  1 ADAMS     IL       63917     1702      98     249     124\n#>  2 ALEXANDER IL        7054     3496      19      48       9\n#>  3 BOND      IL       14477      429      35      16      34\n#>  4 BOONE     IL       29344      127      46     150    1139\n#>  5 BROWN     IL        5264      547      14       5       6\n#>  6 BUREAU    IL       35157       50      65     195     221\n#>  7 CALHOUN   IL        5298        1       8      15       0\n#>  8 CARROLL   IL       16519      111      30      61      84\n#>  9 CASS      IL       13384       16       8      23       6\n#> 10 CHAMPAIGN IL      146506    16559     331    8033    1596\n#> # … with 477 more rows, 2 more variables: inmetro <int>,\n#> #   category <chr>, and abbreviated variable names\n#> #   ¹​popamerindian, ²​popasian, ³​popother\nout3_1 <- data1 %>%\n  left_join(data2, by=\"state\")\nout3_1\n#> # A tibble: 46,825 × 13\n#>      PID count…¹ popto…² state  area count…³ popwh…⁴ popbl…⁵\n#>    <int> <chr>     <int> <chr> <dbl> <chr>     <int>   <int>\n#>  1   561 ADAMS     66090 IL    0.052 ADAMS     63917    1702\n#>  2   561 ADAMS     66090 IL    0.052 ALEXAN…    7054    3496\n#>  3   561 ADAMS     66090 IL    0.052 BOND      14477     429\n#>  4   561 ADAMS     66090 IL    0.052 BOONE     29344     127\n#>  5   561 ADAMS     66090 IL    0.052 BROWN      5264     547\n#>  6   561 ADAMS     66090 IL    0.052 BUREAU    35157      50\n#>  7   561 ADAMS     66090 IL    0.052 CALHOUN    5298       1\n#>  8   561 ADAMS     66090 IL    0.052 CARROLL   16519     111\n#>  9   561 ADAMS     66090 IL    0.052 CASS      13384      16\n#> 10   561 ADAMS     66090 IL    0.052 CHAMPA…  146506   16559\n#> # … with 46,815 more rows, 5 more variables:\n#> #   popamerindian <int>, popasian <int>, popother <int>,\n#> #   inmetro <int>, category <chr>, and abbreviated variable\n#> #   names ¹​county.x, ²​poptotal, ³​county.y, ⁴​popwhite,\n#> #   ⁵​popblack\ndim_desc(out3_1)\n#> [1] \"[46,825 x 13]\"\nout3_1 %>%\n  summarize(across(everything(), ~sum(is.na(.))))\n#> # A tibble: 1 × 13\n#>     PID county.x popto…¹ state  area count…² popwh…³ popbl…⁴\n#>   <int>    <int>   <int> <int> <int>   <int>   <int>   <int>\n#> 1     0        0       0     0     0       0       0       0\n#> # … with 5 more variables: popamerindian <int>,\n#> #   popasian <int>, popother <int>, inmetro <int>,\n#> #   category <int>, and abbreviated variable names\n#> #   ¹​poptotal, ²​county.y, ³​popwhite, ⁴​popblack\nout3_2 <- data1 %>%\n  left_join(data2, by=c(\"state\", \"county\"))\nout3_2\n#> # A tibble: 527 × 12\n#>      PID county  popto…¹ state  area popwh…² popbl…³ popam…⁴\n#>    <int> <chr>     <int> <chr> <dbl>   <int>   <int>   <int>\n#>  1   561 ADAMS     66090 IL    0.052   63917    1702      98\n#>  2   561 ADAMS     66090 IL    0.052   63917    1702      98\n#>  3   562 ALEXAN…   10626 IL    0.014    7054    3496      19\n#>  4   562 ALEXAN…   10626 IL    0.014    7054    3496      19\n#>  5   563 BOND      14991 IL    0.022   14477     429      35\n#>  6   563 BOND      14991 IL    0.022   14477     429      35\n#>  7   564 BOONE     30806 IL    0.017   29344     127      46\n#>  8   564 BOONE     30806 IL    0.017   29344     127      46\n#>  9   565 BROWN      5836 IL    0.018    5264     547      14\n#> 10   565 BROWN      5836 IL    0.018    5264     547      14\n#> # … with 517 more rows, 4 more variables: popasian <int>,\n#> #   popother <int>, inmetro <int>, category <chr>, and\n#> #   abbreviated variable names ¹​poptotal, ²​popwhite,\n#> #   ³​popblack, ⁴​popamerindian\ndim_desc(out3_2)\n#> [1] \"[527 x 12]\"\nout3_2 %>%\n  summarize(across(everything(), ~sum(is.na(.))))\n#> # A tibble: 1 × 12\n#>     PID county poptotal state  area popwhite popbl…¹ popam…²\n#>   <int>  <int>    <int> <int> <int>    <int>   <int>   <int>\n#> 1     0      0        0     0     0        0       0       0\n#> # … with 4 more variables: popasian <int>, popother <int>,\n#> #   inmetro <int>, category <int>, and abbreviated variable\n#> #   names ¹​popblack, ²​popamerindian\nout4_1 <- data1 %>%\n  right_join(data2, by=\"state\")\nout4_1\n#> # A tibble: 46,825 × 13\n#>      PID count…¹ popto…² state  area count…³ popwh…⁴ popbl…⁵\n#>    <int> <chr>     <int> <chr> <dbl> <chr>     <int>   <int>\n#>  1   561 ADAMS     66090 IL    0.052 ADAMS     63917    1702\n#>  2   561 ADAMS     66090 IL    0.052 ALEXAN…    7054    3496\n#>  3   561 ADAMS     66090 IL    0.052 BOND      14477     429\n#>  4   561 ADAMS     66090 IL    0.052 BOONE     29344     127\n#>  5   561 ADAMS     66090 IL    0.052 BROWN      5264     547\n#>  6   561 ADAMS     66090 IL    0.052 BUREAU    35157      50\n#>  7   561 ADAMS     66090 IL    0.052 CALHOUN    5298       1\n#>  8   561 ADAMS     66090 IL    0.052 CARROLL   16519     111\n#>  9   561 ADAMS     66090 IL    0.052 CASS      13384      16\n#> 10   561 ADAMS     66090 IL    0.052 CHAMPA…  146506   16559\n#> # … with 46,815 more rows, 5 more variables:\n#> #   popamerindian <int>, popasian <int>, popother <int>,\n#> #   inmetro <int>, category <chr>, and abbreviated variable\n#> #   names ¹​county.x, ²​poptotal, ³​county.y, ⁴​popwhite,\n#> #   ⁵​popblack\ndim_desc(out4_1)\n#> [1] \"[46,825 x 13]\"\nout4_1 %>%\n  summarize(across(everything(), ~sum(is.na(.))))\n#> # A tibble: 1 × 13\n#>     PID county.x popto…¹ state  area count…² popwh…³ popbl…⁴\n#>   <int>    <int>   <int> <int> <int>   <int>   <int>   <int>\n#> 1     0        0       0     0     0       0       0       0\n#> # … with 5 more variables: popamerindian <int>,\n#> #   popasian <int>, popother <int>, inmetro <int>,\n#> #   category <int>, and abbreviated variable names\n#> #   ¹​poptotal, ²​county.y, ³​popwhite, ⁴​popblack\nout4_2 <- data1 %>%\n  right_join(data2, by=c(\"state\",\"county\"))\nout4_2\n#> # A tibble: 527 × 12\n#>      PID county  popto…¹ state  area popwh…² popbl…³ popam…⁴\n#>    <int> <chr>     <int> <chr> <dbl>   <int>   <int>   <int>\n#>  1   561 ADAMS     66090 IL    0.052   63917    1702      98\n#>  2   561 ADAMS     66090 IL    0.052   63917    1702      98\n#>  3   562 ALEXAN…   10626 IL    0.014    7054    3496      19\n#>  4   562 ALEXAN…   10626 IL    0.014    7054    3496      19\n#>  5   563 BOND      14991 IL    0.022   14477     429      35\n#>  6   563 BOND      14991 IL    0.022   14477     429      35\n#>  7   564 BOONE     30806 IL    0.017   29344     127      46\n#>  8   564 BOONE     30806 IL    0.017   29344     127      46\n#>  9   565 BROWN      5836 IL    0.018    5264     547      14\n#> 10   565 BROWN      5836 IL    0.018    5264     547      14\n#> # … with 517 more rows, 4 more variables: popasian <int>,\n#> #   popother <int>, inmetro <int>, category <chr>, and\n#> #   abbreviated variable names ¹​poptotal, ²​popwhite,\n#> #   ³​popblack, ⁴​popamerindian\ndim_desc(out4_2)\n#> [1] \"[527 x 12]\"\nout4_2 %>%\n  summarize(across(everything(), ~sum(is.na(.))))\n#> # A tibble: 1 × 12\n#>     PID county poptotal state  area popwhite popbl…¹ popam…²\n#>   <int>  <int>    <int> <int> <int>    <int>   <int>   <int>\n#> 1     0      0        0     0     0        0       0       0\n#> # … with 4 more variables: popasian <int>, popother <int>,\n#> #   inmetro <int>, category <int>, and abbreviated variable\n#> #   names ¹​popblack, ²​popamerindian\nout5_1 <- data1 %>%\n  full_join(data2, by=\"state\")\nout5_1\n#> # A tibble: 46,825 × 13\n#>      PID count…¹ popto…² state  area count…³ popwh…⁴ popbl…⁵\n#>    <int> <chr>     <int> <chr> <dbl> <chr>     <int>   <int>\n#>  1   561 ADAMS     66090 IL    0.052 ADAMS     63917    1702\n#>  2   561 ADAMS     66090 IL    0.052 ALEXAN…    7054    3496\n#>  3   561 ADAMS     66090 IL    0.052 BOND      14477     429\n#>  4   561 ADAMS     66090 IL    0.052 BOONE     29344     127\n#>  5   561 ADAMS     66090 IL    0.052 BROWN      5264     547\n#>  6   561 ADAMS     66090 IL    0.052 BUREAU    35157      50\n#>  7   561 ADAMS     66090 IL    0.052 CALHOUN    5298       1\n#>  8   561 ADAMS     66090 IL    0.052 CARROLL   16519     111\n#>  9   561 ADAMS     66090 IL    0.052 CASS      13384      16\n#> 10   561 ADAMS     66090 IL    0.052 CHAMPA…  146506   16559\n#> # … with 46,815 more rows, 5 more variables:\n#> #   popamerindian <int>, popasian <int>, popother <int>,\n#> #   inmetro <int>, category <chr>, and abbreviated variable\n#> #   names ¹​county.x, ²​poptotal, ³​county.y, ⁴​popwhite,\n#> #   ⁵​popblack\ndim_desc(out5_1)\n#> [1] \"[46,825 x 13]\"\nout5_1 %>%\n  summarize(across(everything(), ~sum(is.na(.))))\n#> # A tibble: 1 × 13\n#>     PID county.x popto…¹ state  area count…² popwh…³ popbl…⁴\n#>   <int>    <int>   <int> <int> <int>   <int>   <int>   <int>\n#> 1     0        0       0     0     0       0       0       0\n#> # … with 5 more variables: popamerindian <int>,\n#> #   popasian <int>, popother <int>, inmetro <int>,\n#> #   category <int>, and abbreviated variable names\n#> #   ¹​poptotal, ²​county.y, ³​popwhite, ⁴​popblack\nout5_2 <- data1 %>%\n  full_join(data2, by=c(\"state\",\"county\"))\nout5_2\n#> # A tibble: 527 × 12\n#>      PID county  popto…¹ state  area popwh…² popbl…³ popam…⁴\n#>    <int> <chr>     <int> <chr> <dbl>   <int>   <int>   <int>\n#>  1   561 ADAMS     66090 IL    0.052   63917    1702      98\n#>  2   561 ADAMS     66090 IL    0.052   63917    1702      98\n#>  3   562 ALEXAN…   10626 IL    0.014    7054    3496      19\n#>  4   562 ALEXAN…   10626 IL    0.014    7054    3496      19\n#>  5   563 BOND      14991 IL    0.022   14477     429      35\n#>  6   563 BOND      14991 IL    0.022   14477     429      35\n#>  7   564 BOONE     30806 IL    0.017   29344     127      46\n#>  8   564 BOONE     30806 IL    0.017   29344     127      46\n#>  9   565 BROWN      5836 IL    0.018    5264     547      14\n#> 10   565 BROWN      5836 IL    0.018    5264     547      14\n#> # … with 517 more rows, 4 more variables: popasian <int>,\n#> #   popother <int>, inmetro <int>, category <chr>, and\n#> #   abbreviated variable names ¹​poptotal, ²​popwhite,\n#> #   ³​popblack, ⁴​popamerindian\ndim_desc(out5_2)\n#> [1] \"[527 x 12]\"\nout5_2 %>%\n  summarize(across(everything(), ~sum(is.na(.))))\n#> # A tibble: 1 × 12\n#>     PID county poptotal state  area popwhite popbl…¹ popam…²\n#>   <int>  <int>    <int> <int> <int>    <int>   <int>   <int>\n#> 1     0      0        0     0     0        0       0       0\n#> # … with 4 more variables: popasian <int>, popother <int>,\n#> #   inmetro <int>, category <int>, and abbreviated variable\n#> #   names ¹​popblack, ²​popamerindian\ndata <- data1 %>%\n  inner_join(data2, by=c(\"state\",\"county\"))\ndata\n#> # A tibble: 527 × 12\n#>      PID county  popto…¹ state  area popwh…² popbl…³ popam…⁴\n#>    <int> <chr>     <int> <chr> <dbl>   <int>   <int>   <int>\n#>  1   561 ADAMS     66090 IL    0.052   63917    1702      98\n#>  2   561 ADAMS     66090 IL    0.052   63917    1702      98\n#>  3   562 ALEXAN…   10626 IL    0.014    7054    3496      19\n#>  4   562 ALEXAN…   10626 IL    0.014    7054    3496      19\n#>  5   563 BOND      14991 IL    0.022   14477     429      35\n#>  6   563 BOND      14991 IL    0.022   14477     429      35\n#>  7   564 BOONE     30806 IL    0.017   29344     127      46\n#>  8   564 BOONE     30806 IL    0.017   29344     127      46\n#>  9   565 BROWN      5836 IL    0.018    5264     547      14\n#> 10   565 BROWN      5836 IL    0.018    5264     547      14\n#> # … with 517 more rows, 4 more variables: popasian <int>,\n#> #   popother <int>, inmetro <int>, category <chr>, and\n#> #   abbreviated variable names ¹​poptotal, ²​popwhite,\n#> #   ³​popblack, ⁴​popamerindian\ndata <- data %>%\n  select(!c(PID, category)) %>%\n  distinct()\ndata\n#> # A tibble: 437 × 10\n#>    county    poptotal state  area popwhite popblack popame…¹\n#>    <chr>        <int> <chr> <dbl>    <int>    <int>    <int>\n#>  1 ADAMS        66090 IL    0.052    63917     1702       98\n#>  2 ALEXANDER    10626 IL    0.014     7054     3496       19\n#>  3 BOND         14991 IL    0.022    14477      429       35\n#>  4 BOONE        30806 IL    0.017    29344      127       46\n#>  5 BROWN         5836 IL    0.018     5264      547       14\n#>  6 BUREAU       35688 IL    0.05     35157       50       65\n#>  7 CALHOUN       5322 IL    0.017     5298        1        8\n#>  8 CARROLL      16805 IL    0.027    16519      111       30\n#>  9 CASS         13437 IL    0.024    13384       16        8\n#> 10 CHAMPAIGN   173025 IL    0.058   146506    16559      331\n#> # … with 427 more rows, 3 more variables: popasian <int>,\n#> #   popother <int>, inmetro <int>, and abbreviated variable\n#> #   name ¹​popamerindian\ndata <- data %>%\n  mutate(popdensity=poptotal/area, \n         percwhite=100*popwhite/poptotal,\n         percblack=100*popblack/poptotal,\n         percamerindian=100*popamerindian/poptotal,\n         percasian=100*popasian/poptotal,\n         percother=100*popother/poptotal)\ndata[8:13]\n#> # A tibble: 437 × 6\n#>    popasian popother inmetro popdensity percwhite percblack\n#>       <int>    <int>   <int>      <dbl>     <dbl>     <dbl>\n#>  1      249      124       0   1270962.      96.7    2.58  \n#>  2       48        9       0    759000       66.4   32.9   \n#>  3       16       34       0    681409.      96.6    2.86  \n#>  4      150     1139       1   1812118.      95.3    0.412 \n#>  5        5        6       0    324222.      90.2    9.37  \n#>  6      195      221       0    713760       98.5    0.140 \n#>  7       15        0       0    313059.      99.5    0.0188\n#>  8       61       84       0    622407.      98.3    0.661 \n#>  9       23        6       0    559875       99.6    0.119 \n#> 10     8033     1596       1   2983190.      84.7    9.57  \n#> # … with 427 more rows\ndata3 <- Dataset_3\ndata3\n#> # A tibble: 437 × 10\n#>    county    state popadults perchsd perco…¹ percp…² percb…³\n#>    <chr>     <chr>     <int>   <dbl>   <dbl>   <dbl>   <dbl>\n#>  1 ADAMS     IL        43298    75.1    19.6    4.36   13.2 \n#>  2 ALEXANDER IL         6724    59.7    11.2    2.87   32.2 \n#>  3 BOND      IL         9669    69.3    17.0    4.49   12.1 \n#>  4 BOONE     IL        19272    75.5    17.3    4.20    7.21\n#>  5 BROWN     IL         3979    68.9    14.5    3.37   13.5 \n#>  6 BUREAU    IL        23444    76.6    18.9    3.28   10.4 \n#>  7 CALHOUN   IL         3583    62.8    11.9    3.21   15.1 \n#>  8 CARROLL   IL        11323    76.0    16.2    3.06   11.7 \n#>  9 CASS      IL         8825    72.3    14.1    3.21   13.9 \n#> 10 CHAMPAIGN IL        95971    87.5    41.3   17.8    15.6 \n#> # … with 427 more rows, 3 more variables:\n#> #   percchildbelowpovert <dbl>, percadultpoverty <dbl>,\n#> #   percelderlypoverty <dbl>, and abbreviated variable\n#> #   names ¹​percollege, ²​percprof, ³​percbelowpoverty\ndata <- data %>%\n  inner_join(data3, by=c(\"state\",\"county\"))\ndata\n#> # A tibble: 437 × 24\n#>    county    poptotal state  area popwhite popblack popame…¹\n#>    <chr>        <int> <chr> <dbl>    <int>    <int>    <int>\n#>  1 ADAMS        66090 IL    0.052    63917     1702       98\n#>  2 ALEXANDER    10626 IL    0.014     7054     3496       19\n#>  3 BOND         14991 IL    0.022    14477      429       35\n#>  4 BOONE        30806 IL    0.017    29344      127       46\n#>  5 BROWN         5836 IL    0.018     5264      547       14\n#>  6 BUREAU       35688 IL    0.05     35157       50       65\n#>  7 CALHOUN       5322 IL    0.017     5298        1        8\n#>  8 CARROLL      16805 IL    0.027    16519      111       30\n#>  9 CASS         13437 IL    0.024    13384       16        8\n#> 10 CHAMPAIGN   173025 IL    0.058   146506    16559      331\n#> # … with 427 more rows, 17 more variables: popasian <int>,\n#> #   popother <int>, inmetro <int>, popdensity <dbl>,\n#> #   percwhite <dbl>, percblack <dbl>, percamerindian <dbl>,\n#> #   percasian <dbl>, percother <dbl>, popadults <int>,\n#> #   perchsd <dbl>, percollege <dbl>, percprof <dbl>,\n#> #   percbelowpoverty <dbl>, percchildbelowpovert <dbl>,\n#> #   percadultpoverty <dbl>, percelderlypoverty <dbl>, and …\ndata <- data %>%\n  mutate(popcbelowpoverty=poptotal*percbelowpoverty,\n         popcadultpoverty=popadults*percadultpoverty)\ndata[24:26]\n#> # A tibble: 437 × 3\n#>    percelderlypoverty popcbelowpoverty popcadultpoverty\n#>                 <dbl>            <dbl>            <dbl>\n#>  1              12.4           869179.          476701.\n#>  2              25.2           342628.          184141.\n#>  3              12.7           180924.          104929.\n#>  4               6.22          222081.          106690.\n#>  5              19.2            78904.           44339.\n#>  6              11.0           371142.          191755.\n#>  7              21.1            80627.           46337.\n#>  8               9.53          196799.          113536.\n#>  9              13.7           186440.          105144.\n#> 10               8.11         2694421.         1685513.\n#> # … with 427 more rows\ndata <- data %>%\n  relocate(inmetro, .after=last_col()) %>%\n  relocate(poptotal, .after=area) %>%\n  relocate(popdensity, .after=poptotal)\ndata[3:8]\n#> # A tibble: 437 × 6\n#>     area poptotal popdensity popwhite popblack popamerindian\n#>    <dbl>    <int>      <dbl>    <int>    <int>         <int>\n#>  1 0.052    66090   1270962.    63917     1702            98\n#>  2 0.014    10626    759000      7054     3496            19\n#>  3 0.022    14991    681409.    14477      429            35\n#>  4 0.017    30806   1812118.    29344      127            46\n#>  5 0.018     5836    324222.     5264      547            14\n#>  6 0.05     35688    713760     35157       50            65\n#>  7 0.017     5322    313059.     5298        1             8\n#>  8 0.027    16805    622407.    16519      111            30\n#>  9 0.024    13437    559875     13384       16             8\n#> 10 0.058   173025   2983190.   146506    16559           331\n#> # … with 427 more rows\ndata[23:26]\n#> # A tibble: 437 × 4\n#>    percelderlypoverty popcbelowpoverty popcadultpo…¹ inmetro\n#>                 <dbl>            <dbl>         <dbl>   <int>\n#>  1              12.4           869179.       476701.       0\n#>  2              25.2           342628.       184141.       0\n#>  3              12.7           180924.       104929.       0\n#>  4               6.22          222081.       106690.       1\n#>  5              19.2            78904.        44339.       0\n#>  6              11.0           371142.       191755.       0\n#>  7              21.1            80627.        46337.       0\n#>  8               9.53          196799.       113536.       0\n#>  9              13.7           186440.       105144.       0\n#> 10               8.11         2694421.      1685513.       1\n#> # … with 427 more rows, and abbreviated variable name\n#> #   ¹​popcadultpoverty\ndata %>%\n  group_by(state) %>%\n  summarise(tot_pop = sum(poptotal)) %>%\n  arrange(tot_pop)\n#> # A tibble: 5 × 2\n#>   state  tot_pop\n#>   <chr>    <int>\n#> 1 WI     4891769\n#> 2 IN     5544159\n#> 3 MI     9295297\n#> 4 OH    10847115\n#> 5 IL    11430602\ndata %>%\n  group_by(state) %>%\n  summarise(tot_area = sum(area)) %>%\n  arrange(tot_area)\n#> # A tibble: 5 × 2\n#>   state tot_area\n#>   <chr>    <dbl>\n#> 1 IN        2.13\n#> 2 OH        2.42\n#> 3 WI        3.29\n#> 4 IL        3.30\n#> 5 MI        3.36\ndata %>%\n  group_by(state) %>%\n  summarise(avg_popdensity = mean(popdensity))\n#> # A tibble: 5 × 2\n#>   state avg_popdensity\n#>   <chr>          <dbl>\n#> 1 IL          2823731.\n#> 2 IN          2573130.\n#> 3 MI          3010809.\n#> 4 OH          4639024.\n#> 5 WI          2372694.\ndata %>%\n  group_by(state, inmetro) %>%\n  summarise(avg_popdensity = mean(popdensity))\n#> `summarise()` has grouped output by 'state'. You can\n#> override using the `.groups` argument.\n#> # A tibble: 10 × 3\n#> # Groups:   state [5]\n#>    state inmetro avg_popdensity\n#>    <chr>   <int>          <dbl>\n#>  1 IL          0        773783.\n#>  2 IL          1       8241451.\n#>  3 IN          0       1183804.\n#>  4 IN          1       4638344.\n#>  5 MI          0        743790.\n#>  6 MI          1       8270292.\n#>  7 OH          0       1506462.\n#>  8 OH          1       8398098.\n#>  9 WI          0        674527.\n#> 10 WI          1       6787929.\ndata %>%\n  summarise(across(percwhite:percother, ~mean(.x)))\n#> # A tibble: 1 × 5\n#>   percwhite percblack percamerindian percasian percother\n#>       <dbl>     <dbl>          <dbl>     <dbl>     <dbl>\n#> 1      95.6      2.68          0.799     0.487     0.479\ndata %>%\n  group_by(state) %>%\n  summarise(across(percwhite:percother, ~mean(.x)))\n#> # A tibble: 5 × 6\n#>   state percwhite percblack percamerindian percasian perco…¹\n#>   <chr>     <dbl>     <dbl>          <dbl>     <dbl>   <dbl>\n#> 1 IL         95.0     3.65           0.174     0.564   0.653\n#> 2 IN         97.2     1.89           0.222     0.383   0.298\n#> 3 MI         94.4     3.07           1.37      0.507   0.617\n#> 4 OH         95.4     3.51           0.184     0.433   0.471\n#> 5 WI         95.8     0.822          2.52      0.556   0.315\n#> # … with abbreviated variable name ¹​percother\ndata %>%\n  group_by(state, inmetro) %>%\n  summarise(across(percwhite:percother, ~mean(.x)))\n#> `summarise()` has grouped output by 'state'. You can\n#> override using the `.groups` argument.\n#> # A tibble: 10 × 7\n#> # Groups:   state [5]\n#>    state inmetro percwhite percblack perca…¹ perca…² perco…³\n#>    <chr>   <int>     <dbl>     <dbl>   <dbl>   <dbl>   <dbl>\n#>  1 IL          0      96.5     2.70    0.169   0.338   0.317\n#>  2 IL          1      90.9     6.17    0.186   1.16    1.54 \n#>  3 IN          0      98.4     0.881   0.233   0.259   0.209\n#>  4 IN          1      95.4     3.39    0.206   0.567   0.430\n#>  5 MI          0      96.5     1.06    1.73    0.307   0.366\n#>  6 MI          1      89.6     7.71    0.508   0.970   1.20 \n#>  7 OH          0      97.4     1.61    0.188   0.319   0.521\n#>  8 OH          1      93.0     5.80    0.179   0.569   0.410\n#>  9 WI          0      95.9     0.248   3.27    0.321   0.217\n#> 10 WI          1      95.4     2.31    0.564   1.17    0.571\n#> # … with abbreviated variable names ¹​percamerindian,\n#> #   ²​percasian, ³​percother\ndata %>%\n  group_by(state) %>%\n  summarise(mean(percbelowpoverty))\n#> # A tibble: 5 × 2\n#>   state `mean(percbelowpoverty)`\n#>   <chr>                    <dbl>\n#> 1 IL                        13.1\n#> 2 IN                        10.3\n#> 3 MI                        14.2\n#> 4 OH                        13.0\n#> 5 WI                        11.9\ndata %>%\n  group_by(state, inmetro) %>%\n  summarise(mean(percbelowpoverty))\n#> `summarise()` has grouped output by 'state'. You can\n#> override using the `.groups` argument.\n#> # A tibble: 10 × 3\n#> # Groups:   state [5]\n#>    state inmetro `mean(percbelowpoverty)`\n#>    <chr>   <int>                    <dbl>\n#>  1 IL          0                    14.4 \n#>  2 IL          1                     9.56\n#>  3 IN          0                    10.8 \n#>  4 IN          1                     9.59\n#>  5 MI          0                    15.5 \n#>  6 MI          1                    11.3 \n#>  7 OH          0                    14.3 \n#>  8 OH          1                    11.5 \n#>  9 WI          0                    13.0 \n#> 10 WI          1                     9.01\ndata %>%\n  filter(poptotal >= 50000) %>%\n  group_by(state, inmetro) %>%\n  summarise(mean(percbelowpoverty))\n#> `summarise()` has grouped output by 'state'. You can\n#> override using the `.groups` argument.\n#> # A tibble: 10 × 3\n#> # Groups:   state [5]\n#>    state inmetro `mean(percbelowpoverty)`\n#>    <chr>   <int>                    <dbl>\n#>  1 IL          0                    15.7 \n#>  2 IL          1                    10.6 \n#>  3 IN          0                    10.6 \n#>  4 IN          1                    10.6 \n#>  5 MI          0                    13.0 \n#>  6 MI          1                    11.3 \n#>  7 OH          0                    13.8 \n#>  8 OH          1                    11.8 \n#>  9 WI          0                     8.70\n#> 10 WI          1                     8.82"},{"path":"module-8.html","id":"module-8","chapter":"Module 8","heading":"Module 8","text":" ","code":""},{"path":"module-8.html","id":"data-visualization-base-r","chapter":"Module 8","heading":"Data Visualization (Base R)","text":"already learned use R built-functions compute basic numerical summaries data mean, median, IQR, quantiles, . module, going learn get summary data via visualization.Data visualization plays crucial role data analysis. Prior building statistical models performing statistical procedure, want plot data suggest statistical tools might appropriate. module, learn visualize data Base R. Later, learn use ggplot2 package . versatile advanced visualization tools.using data set (Lung Capacity data set), available Courseworks.","code":"\n\ndata <- read.table(file = \"C:/Users/alexp/OneDrive/Desktop/R Bootcamp/R_bootcamp/lung_capacity.txt\", header = T, sep = \"\", stringsAsFactors = TRUE)"},{"path":"module-8.html","id":"histograms","chapter":"Module 8","heading":"Histograms","text":"Histograms display distribution numerical data. represent frequencies values variable bucketed ranges. function hist() used plot histograms. Let’s plot histogram Age variable:can change labels histogram passing xlab, ylab, main arguments function:x-axis contains range values variable. Histograms divide intervals known bins. Histograms tricky depends subjective judgments exactly put bin margins graph looking . Wide bins produce one picture, narrow bins produce different picture, unequal bins produce confusion. can choose number bins display passing break argument function. example , specify starting ending points bin (instance, 0 2, 2 4, ):can change color bins corresponding borders:can display specific parts histogram passing xlim() arguments. display part histogram corresponds specified range:","code":"\n\nhist(data$Age)\n\nhist(data$Age,\n     \n     xlab = \"AGE\",\n     \n     ylab = \"FREQUENCY\",\n     \n     main = \"Histogram of AGE\")\n\nhist(data$Age,\n     \n     xlab = \"AGE\",\n     \n     ylab = \"FREQUENCY\",\n     \n     main = \"Histogram of AGE\",\n     \n     breaks = seq(0, 20, 2)\n     \n     )\n\nhist(data$Age,\n     \n     xlab = \"AGE\",\n     \n     ylab = \"FREQUENCY\",\n     \n     main = \"Histogram of AGE\",\n     \n     breaks = seq(0, 20, 2),\n     \n     col = \"lightpink\",\n     \n     border = \"black\")\n\nhist(data$Age,\n     \n     xlab = \"AGE\",\n     \n     ylab = \"FREQUENCY\",\n     \n     main = \"Histogram of AGE\",\n     \n     breaks = seq(0, 20, 2),\n     \n     col = \"lightpink\",\n     \n     border = \"black\",\n     \n     xlim = c(0, 12)\n     \n     )"},{"path":"module-8.html","id":"barplots","chapter":"Module 8","heading":"Barplots","text":"Barplots similar histograms used categorical/qualitative variables (R call factors). display levels categorical variable corresponding frequencies. create barplot Status variable:Like histgorams, barplots can customized. Let’s add labels barplot:Now, let’s change color bins borders:can even make horizontal barplot:R, can create clustered barplots. two examples given , guess displaying:","code":"\n\nbarplot(table(data$Status))\n\nbarplot(table(data$Status),\n        \n        xlab = \"Disease Stage\",\n        \n        ylab = \"Frequences\",\n        \n        main = \"Disease Status\",\n        \n        names.arg = c(\"Healthy\", \"Stage 1\", \"Stage 2\", \"Stage 3\"))\n\nbarplot(table(data$Status),\n        \n        xlab = \"Disease Stage\",\n        \n        ylab = \"Frequences\",\n        \n        main = \"Disease Status\",\n        \n        names.arg = c(\"Healthy\", \"Stage 1\", \"Stage 2\", \"Stage 3\"),\n        \n        col = \"orange\",\n        \n        border = \"blue\")\n\nbarplot(table(data$Status),\n        \n        xlab = \"Frequences\",\n        \n        ylab = \"Disease Stage\",\n        \n        main = \"Disease Status\",\n        \n        names.arg = c(\"Healthy\", \"Stage 1\", \"Stage 2\", \"Stage 3\"),\n        \n        col = \"orange\",\n        \n        border = \"blue\",\n        \n        horiz = TRUE)\n\nbarplot(table(data[, c(\"Sex\", \"Status\")]),\n        \n        legend.text = TRUE,\n        \n        ylab = \"Frequences\",\n        \n        xlab = \"Disease Stage\",\n        \n        main = \"Disease Status vs Sex\",\n        \n        names.arg = c(\"Healthy\", \"Stage 1\", \"Stage 2\", \"Stage 3\"),\n        \n        col = c(\"orange\", \"red\"))\n\nbarplot(table(data[, c(\"Sex\", \"Status\")]),\n        \n        beside = TRUE,\n        \n        legend.text = TRUE,\n        \n        ylab = \"Frequences\",\n        \n        xlab = \"Disease Stage\",\n        \n        main = \"Disease Status vs Sex\",\n        \n        names.arg = c(\"Healthy\", \"Stage 1\", \"Stage 2\", \"Stage 3\"),\n        \n        col = c(\"orange\", \"red\"))"},{"path":"module-8.html","id":"boxplots","chapter":"Module 8","heading":"Boxplots","text":"Boxplots used visualize 5-Number summary (Minimum, Q1 (first quartile, also known 25th percentile), median, Q3 (third quartile, also known 75th percentile), Maximum). boxplot Age variable:Let’s add labels change colors:can even add notch want :can change shape size points plot passing pch cex arguments, respectfully. Type ?pch console see shapes available.Often using boxplots compare numerical variable different levels categorical variables (, levels factor). Let’s compare boxplots Age variable female male patients:Let’s make complicated:","code":"\n\nboxplot(data$Age)\n\nboxplot(data$Age,\n        \n        xlab = \"AGE\",\n        \n        ylab = \"Values\",\n        \n        main = \"Boxplot of AGE\",\n        \n        col = \"darkorange\",\n        \n        border = \"dodgerblue\")\n\nboxplot(data$Age,\n        \n        xlab = \"AGE\",\n        \n        ylab = \"Values\",\n        \n        main = \"Boxplot of AGE\",\n        \n        col = \"darkorange\",\n        \n        border = \"dodgerblue\",\n        \n        notch = T)\n\nboxplot(data$Age,\n        \n        xlab = \"AGE\",\n        \n        ylab = \"Values\",\n        \n        main = \"Boxplot of AGE\",\n        \n        col = \"darkorange\",\n        \n        border = \"dodgerblue\",\n        \n        notch = T,\n        \n        pch = 20,\n        \n        cex  = 2)\n\nboxplot(data$Age ~ data$Sex,\n        \n        xlab = \"SEX\",\n        \n        ylab = \"AGE\",\n        \n        main = \"Grouped Boxplots\",\n        \n        col = c(\"darkorange\", \"red\"),\n        \n        border = c(\"dodgerblue\", \"black\"),\n        \n        notch = T)\n\nboxplot(data$Age ~ data$Sex:data$Smoke,\n        \n        xlab = \"COMBINATION OF SEX AND SMOKE VARIABLES\",\n        \n        ylab = \"AGE\",\n        \n        main = \"Grouped Boxplots\",\n        \n        names = c(\"F_Nonsmokers\",\"M_Nonsmokers\", \"F_Smokers\", \"M_Smokers\"),\n        \n        col = c(\"darkorange\", \"red\"),\n        \n        border = c(\"dodgerblue\", \"black\"),\n        \n        notch = T)"},{"path":"module-8.html","id":"scatterplots","chapter":"Module 8","heading":"Scatterplots","text":"mentioned earlier, building statistical model, recommended visualize relationship among variables. Suppose, want build regression model describe relationship Age Lung Capacity variables. First, visualize data using plot() function:can observe, linear trend two variables, suggests linear regression model might appropriate. Now let’s customize plot labeling changing color, shape, size points:can focus specific parts plot adding xlim() argument:can change color (size) points based factor variables. example, can make observation belong female patients displayed red dots observation belong male patients displayed blue ones. addition, can add legends clarify meaning colors plot:Finally, R able display multiple plots single image. , need use par() function. pass mfrow() argument function specifies dimensions final plot. example, want plot two images one row (, 1 row 2 columns), execute par(mfrow = c(1, 2)) function followed plots aim include :","code":"\n\nplot(x = data$Age, y = data$LungCap)\n\nplot(x = data$Age,\n     \n     y = data$LungCap,\n     \n     xlab = \"AGE\",\n     \n     ylab = \"Lung Capacity\",\n     \n     main = \"Lung Capacity vs Age\",\n     \n     col = \"dodgerblue\",\n     \n     pch = 20,\n     \n     cex  = 0.5)\n\nplot(x = data$Age,\n     \n     y = data$LungCap,\n     \n     xlab = \"AGE\",\n     \n     ylab = \"Lung Capacity\",\n     \n     main = \"Lung Capacity vs Age\",\n     \n     col = \"dodgerblue\",\n     \n     pch = 20,\n     \n     cex  = 1,\n     \n     xlim = c(0, 10))\n\ncolors <- c(\"red\", \"blue\")\n\nplot(x = data$Age,\n     \n     y = data$LungCap,\n     \n     xlab = \"AGE\",\n     \n     ylab = \"Lung Capacity\",\n     \n     main = \"Lung Capacity vs Age\",\n     \n     col = colors[data$Sex],\n     \n     pch = 20,\n     \n     cex  = 1)\n\n\nlegend(\"topleft\", legend = c(\"FEMALE\", \"MALE\"), pch = 20, col = colors)\n\npar(mfrow = c(1, 2))\n\n\nboxplot(data$LungCap ~ data$Sex,\n        \n        xlab = \"SEX\",\n        \n        ylab = \"AGE\",\n        \n        main = \"Grouped Boxplots\",\n        \n        col = c(\"darkorange\", \"red\"),\n        \n        border = c(\"dodgerblue\", \"black\"),\n        \n        notch = T)\n\n\nplot(x = data$Age,\n     \n     y = data$LungCap,\n     \n     xlab = \"AGE\",\n     \n     ylab = \"Lung Capacity\",\n     \n     main = \"Lung Capacity vs Age\",\n     \n     col = colors[data$Sex],\n     \n     pch = 20,\n     \n     cex  = 1)\n\n\nlegend(\"topleft\", legend = c(\"FEMALE\", \"MALE\"), pch = 20, col = colors)"},{"path":"module-9.html","id":"module-9","chapter":"Module 9","heading":"Module 9","text":" ","code":""},{"path":"module-9.html","id":"ggplot2-package","chapter":"Module 9","heading":"ggplot2 Package","text":"already learned visualize data using Base R. (following) module(s) going learn using ggplot2 package. R several systems making graphs, ggplot2 one elegant versatile. ggplot2 implements grammar graphics, coherent system describing building graphs. ggplot2, can faster learning one system applying many places.use mpg dataset illustrate functionality ggplot2 package. contains subset fuel economy data EPA makes available. contains models new release every year 1999 2008 - used proxy popularity car.Among variables mpg :displ - car’s engine size, litershwy - car’s fuel efficiency highway, miles per gallon (mpg)cyl - number cylindersclass - type cardrv - type drive trainBefore start exploring ggplot2 package, let’s convert one variables factor:","code":"\n\nprint(mpg)\n#> # A tibble: 234 × 11\n#>    manufac…¹ model displ  year cyl   trans drv     cty   hwy\n#>    <chr>     <chr> <dbl> <int> <fct> <chr> <chr> <int> <int>\n#>  1 audi      a4      1.8  1999 4     auto… f        18    29\n#>  2 audi      a4      1.8  1999 4     manu… f        21    29\n#>  3 audi      a4      2    2008 4     manu… f        20    31\n#>  4 audi      a4      2    2008 4     auto… f        21    30\n#>  5 audi      a4      2.8  1999 6     auto… f        16    26\n#>  6 audi      a4      2.8  1999 6     manu… f        18    26\n#>  7 audi      a4      3.1  2008 6     auto… f        18    27\n#>  8 audi      a4 q…   1.8  1999 4     manu… 4        18    26\n#>  9 audi      a4 q…   1.8  1999 4     auto… 4        16    25\n#> 10 audi      a4 q…   2    2008 4     manu… 4        20    28\n#> # … with 224 more rows, 2 more variables: fl <chr>,\n#> #   class <chr>, and abbreviated variable name\n#> #   ¹​manufacturer\n\nmpg$cyl <- as.factor(mpg$cyl)"},{"path":"module-9.html","id":"creating-a-ggplot-object","chapter":"Module 9","heading":"Creating a ggplot Object","text":"Every ggplot2 plot three key components:DataA set aesthetic mappings variables data visual propertiesAt least one layer describes render observations. Layers usually created geom functionTo produce scatterplot, need pass data ggplot() function:can notice, creates plot object display data. add datapoints object, add geom_point() function + sign inside function specify x y variables dataset, x y axes, respectively:Note ’ve put command new line. recommended code, ’s easy scan plot specification see exactly ’s .","code":"\n\nggplot(data = mpg)\n\n  ggplot(data = mpg) + \n  \n  geom_point(mapping = aes(x = displ, y = hwy))"},{"path":"module-9.html","id":"changing-the-color-size-and-shape-of-datapoints","chapter":"Module 9","heading":"Changing the Color, Size, and Shape of Datapoints","text":"can change color, size, shape datapoints passing arguments geom_point() function:plot color, size, shape points static, meaning every point. want color change based another variable dataset reflect categories, need specify inside aes() function:ggplot2 automatically assigned colors levels cyl variable. want change manually, need using scale_colour_manual() function:can also change shape points reflect another variable dataset:can changing transparency points:change legend title, add labs() function use color argument:Let’s save ggplot object. adding new layers object shortly:","code":"\n\n  ggplot(data = mpg) + \n    \n  geom_point(mapping = aes(x = displ, y = hwy),\n               \n               color = \"steelblue\",\n               \n               size = 3,\n             \n               shape = 24)\n\n  ggplot(data = mpg) + \n    \n    geom_point(mapping = aes(x = displ, y = hwy, color = cyl),\n               \n               size = 3) \n\n  ggplot(data = mpg) + \n    \n    geom_point(mapping = aes(x = displ, y = hwy, color = cyl),\n               \n               size = 3) +\n    \n    scale_colour_manual(values = c(`4` = \"red\", \n                                   \n                                   `5` = \"blue\",\n                                   \n                                   `6` = \"orange\", \n                                   \n                                   `8` = \"yellow\"))\n\n  ggplot(data = mpg) + \n    \n    geom_point(mapping = aes(x = displ, y = hwy, color = cyl, shape = class),\n               \n               size = 3)\n#> Warning: The shape palette can deal with a maximum of 6\n#> discrete values because more than 6 becomes difficult\n#> to discriminate; you have 7. Consider specifying\n#> shapes manually if you must have them.\n#> Warning: Removed 62 rows containing missing values\n#> (geom_point).\n\n  ggplot(data = mpg) + \n    \n    geom_point(mapping = aes(x = displ, y = hwy, alpha = cyl),\n               \n               size = 3)\n#> Warning: Using alpha for a discrete variable is not advised.\n\n  ggplot(data = mpg) + \n    \n  geom_point(mapping = aes(x = displ, y = hwy, color = cyl),\n               \n               size = 3) +\n    \n  labs(color = \"Number of Cylinders\")\n\n  gg <-   ggplot(data = mpg) + \n    \n    geom_point(mapping = aes(x = displ, y = hwy, color = cyl),\n               \n               size = 3) +\n    \n    labs(color = \"Number of Cylinders\")"},{"path":"module-9.html","id":"adding-labels","chapter":"Module 9","heading":"Adding Labels","text":"add labels ggplot object, can use labs() function . Inside function, specify plot title, subtitle, labels x y axes:","code":"\n\ngg <- gg +\n  \n  labs(title = \"Highway Miles per Galon vs Engine Displacement\",\n       \n       subtitle = \"From mpg dataset\",\n       \n       x = \"Engine Displacement\",\n       \n       y = \"Highway Miles per Galon\")\n\n\nprint(gg)"},{"path":"module-9.html","id":"adjusting-limits-of-axes","chapter":"Module 9","heading":"Adjusting Limits of Axes","text":"x y axes limits can controlled 2 ways:can change axis limits using xlim() ylim() functions. need pass numeric vector length 2 (max min values) just max min values:limitation approach deletes points outside specified range. approach change x y limits zooming region interest without deleting points. achieved using coord_cartesian() function:primary argument affects appearance ticks axes: breaks. Breaks controls position ticks, values associated keys. pass argument either scale_x_continuous() scale_y_continuous() functions, depending axis want modify:","code":"\n\n  gg +\n  \n  xlim(c(0, 4)) +\n  \n  ylim(c(0, 25))\n#> Warning: Removed 170 rows containing missing values\n#> (geom_point).\n\n  gg +\n  \n  coord_cartesian(xlim = c(0, 4),\n                  \n                  ylim = c(0, 25))\n\n  gg <- gg +\n    \n    scale_x_continuous(breaks = seq(0, 8, 0.5)) +\n    \n    scale_y_continuous(breaks = seq(15, 50, 10))\n\n\nprint(gg)"},{"path":"module-9.html","id":"themes","chapter":"Module 9","heading":"Themes","text":"can customize non-data elements plot theme() function. example, can change background plot:Let’s select theme_bw() option update plot:, can change color size titles, size angle ticks axes, location legends:","code":"\n\n  gg +\n   \n    theme_bw() \n\n  gg +\n   \n    theme_classic() \n\n  gg +\n   \n    theme_dark() \n\n  gg +\n   \n    theme_light() \n\n  gg +\n   \n    theme_linedraw() \n\n  gg +\n   \n    theme_minimal() \n\n  gg +\n   \n    theme_void() \n\n  gg <- gg +\n    \n    theme_bw()\n\n  gg <- gg +\n    \n    theme(plot.title=element_text(size=15, face=\"bold\", color = \"red\"),\n             \n             axis.text.x=element_text(size=10, angle = 45),\n             \n             axis.text.y=element_text(size=10, angle = 45),\n             \n             axis.title.x=element_text(size=12, color = \"blue\"),\n             \n             axis.title.y=element_text(size=12, color = \"blue\"),\n          \n             legend.position = \"top\") \n\nprint(gg)"},{"path":"module-9.html","id":"facets","chapter":"Module 9","heading":"Facets","text":"working categorical variables, becomes particularly useful split plot facets, subplots display one subset data correspond level categorical variable.facet plot single variable, use facet_wrap() function. first argument facet_wrap() formula, create ~ followed variable name (“formula” name data structure R, synonym “equation”). variable pass facet_wrap() discrete. Let’s plot displ hwy level class variable separately:can decide plots displayed specifying number rows final plot:facet plot combination two variables, add facet_grid() plot call. Let’s plot displ hwy different combinations levels class drv variables:","code":"\n\n  ggplot(data = mpg) + \n    \n  geom_point(mapping = aes(x = displ, y = hwy)) +\n    \n  facet_wrap(~ class)\n\n  ggplot(data = mpg) + \n    \n  geom_point(mapping = aes(x = displ, y = hwy)) +\n    \n  facet_wrap(~ class, nrow = 2)\n\n  ggplot(data = mpg) + \n    \n  geom_point(mapping = aes(x = displ, y = hwy)) +\n    \n  facet_grid(drv ~ class)"},{"path":"module-10.html","id":"module-10","chapter":"Module 10","heading":"Module 10","text":" ","code":""},{"path":"module-10.html","id":"ggplot2-package-contd","chapter":"Module 10","heading":"ggplot2 Package (Cont’d)","text":"continue exploring ggplot2 package. module using Lung Capacity dataset available Courseworks. ’ve already worked data, doesn’t require additional introduction. ","code":"\n\nlibrary(tidyverse)\n#> ── Attaching packages ─────────────────── tidyverse 1.3.2 ──\n#> ✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n#> ✔ tibble  3.1.8      ✔ dplyr   1.0.10\n#> ✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n#> ✔ readr   2.1.3      ✔ forcats 0.5.2 \n#> ── Conflicts ────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n\nlibrary(ggExtra)\n#> Warning: package 'ggExtra' was built under R version 4.2.3\n\nlibrary(patchwork)\n#> Warning: package 'patchwork' was built under R version 4.2.3\n\ndataset1 <- read.table(file = \"C:/Users/alexp/OneDrive/Desktop/R Bootcamp/R_bootcamp/lung_capacity.txt\",\n                   \n                   header = T,\n                   \n                   sep = \"\", \n                   \n                   stringsAsFactors = TRUE)"},{"path":"module-10.html","id":"barplots-1","chapter":"Module 10","heading":"Barplots","text":"mentioned Module 08, barplots refer graph bars represent count cases category categorical variable. similar histogram, discrete instead continuous x-axis. generate barplot ggplot2 package, add another layer ggplot object using geom_bar() function. dataset1 dataset want generate barplot Status variable, categorical variable 4 levels (categories):now, basic barplot. Let’s modify features make look better. can change color width bins. done adding two arguments function: fill - used change color bins; width - used change width bins:Let’s change values see affects plot:might also want change color outlines. done adding color argument function:want colors bars automatically controlled levels categorical variable, pass fill argument inside aes() function:Sometimes interested displaying bars together. Instead, want focus certain groups particularly interested . can done using scale_x_discrete() argument limits. Let’s display bars corresponding Healthy Stage_3 categories :can also use function change order bars appear plot:Knowing exact frequency category often requirement. barplots often hard look , especially scale y-axis large. Thus, reading values plot becomes approximation. fix issue, can add labels plot. can put text near top bar show exact frequency category. solve problem reading values barplot make user-friendly., need add geom_text() function shown code . Keep label stat arguments shown ; vjust argument changes location text, color arguments changes color. example can utilize function:can even convert frequencies percentages:Let’s make barplot self-explanatory adding labels . setting vjust hjust arguments, specify horizontal vertical positions element, respectively:Stacked grouped barplots used reflect categorical variables bars. Let’s display stacked barplot reflect Sex variable barplot:Now can even change colors segments manually:Like simple barplot, can add labels segments stacked barplot display actual frequency segments:bars heights helps us compare proportions segments rather actual counts. achieve , use position argument pass fill :Grouped barplots display bars corresponding categorical variables next instead top . display grouped barplot, need add position argument geom_bar() function pass position_dodge() :Let’s add labels bars reflect actual count groups:Sometimes want add extra touch barplots. instance, can add horizontal line visually filter groups /less observations certain value. done adding geom_hline() function. Suppose want see groups 100 observations:Finally, use coord_flip() turn vertical barplot horizontal one: ","code":"\n\nggplot(data = dataset1) +\n  \ngeom_bar(mapping = aes(x = Status))\n\nggplot(data = dataset1) +\n  \ngeom_bar(mapping = aes(x = Status),\n           \n           fill = \"orange\",\n           \n           width = 0.9)\n\nggplot(data = dataset1) +\n  \ngeom_bar(mapping = aes(x = Status),\n         \n         fill = \"pink\",\n         \n         width = 1.1)\n#> Warning: position_stack requires non-overlapping x intervals\n\nggplot(data = dataset1) +\n  \ngeom_bar(mapping = aes(x = Status),\n         \n         fill = \"pink\",\n         \n         color = \"blue\")\n\nggplot(data = dataset1) +\n  \ngeom_bar(mapping = aes(x = Status, fill = Status),\n           \n           width = 0.9)\n\nggplot(data = dataset1) +\n  \ngeom_bar(mapping = aes(x = Status, fill = Status),\n         \n         width = 0.9) +\n  \nscale_x_discrete(limits = c(\"HEALTHY\", \"STAGE_3\"))\n#> Warning: Removed 269 rows containing non-finite values\n#> (stat_count).\n\nggplot(data = dataset1) +\n  \ngeom_bar(mapping = aes(x = Status, fill = Status),\n         \n         width = 0.9) +\n  \nscale_x_discrete(limits = c(\"STAGE_1\", \"STAGE_2\", \"STAGE_3\", \"HEALTHY\"))\n\nggplot(data = dataset1) +\n  \ngeom_bar(mapping = aes(x = Status),\n           \n           fill = \"orange\") +\n  \ngeom_text(aes(x = Status,label = ..count..),\n            \n            stat = \"count\",\n            \n            vjust = -0.5,\n            \n            colour = \"black\")\n\nggplot(data = dataset1) +\n  \ngeom_bar(mapping = aes(x = Status),\n         \n         fill = \"orange\") +\n  \ngeom_text(aes(x = Status,label = ..count..),\n            \n            stat = \"count\",\n            \n            vjust = 1.5,\n            \n            size = 6,\n            \n            colour = \"black\")\n\nggplot(data = dataset1) +\n  \ngeom_bar(mapping = aes(x = Status),\n         \n         fill = \"orange\") +\n  \ngeom_text(aes(x = Status,label = scales::percent((..count..)/sum(..count..))),\n            \n            stat = \"count\",\n            \n            vjust = 1.5,\n            \n            size = 6,\n            \n            colour = \"black\")\n\nggplot(data = dataset1) +\n  \ngeom_bar(mapping = aes(x = Status, fill = Status)) +\n  \nlabs(title = \"Disease Status\",\n    \n     subtitle = \"From Lung Capacity Dataset\",\n    \n     x = \"STATUS\",\n    \n     y = \"COUNT\",\n    \n     caption = \"STAT2102: Lecture 15\") +\n  \ntheme_classic() +\n  \ntheme(plot.title = element_text(hjust = 0.5),\n        \n      plot.subtitle = element_text(hjust = 1),\n        \n      plot.caption = element_text(hjust = 0))\n\nggplot(data = dataset1) +\n  \ngeom_bar(mapping = aes(x = Status, fill = Sex)) \n\nggplot(data = dataset1) +\n  \ngeom_bar(mapping = aes(x = Status, fill = Sex)) +\n  \nscale_fill_manual(values = c(FEMALE = \"tomato\",\n                                \n                             MALE = \"steelblue\"))\n\nggplot(data = dataset1) +\n  \ngeom_bar(mapping = aes(x = Status, fill = Sex)) +\n  \nscale_fill_manual(values = c(FEMALE = \"tomato\",\n                               \n                             MALE = \"steelblue\")) +\n  \ngeom_text(aes(x = Status, fill = Sex, label = ..count..),\n            \n            stat = \"count\",\n            \n            position = position_stack(vjust = 0.5),\n            \n            size = 4,\n            \n            colour = \"black\")\n#> Warning: Ignoring unknown aesthetics: fill\n\nggplot(data = dataset1) +\n  \ngeom_bar(mapping = aes(x = Status, fill = Sex),\n         \n         position = \"fill\") \n\nggplot(data = dataset1) +\n  \ngeom_bar(mapping = aes(x = Status, fill = Sex),\n         \n         position = position_dodge()) +\n  \nscale_fill_manual(values = c(FEMALE = \"tomato\",\n                               \n                             MALE = \"steelblue\"))\n\nggplot(data = dataset1) +\n  \ngeom_bar(mapping = aes(x = Status, fill = Sex),\n         \n         position = position_dodge()) +\n  \nscale_fill_manual(values = c(FEMALE = \"tomato\",\n                               \n                             MALE = \"steelblue\")) +\n  \ngeom_text(aes(x = Status, fill = Sex,label = ..count..),\n            \n            stat = \"count\",\n            \n            position = position_dodge(0.9),\n            \n            vjust = 1.5,\n            \n            size = 4,\n            \n            colour = \"black\")\n#> Warning: Ignoring unknown aesthetics: fill\n\nggplot(data = dataset1) +\n  \ngeom_bar(mapping = aes(x = Status, fill = Sex),\n         \n         position = position_dodge()) +\n  \nscale_fill_manual(values = c(FEMALE = \"tomato\",\n                               \n                             MALE = \"steelblue\")) +\n  \ngeom_hline(yintercept = 100,\n           \n           linetype = \"dashed\",\n           \n           size = 1)\n\nggplot(data = dataset1) +\n  \ngeom_bar(mapping = aes(x = Status, fill = Sex),\n         \n         position = position_dodge()) +\n  \nscale_fill_manual(values = c(FEMALE = \"tomato\",\n                               \n                             MALE = \"steelblue\")) +\n  \ncoord_flip()"},{"path":"module-10.html","id":"boxplots-1","chapter":"Module 10","heading":"Boxplots","text":"short, boxplots used visualize 5-number summary. excellent data visualization tool statisticians researchers looking visualize data distributions. ggplot2 great set tools helps create boxplots adjust features.Let’s start simple boxplot going create Age variable. done using geom_boxplot() function:Changing colors features boxplot similar barplots. Thus, skip features . Just illustrative purposes, let’s change color boxplot add notch:Often, ’ll want visualize multiple boxplots single chart, representing distribution variable filter condition applied. instance, can visualize distribution Age every possible level Status variable:Let’s change color boxplots reflect levels Status:can also create multiple boxplots level Status variable reflect categorical features:previous boxplot contained outlier - observation stands rest data. customize outliers, use following code:mentioned earlier, boxplots visualize 5-number summary data. don’t display actual observations. want add datapoints boxplot, need add geom_dotplot() function:Boxplots show median thick line somewhere box. also want show mean value? stat_summary() function trick. can use function specify function shape, let’s stick mean value:Quite often need show relationships variables scatterplot, margins, also need show distribution variable. ggplot2 provide functionality, install additional package called ggExtra: ","code":"\n\nggplot(data = dataset1) +\n  \ngeom_boxplot(aes(y = Age))\n\nggplot(data = dataset1) +\n  \ngeom_boxplot(aes(y = Age),\n             \n             fill = \"orange\",\n             \n             notch = TRUE)\n\nggplot(data = dataset1) +\n  \ngeom_boxplot(aes(x = Status, y = Age))\n\nggplot(data = dataset1) +\n  \ngeom_boxplot(aes(x = Status, y = Age, fill = Status))\n\nggplot(data = dataset1) +\n  \ngeom_boxplot(aes(x = Status, y = Age, fill = Sex))\n\nggplot(data = dataset1) +\n  \ngeom_boxplot(aes(x = Status, y = Age, fill = Sex),\n               \n             outlier.colour = \"red\",\n               \n             outlier.shape = 8,\n               \n             outlier.size = 4)\n\nggplot(data = dataset1, aes(x = Status, y = Age)) +\n  \ngeom_boxplot() +\n  \ngeom_dotplot(binaxis = \"y\",\n             \n             stackdir = \"center\",\n             \n             dotsize = 0.3)\n#> Bin width defaults to 1/30 of the range of the data. Pick better value with `binwidth`.\n\nggplot(data = dataset1) +\n  \ngeom_boxplot(aes(x = Status, y = Age, fill = Status)) +\n  \nstat_summary(aes(x = Status, y = Age, fill = Status),\n               \n             fun = \"mean\",\n               \n             geom = \"point\",\n               \n             color = \"black\")\n\nlibrary(ggExtra)\n\n\ngg <- ggplot(data = dataset1) +\n  \n      geom_point(mapping = aes(x = Age, y = LungCap, color = Sex))\n\n\n\n  \nggMarginal(gg, type = \"boxplot\")"},{"path":"module-10.html","id":"histograms-1","chapter":"Module 10","heading":"Histograms","text":"Histograms used describe distribution continuous variable. basic histogram can created using geom_histogram() function. requires continuous variable:Similar barplots boxplots, can change histogram features adding arguments function. Let’s change color width bins, make transparent extend; also let’s change outline type:can also add new features histogram. instance, let’s add vertical line represents mean value continuous variable:ggplot2 allows add density curves histogram. done using geom_density() function:Now let’s change color bins reflect another categorical feature (example, Sex variable):Let’s add vertical lines correspond mean values two groups: ","code":"\n\nggplot(data = dataset1) +\n    \ngeom_histogram(aes(x = LungCap))\n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`.\n\nggplot(data = dataset1) +\n    \ngeom_histogram(aes(x = LungCap),\n                 \n               fill = \"tomato\",\n                 \n               color = \"black\",\n               \n               alpha = 0.3,\n                 \n               binwidth = 0.9,\n               \n               linetype = \"dashed\") \n\nggplot(data = dataset1) +\n    \ngeom_histogram(aes(x = LungCap), \n                   \n               fill = \"tomato\",\n                   \n               alpha = 0.3,\n                   \n               color = \"black\") +\n    \ngeom_vline(aes(xintercept = mean(LungCap)),\n               \n           color = \"blue\",\n               \n           size = 1)\n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`.\nggplot(data = dataset1) +\n    \ngeom_histogram(aes(x = LungCap, y = ..density..),\n                   \n               fill = \"white\", \n                   \n               color = \"black\") +\n    \ngeom_density(aes(x = LungCap),\n                 \n             alpha = 0.3,\n                 \n             fill = \"tomato\")\n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`.\n\nggplot(data = dataset1) +\n    \ngeom_histogram(aes(x = LungCap, fill = Sex, color = Sex),\n               \n               alpha = 0.5)\n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`.\n\n# Preparing inputs \n\ndata_summary = dataset1 %>% \n  \n               group_by(Sex) %>%\n  \n               summarise(grp.mean = mean(LungCap))\n\n\n# Plotting the lines\n  \nggplot(data = dataset1) +\n    \ngeom_histogram(aes(x = LungCap, fill = Sex, color = Sex),\n               \n               alpha = 0.5) +\n    \ngeom_vline(data = data_summary, \n               \n           aes(xintercept=grp.mean, color=Sex),\n               \n           linetype=\"dashed\",\n               \n           size = 1) \n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`."},{"path":"module-10.html","id":"arranging-plots","chapter":"Module 10","heading":"Arranging Plots","text":"Often want show two plots side side show different aspects story compelling way. can achieved using ggplot2’s one extensions, patckwork package. need install package load .’s heart, patchwork package extends ggplot2’s use + operator work multiple plots, well add additional operators specialized compositions working compositions plots. illustrate functionality, first let’s create ggplot objects:simple use patchwork use + add plots together thus creating assemble plots display together:+ specify specific layout, plots displayed together. absence layout algorithm governs number rows columns facet_wrap() decide number rows columns. means adding 3 plots together create 1x3 grid adding 4 plots together create 2x2 grid:often automatically created grid want course possible control . direct powerful way add plot_layout() specification plot:common scenario wanting force single row column. patchwork provides two operators, | / respectively:Patchwork allows nesting layouts means possible create various layouts using just two operators:","code":"\ng1 <- ggplot(data = dataset1) +\n  \n      geom_bar(mapping = aes(x = Status, fill = Status), width = 0.9) +\n  \n      scale_x_discrete(limits = c(\"STAGE_1\", \"STAGE_2\", \"STAGE_3\", \"HEALTHY\"))\n  \n\n\ng2 <- ggplot(data = dataset1) +\n  \n      geom_boxplot(aes(x = Status, y = Age, fill = Sex))\n \n\n\ng3 <-   ggplot(data = dataset1) +\n  \n        geom_histogram(aes(x = LungCap,\n                     \n                       fill = Sex,\n                     \n                       color = Sex,\n                     \n                       alpha = 0.5)) \n  \n\ng1 + g2\n\ng1 + g2 + g3\n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`.\n\ng1 + g2 + g3 +\n  \nplot_layout(ncol = 2)\n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`.\n\ng1/g2\n\ng1|g2\n\ng1 | (g2/g3)\n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`."},{"path":"module-11.html","id":"module-11","chapter":"Module 11","heading":"Module 11","text":" ","code":""},{"path":"module-11.html","id":"r-markdown-files","chapter":"Module 11","heading":"R Markdown Files","text":"R Markdown provides easy way produce rich, fully-documented reproducible analysis. combines code, results, commentary, metadata needed reproduce analysis R. allows include chunks code file along text. R Markdown supports many output formats PDF, Word, slideshows, presentations etc.R Markdown files can used many ways. instance, can utilized communicating decision makers, wants focus conclusions, code behind analysis; collaborating data analysts, interested conclusions reached . addition, can used environment analysis.Even modules written using R Markdown files. module learn create R Markdown file basic functionalities.","code":""},{"path":"module-11.html","id":"creating-r-markdown-files","chapter":"Module 11","heading":"Creating R Markdown Files","text":"R Markdown files .Rmd extensions. create R Markdown files, need rmarkdown package. don’t need explicitly install load package, RStudio automatically needed.can create new R Markdown file File > New File > R Markdown… (top panel; top left corner)mentioned earlier, R Markdown can produce files various formats (PDF, Word, HTML etc.). bootcamp, focus PDF output format. PDF output format requires installing LaTex distribution machine. several traditional options including MikTeX, MacTeX, TeX Live, recommended use TinyTeX.can install TinyTeX R package tinytex. Run following code console:","code":"\ntinytex:: install_tinytex()"},{"path":"module-11.html","id":"r-markdown-file-components","chapter":"Module 11","heading":"R Markdown File Components","text":"","code":""},{"path":"module-11.html","id":"yaml","chapter":"Module 11","heading":"YAML","text":"top part R Markdown file called YAML header. surrounded --s stores metadata needed document (example, file title, author, output format etc.)","code":""},{"path":"module-11.html","id":"text-formatting-with-markdown","chapter":"Module 11","heading":"Text Formatting with Markdown","text":"","code":""},{"path":"module-11.html","id":"fonts","chapter":"Module 11","heading":"Fonts","text":"Markdown designed easy read, write, learn. can find basic guide help format texts document:need type plain text, like word document (just type ).need type plain text, like word document (just type ).Use **  ** operator change font type bold. instance, Hello typed **Hello**.Use **  ** operator change font type bold. instance, Hello typed **Hello**.Use _   _ operator use italics font. example, Hello typed _Hello_.Use _   _ operator use italics font. example, Hello typed _Hello_.Use ~~ ~~ operator cross words . example, Hello typed ~~Hello~~.Use ~~ ~~ operator cross words . example, Hello typed ~~Hello~~.","code":""},{"path":"module-11.html","id":"headers","chapter":"Module 11","heading":"Headers","text":"can create headers text using # operator control size simply adding one # front text like denote header.","code":"\n\n# Top Level Header (For example, Question 1)\n\n## Second Level Header (For example, Question 1 part a)\n\n### Third Level Header\n\n#### and so on"},{"path":"module-11.html","id":"block-quotes","chapter":"Module 11","heading":"Block Quotes","text":"can create block quote using > operator. example line belowwill produce following result:first block quote","code":"\n> Your first block quote"},{"path":"module-11.html","id":"lists-1","chapter":"Module 11","heading":"Lists","text":"R Markdown can create ordered unordered lists. create unordered list, use * operator:Bullet point 1Bullet point 2\nbullet point 2 \nbullet point 2 b\nbullet point 2 abullet point 2 bTo create ordered lists, simply use numbers:Bullet point 1Bullet point 2\nbullet point 2a\nbullet point 2b\nbullet point 2abullet point 2b","code":"* Bullet point 1\n\n* Bullet point 2\n\n  * bullet point 2a\n\n  * bullet point 2b1. Bullet point 1\n\n2. Bullet point 2\n   * bullet point 2a\n   * bullet point 2b"},{"path":"module-11.html","id":"tables","chapter":"Module 11","heading":"Tables","text":"Use following formatting style create tables R Markdown:","code":"First Header  | Second Header\n------------- | -------------\nContent Cell  | Content Cell\nContent Cell  | Content Cell"},{"path":"module-11.html","id":"links","chapter":"Module 11","heading":"Links","text":"Use following format insert link text:produces link desired webpage can included text: first link","code":"[Your first link](http://posit.co)"},{"path":"module-11.html","id":"inline-equations","chapter":"Module 11","heading":"Inline Equations","text":"Use $ $ operator include equations text. example, \\(= \\pi*r^{2}\\) typed $= \\pi*r^{2}$.","code":""},{"path":"module-11.html","id":"line-breaks","chapter":"Module 11","heading":"Line Breaks","text":"order start new paragraph new line, need sure white space exists two paragraphs/line:first lines.another line.Another useful way divide different parts file including horizontal lines. can achieve using *** operator:produce horizontal line .Finally, want start paragraph line new page, use \\newpage command:","code":"This is the first lines.\n\n\nAnd here we have another line.***\\newpage"},{"path":"module-11.html","id":"r-chunks-of-code","chapter":"Module 11","heading":"R Chunks of Code","text":"addition plain text, can also run R codes inside file include along plain text show code used produce results.can run include R code manually typing chunk deliminiters ```{r} ```. display code used results code produced. example, following chunk run code specified inside produce corresponding output:","code":"```{r}\n\nprint(2 + 2)\n\n``` #> [1] 4"},{"path":"module-11.html","id":"options","chapter":"Module 11","heading":"Options","text":"Chunk can customized options, , arguments supplied chunk header. nearly 60 options can use customize code, module discuss important commonly used options:eval = FALSE prevents code evaluated. results, code run results produced. useful displaying example code.include = FALSE runs code, doesn’t show code results final document.echo = FALSE prevents code, results appearing finished file.results = 'hide' prevents results, code appearing finished file.","code":"```{r, eval = FALSE}\nprint(2 + 2)\n``` ```{r, include = FALSE}\nprint(2 + 2)\n``` ```{r, echo = FALSE}\nprint(2 + 2)\n``` ```{r, results = 'hide'}\nprint(2 + 2)\n``` "},{"path":"module-11.html","id":"generating-r-markdown-files","chapter":"Module 11","heading":"Generating R Markdown Files","text":"done text code want include file, can generate R Markdown files clicking knit button top editor pane. drop-menu allows pick output formats. recommended use HTML format preparing file fixing error. display file Viewer tab nicely conveniently. finalize code text, can generate file clicking knit button selecting PDF output format.","code":""},{"path":"module-11.html","id":"additional-resources","chapter":"Module 11","heading":"Additional Resources","text":"discussed basic crucial parts R Markdown files creating, formatting, generating files. course, R Markdown allows much . Unfortunately, beyond scope bootcamp don’t enough time cover topics. case interested exploring topic , can find list useful links resources.R Markdown WebpageR Markdown Reference GuideR Markdown CookbookR Markdown: Definitive Guide","code":""},{"path":"problem-set-3.html","id":"problem-set-3","chapter":"Problem Set 3","heading":"Problem Set 3","text":" ","code":""},{"path":"problem-set-3.html","id":"problem-1-use-base-r","chapter":"Problem Set 3","heading":"Problem 1 (Use Base R)","text":"Download carseats data set Courseworks import R (don’t forget convert character variables factors). provides information sales child car seats 400 different stores. contains following variables: Sales - Unit sales (thousands) locationSales - Unit sales (thousands) locationAdvertising - Local advertising budget company location (thousands dollars)Advertising - Local advertising budget company location (thousands dollars)Population - Population size region (thousands)Population - Population size region (thousands)Price - Price company charges car seats sitePrice - Price company charges car seats siteShelveLoc - factor levels Bad, Good Medium indicating quality shelving location car seats siteShelveLoc - factor levels Bad, Good Medium indicating quality shelving location car seats siteAge - Average age local populationAge - Average age local populationUrban - factor levels Yes indicate whether store urban rural locationUrban - factor levels Yes indicate whether store urban rural locationUS - factor levels Yes indicate whether store US \n US - factor levels Yes indicate whether store US  Compare average age local population US non-US stores displaying boxplots. Customize boxplots follows: add labels, change colors, add notches. Summarize quality shelving locations displaying barplot. Customize discussed previous question ( notches ). Plot side--side barplots displaying frequency ShelveLoc variable urban rural areas. Customize plot discussed . Plot Sales variable Price variable. Label plot axes accordingly, change shape points triangular, change color points based whether store located urban (orange color) rural (green color) area add corresponding legend plot, change size points 0.9. Combine histogram Price variable boxplot Population variable one image. Customize plots discussed part (1) (notches histogram). ","code":""},{"path":"problem-set-3.html","id":"problem-2-use-ggplot2-package","chapter":"Problem Set 3","heading":"Problem 2 (Use ggplot2 Package)","text":"problem, working ames_housing.csv dataset (available Courseworks). contains information homes sold Ames, Iowa, 2006 2010. dataset includes 18 variables covers wide range home characteristics. purpose assignment, going work following variables:Sales_Price - Sale PriceNeighborhood - Physical locations within Ames city limitsRoof_Style - Type roofFence - Fence qualityTotRms_AbvGrd - Total rooms grade (include bathrooms)Gr_Liv_Area - grade(ground) living area square feet Plot histogram Sale_Price variable: add labels (title, subtitle, x y labels); adjust limits x axis adding new ticks (step size = 100,000) changing angle ticks 60; change theme minimal; change colors bins bin outlines (pick colors); add blue vertical line represents mean value variable. Use stacked barplot visualize relationship two categorical variables (make sure bars height); add labels plot (title, subtitle, x y labels). Plot boxplot Sales_Price variable reflecting North_Ames College_Creek neighborhoods; add black dots boxplots represent average prices groups; make boxplots transparent (use transparency rate 0.45). Add new variable dataset (name Rooms) split homes dataset following three groups based total number rooms ground: \"2-4\", \"5-8\", \"9 \". words, need create factor variable 3 levels converting TotRms_AbvGrd variable. (Hint: might want check case_when() function dpyr package).\nPlot barplot Rooms variable: add labels barplot display exact frequency category. Plot another barplot Rooms variable labels display frequency category percentages. Now create composition (assemble) plots (pick layout). words, combine barplots one plot.Add new variable dataset (name Rooms) split homes dataset following three groups based total number rooms ground: \"2-4\", \"5-8\", \"9 \". words, need create factor variable 3 levels converting TotRms_AbvGrd variable. (Hint: might want check case_when() function dpyr package).Plot barplot Rooms variable: add labels barplot display exact frequency category. Plot another barplot Rooms variable labels display frequency category percentages. Now create composition (assemble) plots (pick layout). words, combine barplots one plot. Plot Sale_Price variable (Y) Gr_Liv_Area variable (X): add labels scatterplot (title, subtitle, caption, x y labels) change colors; change size shape datapoints; change color datapoints based Rooms variable; move legends left. Plot Sale_Price variable (Y) Gr_Liv_Area variable (X) level Rooms variable separately, using facets.","code":""},{"path":"ps-3-solutions.html","id":"ps-3-solutions","chapter":"PS 3 Solutions","heading":"PS 3 Solutions","text":"  ","code":""},{"path":"ps-3-solutions.html","id":"problem-1-use-base-r-1","chapter":"PS 3 Solutions","heading":"Problem 1 (Use Base R)","text":"Compare average age local population US non-US stores displaying boxplots. Customize boxplots follows: add labels, change colors, add notches. Summarize quality shelving locations displaying barplot. Customize discussed previous question ( notches ). Plot side--side barplots displaying frequency ShelveLoc variable urban rural areas. Customize plot discussed . Plot Sales variable Price variable. Label plot axes accordingly, change shape points triangular, change color points based whether store located urban (orange color) rural (green color) area add corresponding legend plot, change size points 0.9. Combine histogram Price variable boxplot Population variable one image. Customize plots discussed part (1) (notches histogram). ","code":"\ndata1 <- read.csv(file = \"carseats.csv\", header = T, stringsAsFactors = T)\n\nboxplot(data1$Age ~ data1$US,\n        \n        xlab = \"Store Loc.\",\n        \n        ylab = \"Age\",\n        \n        names = c(\"Non-US\", \"US\"),\n        \n        main = \"Age of Population for the US and non-US stores\",\n        \n        col = c(\"lightblue\", \"lightcoral\"),\n        \n        border = c(\"dodgerblue\", \"red\"),\n        \n        notch = T)\nbarplot(table(data1$ShelveLoc),\n        \n        xlab = \"Quality of Shelving Loc.\",\n        \n        ylab = \"Num. of Stores\",\n        \n        main = \"Quality of Shelving Loc. Count\",\n        \n        col = \"lightblue\",\n        \n        border = \"blue\")\nbarplot(table(data1[, c(\"ShelveLoc\", \"Urban\")]),\n        \n        beside = TRUE,\n        \n        legend.text = c(\"Bad\", \"Good\", \"Medium\"),\n        \n        ylab = \"Num. of Stores\",\n        \n        xlab = \"Store Location: Urban\",\n        \n        main = \"Qual. of Shelving Loc. vs Urban/Rural\",\n        \n        col = c(\"lightblue\", \"lightcoral\", \"orange\"))\ncolors <- c(\"green\", \"orange\")\n\nplot(x = data1$Price,\n     \n     y = data1$Sales,\n     \n     xlab = \"Price\",\n     \n     ylab = \"Sales\",\n     \n     main = \"Sales vs Price\",\n     \n     col = colors[data1$Urban],\n     \n     pch = 2,\n     \n     cex  = 0.9)\n\n\nlegend(\"topleft\", legend = c(\"Rural\", \"Urban\"), pch = 2, col = colors)\npar(mfrow = c(1, 2))\n\nhist(data1$Price,\n     \n     xlab = \"Price\",\n     \n     ylab = \"Num. of Stores\",\n     \n     main = \"Histogram of Price\",\n     \n     col = \"pink\",\n     \n     border = \"violetred\")\n\n\nboxplot(data1$Population,\n        \n        xlab = \"Population\",\n        \n        ylab = \"Values\",\n        \n        main = \"Boxplot of Population\",\n        \n        col = \"lightblue\",\n        \n        border = \"dodgerblue\")"},{"path":"ps-3-solutions.html","id":"problem-2-use-ggplot2-package-1","chapter":"PS 3 Solutions","heading":"Problem 2 (Use ggplot2 Package)","text":"Plot histogram Sale_Price variable: add labels (title, subtitle, x y labels); adjust limits x axis adding new ticks (step size = 100,000) changing angle ticks 60; change theme minimal; change colors bins bin outlines (pick colors); add blue vertical line represents mean value variable. Use stacked barplot visualize relationship two categorical variables (make sure bars height); add labels plot (title, subtitle, x y labels). Plot boxplot Sales_Price variable reflecting North_Ames College_Creek neighborhoods; add black dots boxplots represent average prices groups; make boxplots transparent (use transparency rate 0.45). Add new variable dataset (name Rooms) split homes dataset following three groups based total number rooms ground: \"2-4\", \"5-8\", \"9 \". words, need create factor variable 3 levels converting TotRms_AbvGrd variable. (Hint: might want check case_when() function dpyr package).\nPlot barplot Rooms variable: add labels barplot display exact frequency category. Plot another barplot Rooms variable labels display frequency category percentages. Now create composition (assemble) plots (pick layout). words, combine barplots one plot.Add new variable dataset (name Rooms) split homes dataset following three groups based total number rooms ground: \"2-4\", \"5-8\", \"9 \". words, need create factor variable 3 levels converting TotRms_AbvGrd variable. (Hint: might want check case_when() function dpyr package).Plot barplot Rooms variable: add labels barplot display exact frequency category. Plot another barplot Rooms variable labels display frequency category percentages. Now create composition (assemble) plots (pick layout). words, combine barplots one plot. Plot Sale_Price variable (Y) Gr_Liv_Area variable (X): add labels scatterplot (title, subtitle, caption, x y labels) change colors; change size shape datapoints; change color datapoints based Rooms variable; move legends left. Plot Sale_Price variable (Y) Gr_Liv_Area variable (X) level Rooms variable separately, using facets.","code":"\n\ndata <- read.csv(\"ames_housing.csv\", header = T, stringsAsFactors = TRUE)\n\nlibrary(tidyverse)\n#> ── Attaching packages ─────────────────── tidyverse 1.3.2 ──\n#> ✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n#> ✔ tibble  3.1.8      ✔ dplyr   1.0.10\n#> ✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n#> ✔ readr   2.1.3      ✔ forcats 0.5.2 \n#> ── Conflicts ────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n\nggplot(data = data) +\n    \ngeom_histogram(aes(x = Sale_Price),\n               \n               fill=\"steelblue1\",\n               \n               color=\"steelblue\") +\n  \n  geom_vline(aes(xintercept = mean(Sale_Price)),\n               \n           color = \"blue\",\n               \n           size = 1) +\n\n  labs(title = \"Sale Price Histogram\",\n       \n       subtitle = \"From ames_housing dataset\",\n       \n       x = \"Sale Price\",\n       \n       y = \"Frequency\") +\n  \n  scale_x_continuous(breaks = seq(0, 750000, 100000), limits = c(0, 750000)) +\n  \n  theme_minimal() +\n  \n  theme(axis.text.x=element_text(angle = 60))\n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`.\n#> Warning: Removed 1 rows containing non-finite values\n#> (stat_bin).\n#> Warning: Removed 2 rows containing missing values\n#> (geom_bar).\nggplot(data = data) +\n  \n  geom_bar(mapping = aes(x = Roof_Style, fill = Fence),\n           \n           position = \"fill\") +\n  \n  labs(title=\"Distribution of Fence for Different Roof Style\",\n      \n      subtitle=\"From ames_housing dataset\",\n      \n      x=\"Roof Style\",\n      \n      y=\"Frequentist Probability\")\n\ndata1 <- data %>% filter(Neighborhood %in% c(\"College_Creek\", \"North_Ames\"))\n\nggplot(data = data1) +\n  \ngeom_boxplot(aes(x = Neighborhood, y = Sale_Price), alpha = 0.45) +\n  \nstat_summary(aes(x = Neighborhood, y = Sale_Price),\n               \n             fun = \"mean\",\n               \n             geom = \"point\",\n               \n             color = \"black\")\ncategorize <- function(x) {\n  \n  case_when(x<=4 & x>=2 ~ \"2-4\",\n            \n            x<=8 & x>=5 ~ \"5-8\",\n            \n            x>=9 ~ \"9 or more\") %>%\n    \n  as.factor()\n  \n}\n\ndata <- data %>%\n  \n  mutate(Rooms = categorize(TotRms_AbvGrd))\ngg1 <- ggplot(data = data) +\n  \n  geom_bar(mapping = aes(x = Rooms), fill = \"gray70\") +\n  \n  geom_text(aes(x = Rooms, label = ..count..),\n            \n            stat = \"count\",\n            \n            colour = \"black\")\n\ndata2 <- data %>%\n  \n  count(Rooms) %>%\n  \n  mutate(perc = n / sum(n))\n\ngg2 <- ggplot(data2, aes(x = Rooms, y = perc)) +\n  \n  geom_bar(stat = \"identity\", fill = \"gray70\") +\n  ## add percentage labels\n  \n  geom_text(aes(label = scales::percent(perc))) +\n  \n  scale_y_continuous(labels = scales::percent) +\n  \n  labs(y = \"Percentage\")\n\nlibrary(patchwork)\n#> Warning: package 'patchwork' was built under R version 4.2.3\n\ngg1/gg2\n  ggplot(data = data) + \n  \n  geom_point(mapping = aes(x = Gr_Liv_Area, y = Sale_Price, color = Rooms),\n               \n             size = 0.8,\n             \n             shape = 22) +\n  \n  labs(x = \"Above Ground Living Area\",\n       \n       y = \"Sale Price\",\n       \n       title = \"Sale Price - Above Ground Living Area Scatter Plot\",\n       \n       subtitle = \"From ames_housing data\",\n       \n       caption = \"The plot resembles a correlation between sale price and above ground living area.\") +\n  \n  theme(plot.title=element_text(size=15, face=\"bold\", color = \"red\"),\n             \n        axis.title.x=element_text(color = \"blue\"),\n             \n        axis.title.y=element_text(color = \"blue\"),\n        \n        legend.position = \"left\")\n\nggplot(data = data) + \n    \n  geom_point(mapping = aes(x = Gr_Liv_Area, y = Sale_Price),\n             \n             size = 0.8,\n             \n             shape = 22,\n             \n             color = \"steelblue\") +\n    \n  facet_wrap(~ Rooms)"},{"path":"module-12.html","id":"module-12","chapter":"Module 12","heading":"Module 12","text":" ","code":""},{"path":"module-12.html","id":"probability","chapter":"Module 12","heading":"Probability","text":"Probability theory foundation statistics, R plenty machinery working probability, probability distributions, random variables. recipes module show calculate probabilities quantiles, calculate quantiles probabilities, generate random variables drawn distributions, plot distributions, forth.working different statistical distributions, often want make probabilistic statements based distribution. typically want know one four things:value probability density function (pdf) particular pointThe value cumulative distribution function (cdf) particular pointThe quantile value corresponding particular probabilityA random draw values particular distributionR functions obtaining density, distribution, quantile random values. general naming structure relevant R functions :dname calculates pdf input xpname calculates cdf input xqname calculates quantile input probabilityrname generates random draw particular distributionNote name functions represents name given distribution. statistics, many well-known commonly used probability distributions can divided two groups: discrete continuous distributions.Discrete distributions whose possible values either constitute finite set else can listed infinite sequence first element, second element, (“countably” infinite). contrast, continuous distributions whose possible values consist either numbers single interval number line numbers disjoint union intervals.R functions almost well-studied commonly used distributions. tables list :* can d, p, q, r.module discuss binomial, geometric, normal distributions (basic (fundamental) distributions chosen simplicity, order illustrate R functions work; later functions can generalized , complex distributions). Let’s dive .","code":""},{"path":"module-12.html","id":"bernoulli-trials","chapter":"Module 12","heading":"Bernoulli Trials","text":"introducing binomial distribution, need discuss Bernoulli random variables (also known Bernoulli trials). random variable whose possible values 0 (failure) 1 (success) called Bernoulli random variable.Suppose X Bernoulli random variable. ,","code":""},{"path":"module-12.html","id":"binomial-distribution","chapter":"Module 12","heading":"Binomial Distribution","text":"many experiments conform either exactly approximately following list requirements:experiment consists sequence n smaller experiments called trials, n fixed advance experimentEach trial can result one two possible outcomes, success (S) failure (F).trials independent, outcome particular trial influence outcome trial.probability success P(S) constant trial trial; denote probability p.experiment 4 conditions satisfied called binomial experiment. distribution describes process called Binomial Distribution. counts number successes among n trials.probability mass function (pmf) (pdf discrete distributions) binomial distribution given \\[\\begin{align*}\nb(x; n, p) = \\binom{n}{x} p^x(1-p)^{n-x} \\quad \\quad x = 0, 1, ..., n\n\\end{align*}\\]\\(\\binom{n}{x} = \\frac{n!}{(n-x)!x!}\\) \\(n! = 1 \\times 2 \\times ... \\times n\\).words, probability mass function calculates probability binomial distribution take particular value x.Let’s consider following example:Suppose probability train time given day 0.7. Next week, Monday Friday, important meetings business partners every day. train late, miss important meeting particular day. Assume train schedules independent one another.Now let’s count number days train time. possible values 0, 1, 2, 3, 4, 5. can already guess, binomial distribution n = 5 p = 0.7.","code":""},{"path":"module-12.html","id":"dbinom-function","chapter":"Module 12","heading":"dbinom() Function","text":"can use probability mass function calculate probabilities certain events. example, probability attend 3 meetings , , x = 3 ?answer question, use dbinom() function:can manually well using definition pmf binomial distribution:","code":"\n\ndbinom(x = 3, size = 5, prob = 0.7)\n#> [1] 0.3087\n\nchoose(n = 5, k = 3)*(0.7^3)*(0.3^2)\n#> [1] 0.3087"},{"path":"module-12.html","id":"pbinom-function","chapter":"Module 12","heading":"pbinom() Function","text":"Now, suppose want calculate probability attend 4 meetings, , either 0, 1, 2, 3, 4. , need cumulative distribution function (cdf) binomial distribution. can use pbinom() function calculate cumulative probabilities:noticed, pbinom() function summation dbinom() functions:","code":"\n\npbinom(q = 4, size = 5, prob = 0.7)\n#> [1] 0.83193\n\ndbinom(x = 0, size = 5, prob = 0.7) +\ndbinom(x = 1, size = 5, prob = 0.7) + \ndbinom(x = 2, size = 5, prob = 0.7) + \ndbinom(x = 3, size = 5, prob = 0.7) + \ndbinom(x = 4, size = 5, prob = 0.7)\n#> [1] 0.83193"},{"path":"module-12.html","id":"geometric-distribution","chapter":"Module 12","heading":"Geometric Distribution","text":"Geometric Distribution one parameter p (probability success) describes number Bernoulli trials needed get first success. probability mass function geometric distribution can defined follows:\\[\\begin{align*}\ng(x; p) = (1-p)^{x-1}p \\quad \\quad x = 1, 2, 3,  ...\n\\end{align*}\\]example describes geometric distribution: starting fixed time, observe gender newborn child certain hospital girl (G) born. Let P(G) = p = 0.55 assume successive births independent.","code":""},{"path":"module-12.html","id":"dgeom-function","chapter":"Module 12","heading":"dgeom() Function","text":"dgeom() function calculates probability geometric distribution take particular value x. instance, let’s calculate probability need observe 6 newborn children get first girl:","code":"\n\ndgeom(x = 6, prob = 0.55)\n#> [1] 0.004567071"},{"path":"module-12.html","id":"pgeom-function","chapter":"Module 12","heading":"pgeom() Function","text":"Like pbinom() function, pgeom() calculates cumulative probabilities (cdf’s). example, probability need observe 5 newborn children get first girl? words, probability geometric distribution take either 1, 2, 3, 4, 5 values?","code":"\n\npgeom(q = 5, prob = 0.55)\n#> [1] 0.9916962"},{"path":"module-12.html","id":"normal-distribution","chapter":"Module 12","heading":"Normal Distribution","text":"Normal Distribution important commonly used distribution probability statistics. Many numerical populations distributions can fit closely appropriate normal curve. Normal distributions two parameters: mean, \\(\\mu\\), standard deviation, \\(\\sigma\\). probability density functions (pdf’s) defined \\[\\begin{align*}\nf(x; \\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{\\frac{-(x - \\mu)^2}{2\\sigma^2}}   \\quad  -\\infty < x < \\infty\n\\end{align*}\\]normal distribution bell-shaped, symmetric, centered mean value. distribution continues positive negative infinity, area close center.Normal distributions can look quite different. Specifically, normal distribution can adjusted using mean standard deviation. Changing mean value normal distribution shifts curve left right. Changing standard deviation normal distribution stretches constricts curve around mean. examples normal distribution:","code":""},{"path":"module-12.html","id":"dnorm-function","chapter":"Module 12","heading":"dnorm() Function","text":"dnorm() calculates value probability density function (pdf) normal distribution particular point x. words, calculates height normal curve certain point x. Suppose normal distribution mean value 2.5 standard deviation 0.5. ,","code":"\n\nx <- seq(-10, 10, by = .1)\n\n\ny <- dnorm(x, mean = 2.5, sd = 0.5)\n\n\nplot(x,y)"},{"path":"module-12.html","id":"pnorm-function","chapter":"Module 12","heading":"pnorm() Function","text":"calculate value cumulative distribution function (cdf) certain value x, , probability normal distribution take values less x, use pnorm() function. Suppose, normal distribution mean = 2 standard deviation = 5. Now let’s calculate probability randomly selected observation distribution less 3:can even use function calculate probability obtaining certain intervals. probability randomly selected observation distribution 1.5 3?","code":"\n\npnorm(q = 3, mean = 2, sd = 5)\n#> [1] 0.5792597\n\npnorm(q = 3, mean = 2, sd = 5) - pnorm(q = 1.5, mean = 2, sd = 5)\n#> [1] 0.1190875"},{"path":"module-12.html","id":"qnorm-function","chapter":"Module 12","heading":"qnorm() Function","text":"calculate quantiles normal distribution, use qnorm() function. takes probability value returns number whose cdf matches input value. example, let’s find 0.6 quantile (also known 60th percentile) normal distribution mean = 2 standard deviation = 5:can think inverse pnorm() function. Let’s illustrate :","code":"\n\nqnorm(p = 0.6, mean = 2, sd = 5)\n#> [1] 3.266736\n\nqnorm(p = 0.6, mean = 2, sd = 5)\n#> [1] 3.266736\n\npnorm(q = 3.266736, mean = 2, sd = 5)\n#> [1] 0.6"},{"path":"module-12.html","id":"rnorm-function","chapter":"Module 12","heading":"rnorm() Function","text":"rnorm() function used generate random values normal distribution. Suppose, normal distribution mean = 2 standard deviation = 5. Let’s generate 50 observations distribution visualize :","code":"\n\nx <- rnorm(n = 50, mean = 2, sd = 5)\n\nhist(x,\n     \n     xlab = \"VALUES\",\n     \n     ylab = \"FREQUENCY\",\n     \n     main = \"Generating Values from a  Normal Distribution\",\n     \n     col = \"orange\",\n     \n     border = \"black\")"},{"path":"module-12.html","id":"generating-data","chapter":"Module 12","heading":"Generating Data","text":"","code":""},{"path":"module-12.html","id":"generating-reproducible-random-numbers","chapter":"Module 12","heading":"Generating Reproducible Random Numbers","text":"Let’s generate 10 random values normal distribution mean = 3 standard deviation = 4. 3 times:notice, every time generate sample random numbers, generates different set values, done random.generating random numbers, may often want reproduce sequence “random” numbers every time program executes. way, get results run run.R, set.seed() function sets random number generator known state. function takes one argument, integer. positive integer work, must use one order get initial state.function returns nothing. works behind scenes, initializing (reinitializing) random number generator. key using seed restarts random number generator back place:","code":"\n\nrnorm(n = 10, mean = 3, sd = 4)\n#>  [1] -0.52711769 -3.24022011  5.60732657  7.98494058\n#>  [5]  3.30136268  5.92960566  5.72930879  1.67258555\n#>  [9]  0.07446109 -4.55392386\n\nrnorm(n = 10, mean = 3, sd = 4)\n#>  [1]  4.2559431  2.3579255 -0.5941688  7.8496901  0.2835305\n#>  [6]  1.4535843  5.2583488  1.6895225  5.9364717  1.2319979\n\nrnorm(n = 10, mean = 3, sd = 4)\n#>  [1]  6.401554 -2.137234  1.725130  0.587484  2.135431\n#>  [6] -3.643413  4.507226  5.976942  6.413471  7.115429\n\nset.seed(1)    # Initialize generator to known state\n\nrnorm(n = 10, mean = 3, sd = 4)   # Generate ten random numbers\n#>  [1]  0.4941848  3.7345733 -0.3425144  9.3811232  4.3180311\n#>  [6] -0.2818735  4.9497162  5.9532988  5.3031254  1.7784465\n\nset.seed(1)    # Reinitialize to the same known state\n\nrnorm(n = 10, mean = 3, sd = 4)   # Generate the same ten \"random\" numbers\n#>  [1]  0.4941848  3.7345733 -0.3425144  9.3811232  4.3180311\n#>  [6] -0.2818735  4.9497162  5.9532988  5.3031254  1.7784465"},{"path":"module-12.html","id":"generating-a-random-sample","chapter":"Module 12","heading":"Generating a Random Sample","text":"sample() function randomly select n items set values. instance:sample() function normally samples without replacement, meaning select item twice. statistical procedures require sampling replacement, means one item can appear multiple times sample. Specify replace=TRUE sample replacement:","code":"\n\nx <- 1:20\n\nsample(x, 6)\n#> [1]  9 15  5 20 17 14\n\nx <- 1:20\n\nsample(x, 6, replace = TRUE)\n#> [1]  5  5  2 10 12 15"},{"path":"module-12.html","id":"generating-random-sequences","chapter":"Module 12","heading":"Generating Random Sequences","text":"Sometimes want generate random sequence, simulated sequence Bernoulli trials. can using sample() function. Sample n draws set possible values, set replace=TRUE. Suppose toss coin 15 times want generate results 15 trials. ,default, sample() choose equally among set elements probability selecting either H T 0.5. Bernoulli trial, probability p success necessarily 0.5. can bias sample using prob argument sample; argument vector probabilities, one set element.Suppose want generate 20 Bernoulli trials (toss coin 20 times) probability getting heads p = 0.8. Thus, set probability tails 0.2:","code":"\n\nsample(c(\"H\", \"T\"), 15, replace = TRUE)\n#>  [1] \"H\" \"T\" \"H\" \"T\" \"T\" \"T\" \"T\" \"H\" \"T\" \"T\" \"T\" \"T\" \"T\" \"H\"\n#> [15] \"H\"\n\nsample(c(\"H\", \"T\"), 20, replace = TRUE, prob = c(0.8, 0.2))\n#>  [1] \"H\" \"T\" \"H\" \"H\" \"H\" \"H\" \"H\" \"H\" \"H\" \"H\" \"T\" \"H\" \"H\" \"H\"\n#> [15] \"H\" \"H\" \"H\" \"H\" \"H\" \"T\""},{"path":"module-12.html","id":"randomly-permutting-a-vector","chapter":"Module 12","heading":"Randomly Permutting a Vector","text":"Sometimes want generate random permutation vector. v vector, sample(v) returns random permutation:","code":"\n\nx <- 1:10\n\nprint(x)\n#>  [1]  1  2  3  4  5  6  7  8  9 10\n\nsample(x)             # permutation 1\n#>  [1]  6  1  3  8 10  4  2  7  9  5\n\nsample(x)             # permutation 2\n#>  [1]  4  8  1  9  6 10  3  7  5  2"},{"path":"module-13.html","id":"module-13","chapter":"Module 13","heading":"Module 13","text":" ","code":""},{"path":"module-13.html","id":"data-analysis","chapter":"Module 13","heading":"Data Analysis","text":"","code":""},{"path":"module-13.html","id":"introduction-1","chapter":"Module 13","heading":"Introduction","text":"Now equipped enough programming tools can finally move Data Analysis part bootcamp. use new tools data wrangling programming perform certain statistical procedures, including Exploratory Data Analysis (EDA) Formal Inference. general, EDA iterative process involvesGenerating questions dataSearching answers visualizing, transforming, modelling dataUsing learn refine questions /generate new questionsEDA formal process strict set rules. initial phases EDA feel free investigate every idea occurs . ideas pan , dead ends. exploration continues, home particularly productive areas ’ll eventually write communicate others.EDA important part data analysis, always need investigate quality data. Data cleaning just one application EDA: ask questions whether data meets expectations . data cleaning, ’ll need deploy tools EDA: visualization, transformation, modelling.hand, formal inference process inferring properties underlying distribution variables. infers properties population testing hypothesis deriving estimates. module, cover t - tests population mean (one sample two sample tests), \\(\\chi^2\\) goodness fit test \\(\\chi^2\\) test independence, predictive models.module, going cover aspects mathematical theory underlies models. , however, build intuition statistical models work, give family useful tools (R functions) allow use models better understand data. Specifically, learnhow models work mechanistically gain insights model tells datahow pull known patterns real dataNote: objective bootcamp exposing various statistical models theoretical topics. main focus get familiar useful R functions come handy start coursework MA program. Thus, procedures discussed module following module might seem basic, used showcase R functionality.illustrate tools, use carseats_full dataset, available Courseworks. Data Description: company interested studying sales related certain products produce. collected data sales child car seats 400 different stores. data contains following variables:Sales - Unit sales (thousands) locationCompPrice - Price charged competitor locationIncome - Community income level (thousands dollars)Advertising - Local advertising budget company location (thousands dollars)Population - Population size region (thousands)Price - Price company charges car seats siteShelveLoc - factor variables levels Bad, Good, Medium indicating quality shelving location car seats siteAge - Average age local populationEducation - Education level locationUrban - factor variable levels Yes indicate whether store urban rural locationUS - factor variable levels Yes indicate whether store US  ","code":""},{"path":"module-13.html","id":"hypothesis-tests","chapter":"Module 13","heading":"Hypothesis Tests","text":"statistics, population total group individuals objects want make conclusions . words, totality individuals objects interest statistical study. Typically, observe every individual/object population due limitations. Instead measuring every item population, take sample. sample subset cases often small fraction overall population.summary value calculated population called parameter. Similarly, summary value calculated samples called statistic. parameter can estimated sample data either single number (point estimate) entire interval plausible values (confidence interval). Frequently, however, objective investigation estimate parameter decide two contradictory claims parameter correct.Methods accomplishing comprise part statistical inference called hypothesis testing. statistical hypothesis claim assertion either value single parameter, values several parameters, form entire probability distribution. hypothesis test used determine whether results obtained sample convincing enough allow us infer something population.hypothesis-testing problem, two contradictory hypotheses consideration:Null Hypothesis, denoted \\(H_0\\), claim initially assumed true. claim difference see sample results compared population due chance, , due uninteresting variation randomness sampling distribution expected.Alternative Hypothesis, denoted \\(H_a\\), assertion contradictory \\(H_0\\). claim difference sample results compared population due chance.two types hypotheses:alternative hypothesis equally interested deviations either side null hypothesis value called two-sided alternative corresponding hypothesis test called two-sided test.alternative hypothesis focuses deviations null hypothesis value one direction called one-sided alternative corresponding hypothesis test called one-sided test.null hypothesis rejected favor alternative hypothesis sample evidence suggests \\(H_0\\) fit data well. sample strongly contradict \\(H_0\\), continue believe plausibility null hypothesis. two possible conclusions hypothesis-testing analysis reject \\(H_0\\) fail reject \\(H_0\\).help us evaluate null model (model null hypothesis), use probability called P-value. probability calculated assuming null hypothesis true. p-value large, indicates observed results look like result natural variation expect see take random sample. large p-value supports null hypothesis.hand, smaller p-value , less inclined think sample result simply due natural variation. small p-value supports alternative hypothesis.words, p-value probability, calculated assuming null hypothesis true, obtaining value test statistic least contradictory \\(H_0\\) value calculated available sample data.Test Statistic function sample data used basis deciding whether \\(H_0\\) rejected. Values test statistic tend result \\(H_0\\) true quite different typically observed \\(H_0\\) true.conclusion reached hypothesis testing analysis selecting number \\(\\alpha\\), called significance level test, reasonably close 0:\\(H_0\\) rejected favor \\(H_a\\) p-value \\(\\leq\\) \\(\\alpha\\)Whereas \\(H_0\\) rejected p-value > \\(\\alpha\\) general, basic structure hypothesis test follows:overall model related assumptions madeThe null alternative hypotheses specified. Usually null hypothesis specifies particular value parameterWith given data, value test statistic calculatedUnder general assumptions, well assuming null hypothesis true, distribution test statistic knownGiven distribution value test statistic, well form alternative hypothesis, p-value calculatedBased p-value pre-specified level significance, conclusion made.module consider hypothesis tests concerning various population parameters. start population mean. ","code":""},{"path":"module-13.html","id":"one-sample-t-test-for-a-population-mean","chapter":"Module 13","heading":"One Sample t-test for a Population Mean","text":"context testing value population mean \\(\\mu\\), possible hypothesis statements :\\[\\begin{align*}\nH_0: \\mu = \\mu_0  \\quad versus \\quad H_a: \\mu \\neq \\mu_0\n\\end{align*}\\]\\[\\begin{align*}\nH_0: \\mu = \\mu_0  \\quad versus \\quad H_a: \\mu > \\mu_0\n\\end{align*}\\]\\[\\begin{align*}\nH_0: \\mu = \\mu_0  \\quad versus \\quad H_a: \\mu < \\mu_0\n\\end{align*}\\]test statistic given \\[\\begin{align*}\nt = \\frac{\\bar{x} - \\mu_0}{s/\\sqrt{n}} \\sim t(n-1)\n\\end{align*}\\]\\(100(1-\\alpha)\\%\\) confidence interval \\(\\mu\\) given \\[\\begin{align*}\n\\bar{x} \\pm t_{\\alpha/2, n-1}\\frac{s}{\\sqrt{n}}\n\\end{align*}\\]order perform one-sample t-test, following condition must met:Observations must independent one anotherPopulation distribution must nearly normal sample size must sufficiently large (usually, sample size 30 enough satisfy condition)module, asked manually calculate test statistic make conclusion. Instead, using R function get results. illustrate , let’s go back carseats_full dataset.Example:Suppose researcher company suspects stores average spend $5000 advertising, might reasonable given company’s budget. Since don’t access data available stores, instead use sample 400 stores perform statistical test check hypothesis. like test \\(\\alpha = 0.05\\) significance level.given question, null alternative hypotheses given \\[\\begin{align*}\nH_0: \\mu = 5  \\quad versus \\quad H_a: \\mu > 5\n\\end{align*}\\]perform test, use t.test() function R. following arguments:x - (non-empty) numeric vector data valuesy - optional (non-empty) numeric vector data valuesalternative - character string specifying alternative hypothesis, must one “two.sided” (default), “greater” “less”. can specify just initial lettermu - number indicating true value mean (difference means performing two sample test)var.equal - logical variable indicating whether treat two variances equal. TRUE pooled variance used estimate variance otherwise Welch (Satterthwaite) approximation degrees freedom usedconf.level - confidence level intervalNow since work single population, don’t need y argument (come back shortly). x vector Advertising variable, mu 5, alternative greater (options correspond alternative hypothesis), conf.level 0.95, one-sample test don’t need var.equal argument (, come back argument shortly). Thus,function output provides information test statistic (t = 4.917), degrees freedom (df = 399) p-value. output can see p-value approximately 0 less significance level \\(\\alpha = 0.05\\), thus, reject \\(H_0\\) hypothesis.conclude , based sample data, evidence stores average spend $5000 advertising, leadership might want send note store managers asking cut advertising budgets. ","code":"\n\nt.test(x = dataset1$Advertising,\n       \n       alternative = \"greater\",\n       \n       mu = 5,\n       \n       conf.level = 0.95)\n#> \n#>  One Sample t-test\n#> \n#> data:  dataset1$Advertising\n#> t = 4.917, df = 399, p-value = 6.431e-07\n#> alternative hypothesis: true mean is greater than 5\n#> 95 percent confidence interval:\n#>  6.086783      Inf\n#> sample estimates:\n#> mean of x \n#>     6.635"},{"path":"module-13.html","id":"two-sample-t-test-for-a-difference-between-population-means","chapter":"Module 13","heading":"Two Sample t-test for a Difference between Population Means","text":"far ’ve worked one population mean. want compare means taken two populations? case, perform two-sample t-test. context testing difference two population means, possible hypotheses :\\[\\begin{align*}\nH_0: \\mu_1 - \\mu_2 = \\mu_0  \\quad versus \\quad H_a: \\mu_1 - \\mu_2 \\neq \\mu_0\n\\end{align*}\\]\\[\\begin{align*}\nH_0: \\mu_1 - \\mu_2 = \\mu_0  \\quad versus \\quad H_a: \\mu_1 - \\mu_2 > \\mu_0\n\\end{align*}\\]\\[\\begin{align*}\nH_0: \\mu_1 - \\mu_2 = \\mu_0 \\quad versus \\quad H_a: \\mu_1 - \\mu_2 < \\mu_0\n\\end{align*}\\]test statistic given \\[\\begin{align*}\nt = \\frac{(\\bar{x}_1 - \\bar{x}_2) - \\mu_0}{\\sqrt{s_1^2/n_1 + s_2^2/n_2}} \\sim t(n_1 + n_2 - 2)\n\\end{align*}\\]\\(100(1-\\alpha)\\%\\) confidence interval difference two population means given \\[\\begin{align*}\n(\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\alpha/2, n_1 + n_2 - 2}\\sqrt{s_1^2/n_1 + s_2^2/n_2}\n\\end{align*}\\]order perform two-sample t-test, following condition must met:Observations group must independent one anotherTwo groups must independent one anotherPopulation distributions must nearly normal sample sizes must sufficiently large (usually, sample size 30 enough satisfy condition)population variances must equal Example 1:researcher thinks sales average might higher stores located rural areas since people areas tend use cars often. words, \\(\\mu_R - \\mu_U > 0\\). wants test hypothesis \\(\\alpha = 0.02\\) significance level. given research question, null alternative hypotheses :\\[\\begin{align*}\nH_0: \\mu_R - \\mu_U = 0  \\quad versus \\quad H_a: \\mu_R - \\mu_U > 0\n\\end{align*}\\]perform formal test, let’s visualize data:mentioned, one assumptions two-sample t-test populations variances must equal. First, check assumption performing another test called Levene’s test. , use LeveneTest() function. function available car package, thus, first need install package:p-value test extremely high, indicates variances two populations equal. Thus, t.test var.equal argument set TRUE:Since p-value 0.3793 greater significance level 0.02, fail reject null hypothesis conclude statistical difference average sales Rural Urban areas.Example 2:Now suppose like test claim average stores US outside US equally profitable. words, sales stores located US outside US average equal. want test claim \\(\\alpha = 0.05\\) significance level. null alternative hypotheses given :\\[\\begin{align*}\nH_0: \\mu_{US} - \\mu_{non\\_US} = 0  \\quad versus \\quad H_a: \\mu_{US} - \\mu_{non\\_US} \\neq 0\n\\end{align*}\\]Let’s visualize data:plot observe average sales stores located US higher sales stores located outside US. difference statistically significant? find .usual, perform formal t-test, let’s test assumption equal variances 5% significance level:Since p-value 0.05741 greater 0.05, assume variances equal. Now move t-test:Since p-value 0.00037 less significance level 0.05, reject null hypothesis conclude average stores US outside US different profitability.","code":"\n\ndata_summary = dataset1 %>% \n  \n               group_by(Urban) %>%\n  \n               summarise(grp.mean = mean(Sales))\n\n\n# Plotting the lines\n  \nggplot(data = dataset1) +\n    \ngeom_histogram(aes(x = Sales, fill = Urban, color = Urban),\n               \n               alpha = 0.5) +\n    \ngeom_vline(data = data_summary, \n               \n           aes(xintercept=grp.mean, color=Urban),\n               \n           size = 1) \n#> `stat_bin()` using `bins = 30`. Pick better value with\n#> `binwidth`.\n\nlibrary(car)\n#> Loading required package: carData\n#> \n#> Attaching package: 'car'\n#> The following object is masked from 'package:dplyr':\n#> \n#>     recode\n#> The following object is masked from 'package:purrr':\n#> \n#>     some\n\nleveneTest(Sales ~ Urban, data = dataset1)\n#> Levene's Test for Homogeneity of Variance (center = median)\n#>        Df F value Pr(>F)\n#> group   1       0 0.9986\n#>       398\n\nRural <- dataset1 %>%\n  \n         filter(Urban == \"No\") %>%\n          \n         select(Sales)\n\nUrban <- dataset1 %>%\n  \n         filter(Urban == \"Yes\") %>%\n          \n         select(Sales)\n\n\nt.test(x = Rural,\n       \n       y = Urban,\n       \n       alternative = \"greater\",\n       \n       mu = 0,\n       \n       var.equal = TRUE,\n       \n       conf.level = 0.98)\n#> \n#>  Two Sample t-test\n#> \n#> data:  Rural and Urban\n#> t = 0.30765, df = 398, p-value = 0.3793\n#> alternative hypothesis: true difference in means is greater than 0\n#> 98 percent confidence interval:\n#>  -0.543356       Inf\n#> sample estimates:\n#> mean of x mean of y \n#>  7.563559  7.468191\n\nggplot(data = dataset1) +\n  \ngeom_boxplot(aes(x = US, y = Sales, fill = US)) +\n  \nstat_summary(aes(x = US, y = Sales, fill = US),\n               \n             fun = \"mean\",\n               \n             geom = \"point\",\n               \n             color = \"black\")\n\nleveneTest(Sales ~ US, data = dataset1)\n#> Levene's Test for Homogeneity of Variance (center = median)\n#>        Df F value  Pr(>F)  \n#> group   1  3.6316 0.05741 .\n#>       398                  \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nt.test(Sales ~ US, \n       \n       data = dataset1,\n       \n       mu = 0,\n       \n       alternative = \"two.sided\",\n       \n       var.equal = TRUE,\n       \n       conf.level = 0.95)\n#> \n#>  Two Sample t-test\n#> \n#> data:  Sales by US\n#> t = -3.5897, df = 398, p-value = 0.0003723\n#> alternative hypothesis: true difference in means between group No and group Yes is not equal to 0\n#> 95 percent confidence interval:\n#>  -1.6155534 -0.4721887\n#> sample estimates:\n#>  mean in group No mean in group Yes \n#>          6.823028          7.866899"},{"path":"module-13.html","id":"chi2-goodness-of-fit-test-gof","chapter":"Module 13","heading":"\\(\\chi^2\\) Goodness of Fit Test (GOF)","text":"Sometimes interested check whether data comes specified distribution . \\(\\chi^2\\) (chi-squared) goodness fit test helps answer question. chi-squared goodness fit test, term goodness fit used compare observed sample distribution expected probability distribution. module, perform chi-squared goodness fit test categorical variables.context chi-squared goodness fit test, test statistic given :\\[\\begin{align*}\n\\chi^2 = \\sum_{= 1}^{k}\\frac{(observed_i - expected_i)^2}{expected_i}\n\\end{align*}\\]\\(observed_i\\) observed frequency level \\(\\) \\(expected_i\\) expected frequency level \\(\\) null hypothesis, \\(k\\) number levels categorical variable.order perform chi-squared goodness fit test, following condition must met:case contributes count table must independent cases table.expected counts level categorical variable must least 5.must least 3 levels categorical variable. Let’s consider example better understand test works:Example:Data analysts company believe order achieve desired number sales child car seat product, 55% items placed medium quality shelves, 25% good quality shelves, remaining 20% can placed bad quality shelves. Thus, desired distribution ShelveLoc variable isNow let’s check whether sample distribution follows distribution given table . words, going test whether sample data fits specified distribution well. null alternative hypotheses correspond research question given \\(H_0\\): distribution shelve locations distribution proposed analysts. observed difference due chance.\\(H_a\\): distribution shelve locations different distribution proposed analysts. observed difference due chance.test hypotheses, let’s visualize sample data:Let’s convert count frequency percentages:can notice, sample distribution differs desired distribution shelve locations. difference statistically significant? going figure .table observed expected counts.observed counts obtained sample, expected counts calculated assuming null hypothesis true. words, frequencies expect get null hypothesis true:Now use observed expected counts calculate chi-squared test statistic corresponding p-value. Instead manually hand, going use chisq.test() function. function needs following arguments:x - numeric vector matrixp - vector probabilities length xLet’s test hypothesis \\(\\alpha = 0.05\\) significance level:function output contains test statistic (\\(\\chi^2\\) = 5.4545), degrees freedom (df = 2), p-value. Since p-value 0.0654 greater significance level 0.05, fail reject \\(H_0\\). Thus, based data, actual distribution ShelveLoc variable follows desired distribution. ","code":"\n\nggplot(data = dataset1) +\n  \ngeom_bar(mapping = aes(x = ShelveLoc, fill = ShelveLoc),\n         \n         width = 0.9) +\n  \nscale_x_discrete(limits = c(\"Bad\", \"Medium\", \"Good\")) + \n  \ngeom_text(aes(x = ShelveLoc,label = ..count..),\n            \n            stat = \"count\",\n            \n            vjust = 1.5,\n          \n            size = 6,\n            \n            colour = \"white\")\n\nggplot(data = dataset1) +\n  \ngeom_bar(mapping = aes(x = ShelveLoc, fill = ShelveLoc),\n         \n         width = 0.9) +\n  \nscale_x_discrete(limits = c(\"Bad\", \"Medium\", \"Good\")) + \n  \ngeom_text(aes(x = ShelveLoc,label = scales::percent((..count..)/sum(..count..))),\n            \n            stat = \"count\",\n            \n            vjust = 1.5,\n          \n            size = 6,\n            \n            colour = \"white\")\n\nchisq.test(x = c(96, 219, 85), p = c(0.2, 0.55, 0.25))\n#> \n#>  Chi-squared test for given probabilities\n#> \n#> data:  c(96, 219, 85)\n#> X-squared = 5.4545, df = 2, p-value = 0.0654"},{"path":"module-13.html","id":"chi2-test-of-independence","chapter":"Module 13","heading":"\\(\\chi^2\\) Test of Independence","text":"chi-squared test independence used check whether two categorical variables related . words, tests whether two categorical variables independent. general, two categorical variables related, probability one variable certain value dependent value variables.chi-squared test independence can used test following set hypotheses:\\(H_0:\\) Variable Variable B independent. observed difference due chance.\\(H_a:\\) Variable Variable B independent. observed difference due chance.test statistic test identical chi-squared goodness fit test:\\[\\begin{align*}\n\\chi^2 = \\sum_{= 1}^{k}\\frac{(observed_i - expected_i)^2}{expected_i}\n\\end{align*}\\], \\(observed_i\\) observed frequency level \\(\\) \\(expected_i\\) expected frequency level \\(\\) null hypothesis, \\(k\\) number levels categorical variable.slightly different set conditions need met order perform chi-squared test independence:case contributes count table must independent cases table.expected count cell two-way table must least 5. better understand test works, let’s consider example.Example:Suppose interested know whether ShelveLoc Urban variables related. words, trying figure whether distribution items shelves depends whether store located rural urban area. set hypotheses correspond research question \\(H_0:\\) Variables ShelveLoc Urban independent. observed difference due chance.\\(H_a:\\) Variables ShelveLoc Urban independent. observed difference due chance.going test hypotheses using sample data \\(\\alpha = 0.1\\) significance level. best way display sample data using two-way contingency table. two-way contingency table, rows represent levels(categories) one categorical variable columns represent levels categorical variable:variables independent, , related, distribution ShelveLoc variable every level Urban variable vice versa.can visualize data using stacked barplot:Stacked barplots particularly useful describing relationship (lack ) two categorical variables. columns plot divided different vertical locations others, might indication variable related, , independent. per usual, formally test hypothesis, need perform statistical test. case, chi-squared test independence:Since p-value 0.2544 greater significance level 0.1, fail reject null hypothesis. conclude , based sample data, ShelveLoc Urban variables independent one another.","code":"\n\ndataset1 %>%\n  \n  select(Urban, ShelveLoc) %>%\n  \n  table()\n#>      ShelveLoc\n#> Urban Bad Good Medium\n#>   No   22   28     68\n#>   Yes  74   57    151\n\nggplot(data = dataset1) +\n  \ngeom_bar(mapping = aes(x = ShelveLoc, fill = Urban),\n         \n         position = \"fill\") \n\nchisq.test(dataset1$ShelveLoc, dataset1$Urban)\n#> \n#>  Pearson's Chi-squared test\n#> \n#> data:  dataset1$ShelveLoc and dataset1$Urban\n#> X-squared = 2.7376, df = 2, p-value = 0.2544"},{"path":"module-14.html","id":"module-14","chapter":"Module 14","heading":"Module 14","text":" ","code":""},{"path":"module-14.html","id":"modeling","chapter":"Module 14","heading":"Modeling","text":"","code":""},{"path":"module-14.html","id":"introduction-2","chapter":"Module 14","heading":"Introduction","text":"Patterns data provide clues relationships among variables. systematic relationship exists two variables appear pattern data. spot pattern, ask :pattern due coincidence (.e. random chance)?can describe relationship implied pattern?strong relationship implied pattern?variables might affect relationship?relationship change look individual subgroups data?Patterns provide one useful tools data analysts reveal covariation. think variation phenomenon creates uncertainty, covariation phenomenon reduces . two variables covary, can use values one variable make better predictions values second. covariation due causal relationship (special case), can use value one variable control value second.Models tool extracting patterns data. goal model provide simple low-dimensional summary dataset. Ideally, model capture true “signals” (.e. patterns generated phenomenon interest), ignore “noise” (.e. random variation ’re interested ).module, cover predictive models, , name suggests, generate predictions. Specifically, going focus linear regression models, famous arguably simplest models, yet widely used statistics. ","code":""},{"path":"module-14.html","id":"simple-linear-regression-slr-model","chapter":"Module 14","heading":"Simple Linear Regression (SLR) Model","text":"mentioned, linear regression model one simplest models data analysis. Though may seem somewhat dull compared modern statistical learning approaches, linear regression still useful widely applied statistical learning method.Moreover, serves good starting point advanced approaches; fact, many sophisticated statistical learning approaches can seen generalizations extensions ordinary linear regression. Consequently, important good understanding linear regression studying complex learning methods.discussing linear regression models detail, first give general definition. start simple linear regression (SLR) model, linear model contains one predictor.","code":""},{"path":"module-14.html","id":"model-set-up","chapter":"Module 14","heading":"Model Set Up","text":"simple linear regression model defines relationship two variables follows: \\[\\begin{align*}\nY_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i \\quad   \\quad  = 1, \\dots, n\n\\end{align*}\\] \\(Y\\) response (also known target, outcome, dependent) variable\\(X\\) predictor (also known explanatory independent) variable values fixed\\(\\beta_0\\) \\(\\beta_1\\) fixed model parameters; specifically, intercept slope regression function, respectively\\(\\epsilon\\) (epsilon) error term ’s random variable; assumed normally distributed mean 0 variance \\(\\sigma^2\\), , \\(\\epsilon \\sim N(0, \\sigma^2)\\). model linear, uses linear function describe relationship response predictor variables. simple, contains one predictor. Interpretation parameters:slope parameter \\(\\beta_1\\) indicates change mean value response variable \\(Y\\) per unit increase predictor variable \\(X\\).intercept parameter \\(\\beta_0\\) \\(Y\\) intercept regression line. scope model includes \\(X = 0\\), \\(\\beta_0\\) given mean value \\(Y\\) \\(X = 0\\). Model Assumptions:Linear regression models must meet certain assumptions valid. assumptions areLinearity regression functionConstant variance error termsIndependence error termsNo outliersNormality error terms assume relationship variables can described using SLR model, model can utilized make predictions response variable \\(Y\\) based values predictor variable \\(X\\).Normally, make predictions mean value response variable. words, using predictive models SLR, predict average value response value given value explanatory variable. can written  \\[\\begin{align*}\nE(Y_i) = E(\\beta_0 + \\beta_1 X_i + \\epsilon_i) = \\beta_0 + \\beta_1 X_i + 0  = \\beta_0 + \\beta_1 X_i\n\\end{align*}\\]Thus,\\[\\begin{align*}\nE(Y_i) = \\beta_0 + \\beta_1 X_i  \\quad   \\quad  = 1, \\dots, n\n\\end{align*}\\] noticed, SLR model contains three parameters: \\(\\beta_0\\), \\(\\beta_1\\), \\(\\sigma^2\\). parameters fixed (constant), unknown us. Thus, first need estimate parameters order set model make predictions based model. ","code":""},{"path":"module-14.html","id":"parameter-estimation-least-squares-approach","chapter":"Module 14","heading":"Parameter Estimation: Least Squares Approach","text":"introduce estimation method, let’s consider example. Recall lung capacity dataset ’ve used modules. Suppose believe SLR model can used predict lung capacity based patient’s height. adviced earlier, always good idea visualize data part EDA (Explanatory Data Analysis):scatterplot becomes clear linear model indeed good fit data displays strong linear pattern/trend. Now ’s time estimate parameters set model.can estimate parameters? general, goal build predictive model (known fitted model) form \\[\\begin{align*}\n\\hat{Y} = b_0 + b_1X\n\\end{align*}\\] \\(b_0\\) \\(b_1\\) estimates model parameters \\(\\beta_0\\) \\(\\beta_1\\), respectively, \\(\\hat{Y}\\) fitted value response variable. infinite number combinations \\(b_0\\) \\(b_1\\) values. combinations define family predictive models.Let’s plot . example, try model data horizontal line representing mean value lung capacity variable. , building model response outcome depend predictor variable:plot , see doesn’t seem good job. Many data points far line representing mean value response variable. example underfitting. obvious fix make fitted model actually depend predictor. illustrate models:line plot represents fitted model. 250 models plot (depicted plot). models really bad! going decide one best? selection criterion?need find good models making precise intuition good model “close” data. need way quantify distance data model. can fit model finding value \\(b_0\\) \\(b_1\\) generate model smallest distance data.One easy place start find vertical distance point model. distance just difference fitted value (predicted) given model actual response value data:\\[\\begin{align*}\nY_i - \\hat{Y}_i\n\\end{align*}\\]Next, need way compute overall distance predicted actual values. One common way statistics use sum squared deviations (also known Error Sum Squares (SSE)). compute difference actual predicted, square , add : \\[\\begin{align*}\nSSE = \\sum_{= 1}^{n}(Y_i - \\hat{Y}_i)^2 = \\sum_{= 1}^{n}(Y_i - (b_0 + b_1X_i))^2\n\\end{align*}\\] distance lots appealing mathematical properties, ’re going talk .Now pair values \\(b_0\\) \\(b_1\\) minimize quantity given known best estimates model parameters \\(\\beta_0\\) \\(\\beta_1\\). approach known least squares method, estimates called least squares estimates, fitted model referred ordinary least squares (OLS) regression.skip derivation estimates beyond scope bootcamp simply provide formulas: \\[\\begin{align*}\nb_1 = \\frac{\\sum_{= 1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{= 1}^{n}(x_i - \\bar{x})^2}\n\\end{align*}\\] \\[\\begin{align*}\nb_0 = \\bar{y} - b_1\\bar{x}\n\\end{align*}\\] Now know best estimates model parameters, let’s calculate values. First, manually using formulas:Thus, fitted function fitted model given  \\[\\begin{align*}\n\\hat{Y} = -13.996 + 0.337 X\n\\end{align*}\\], specifically\\[\\begin{align*}\n\\hat{Lung Capacity} = -13.996 + 0.337 Height\n\\end{align*}\\] can interpret model estimates follows:can expect mean value lung capacity increase 0.337 units per unit increase Height predictor.given context, makes sense interpret intercept scope model include \\(X = 0\\) (patient Height = 0).Now, instead calculations manually can use lm() function:summary() function provides model summary (come back shortly).Now can visualize results plot fitted regression line:Set se = FALSE want remove confidence band around regression line: ","code":"\n\n gg = ggplot(data = dataset1, aes(x = Height, y = LungCap)) + \n  \n  geom_point(color = \"steelblue\") +\n  \n  labs(title = \"Lung Capacity versus Height\",\n       \n       subtitle = \"From lung_capacity dataset\",\n       \n       x = \"Height\",\n       \n       y = \"Lung Capacity\")\n\n\nplot(gg)\n\nmean_lungcap = mean(dataset1$LungCap)\n\n\ngg + \n\ngeom_hline(yintercept = mean_lungcap, size = 1)\n\nset.seed(4)\nmodels <- tibble(\n  b0 = runif(250, -20, 40),\n  b1 = runif(250, -5, 5)\n)\n\n\ngg +\n  \ngeom_abline(aes(intercept = b0, slope = b1), data = models)#> `geom_smooth()` using formula 'y ~ x'\n\nx <- dataset1$Height\n\ny <- dataset1$LungCap\n\nSxy <- sum((x - mean(x)) * (y - mean(y)))\n\nSxx <- sum((x - mean(x)) ^ 2)\n\nSyy <- sum((y - mean(y)) ^ 2)\n\nb_1 <- Sxy / Sxx\n\nprint(b_1)\n#> [1] 0.3371566\n\nb_0 <- mean(y) - b_1 * mean(x)\n\nprint(b_0)\n#> [1] -13.99683\n\nmodel <- lm(LungCap ~ Height, data = dataset1)\n\nsummary(model)\n#> \n#> Call:\n#> lm(formula = LungCap ~ Height, data = dataset1)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -3.3619 -0.7014 -0.0032  0.7787  3.2938 \n#> \n#> Coefficients:\n#>               Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) -13.996829   0.367451  -38.09   <2e-16 ***\n#> Height        0.337157   0.005633   59.86   <2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 1.092 on 723 degrees of freedom\n#> Multiple R-squared:  0.8321, Adjusted R-squared:  0.8319 \n#> F-statistic:  3583 on 1 and 723 DF,  p-value: < 2.2e-16\n\ngg +\n  \n  geom_smooth(method = 'lm')\n#> `geom_smooth()` using formula 'y ~ x'\n\ngg +\n  \n  geom_smooth(method = 'lm', se = FALSE)\n#> `geom_smooth()` using formula 'y ~ x'"},{"path":"module-14.html","id":"making-predictions","chapter":"Module 14","heading":"Making Predictions","text":"can now utilize fitted model make predictions. , first manually, present R function. Suppose based fitted model want predict mean lung capacity patient \\(Height = 75\\)?, simply plug value model calculate corresponding predicted value:\\[\\begin{align*}\n\\hat{Lung Capacity} = -13.996 + 0.337 Height = -13.996 + 0.337\\times 75 = 11.289\n\\end{align*}\\]Thus, expected lung capacity patient Height = 75 11.289. time, want make predictions multiple values, number inputs might quite large. instead manually, can use predict() function. need pass fitted model object function values predictor variable trying make predictions :can even make predictions multiple values. example let’s calculate expected mean lung capacity Height = 67.5, Height = 64, Height = 53.8:predict() function can also used construct confidence interval. come back function later. ","code":"\n\npredict(model, data.frame(Height = 75))\n#>        1 \n#> 11.28991\n\npredict(model, data.frame(Height = c(67.5, 64, 53.8)))\n#>        1        2        3 \n#> 8.761240 7.581192 4.142195"},{"path":"module-14.html","id":"residuals","chapter":"Module 14","heading":"Residuals","text":"think model “Response = Prediction + Error,” can write  \\[\\begin{align*}\nY = \\hat{Y} + e\n\\end{align*}\\]define residual observed value minus predicted value: \\[\\begin{align*}\ne = Y - \\hat{Y}\n\\end{align*}\\]Residuals play crucial role model building process used many statistical procedures. obtained residuals data, use residuals() function (display first 10 residuals dataset large displaying residuals take much space):good idea bind together residuals predictor variable one data frame know residual corresponds predictor value (values independent variable, predictions!):One main properties residuals summation equal zero. property used derive important features linear regression models. Let’s show residuals model indeed add zero: ","code":"\n\n# Obtaining first 10 residuals\n\nresiduals(model)[1:10]  \n#>           1           2           3           4           5 \n#> -0.46559420 -1.06376699  0.04701586  1.18371232 -0.38738003 \n#>           6           7           8           9          10 \n#>  0.43073814 -2.39518208 -2.41399374 -0.89770940  0.83715986\n\n# Obtaining first 10 residuals and corresponding predictor values\n\ndata.frame(Height = dataset1$Height, Residuals = residuals(model))[1:10, ]\n#>    Height   Residuals\n#> 1    62.1 -0.46559420\n#> 2    74.7 -1.06376699\n#> 3    69.7  0.04701586\n#> 4    71.0  1.18371232\n#> 5    56.9 -0.38738003\n#> 6    58.7  0.43073814\n#> 7    63.3 -2.39518208\n#> 8    70.4 -2.41399374\n#> 9    70.5 -0.89770940\n#> 10   59.2  0.83715986\n\nsum(residuals(model))\n#> [1] -1.496546e-14"},{"path":"module-14.html","id":"variance-estimation","chapter":"Module 14","heading":"Variance Estimation","text":"now use residuals estimate model variance, \\(\\sigma^2\\). best estimate model variance \\(\\sigma^2\\) (derivations omitted) Error Mean Square (MSE) given  \\[\\begin{align*}\nMSE = \\frac{\\sum_{= 1}^{n}(Y_i - \\hat{Y}_i)^2}{n-2} = \\frac{SSE}{n-2} = \\frac{\\sum Residuals^2}{n-2}\n\\end{align*}\\] Let’s estimate model variance based data. First, let’s manually:output anova() function includes MSE, , estimate model variance. Thus, can used variance estimation:output value intersection Mean.Sq column Residuals row MSE. , equal 1.2. ","code":"\n\nsum(residuals(model)^2)/(dim(dataset1)[1]-2)\n#> [1] 1.191535\n\nanova(model)\n#> Analysis of Variance Table\n#> \n#> Response: LungCap\n#>            Df Sum Sq Mean Sq F value    Pr(>F)    \n#> Height      1 4269.0  4269.0  3582.8 < 2.2e-16 ***\n#> Residuals 723  861.5     1.2                      \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"module-14.html","id":"lm-useful-functions","chapter":"Module 14","heading":"lm(): Useful Functions","text":"section like share useful functions allow extract important information/features fitted model.summary()summary() function, ’ve already seen, summarizes fitted model:contains sorts information presented one output. discuss detail later .coef()goal extract just model coefficients (estimates), use coef() function:resid()resid() function residuals() functions displays residuals fitted model:fitted()fitted() function used obtain fitted values:understand, relationship among actual response values, fitted values, residuals: ","code":"\n\nsummary(model)\n#> \n#> Call:\n#> lm(formula = LungCap ~ Height, data = dataset1)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -3.3619 -0.7014 -0.0032  0.7787  3.2938 \n#> \n#> Coefficients:\n#>               Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) -13.996829   0.367451  -38.09   <2e-16 ***\n#> Height        0.337157   0.005633   59.86   <2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 1.092 on 723 degrees of freedom\n#> Multiple R-squared:  0.8321, Adjusted R-squared:  0.8319 \n#> F-statistic:  3583 on 1 and 723 DF,  p-value: < 2.2e-16\n\ncoef(model)\n#> (Intercept)      Height \n#> -13.9968289   0.3371566\n\n# Obtaining residuals for the first 10 observations in the dataset\n\nresid(model)[1:10]\n#>           1           2           3           4           5 \n#> -0.46559420 -1.06376699  0.04701586  1.18371232 -0.38738003 \n#>           6           7           8           9          10 \n#>  0.43073814 -2.39518208 -2.41399374 -0.89770940  0.83715986\n\n# Obtaining fitted values for the first 10 observations in the dataset\n\nfitted(model)[1:10]\n#>         1         2         3         4         5         6 \n#>  6.940594 11.188767  9.502984  9.941288  5.187380  5.794262 \n#>         7         8         9        10 \n#>  7.345182  9.738994  9.772709  5.962840\n\nactual <- dataset1$LungCap[1:10]\n\nfitted <- fitted(model)[1:10]\n\nresiduals <- resid(model)[1:10]\n\n\ndata.frame(residuals, actual - fitted)\n#>      residuals actual...fitted\n#> 1  -0.46559420     -0.46559420\n#> 2  -1.06376699     -1.06376699\n#> 3   0.04701586      0.04701586\n#> 4   1.18371232      1.18371232\n#> 5  -0.38738003     -0.38738003\n#> 6   0.43073814      0.43073814\n#> 7  -2.39518208     -2.39518208\n#> 8  -2.41399374     -2.41399374\n#> 9  -0.89770940     -0.89770940\n#> 10  0.83715986      0.83715986"},{"path":"module-14.html","id":"confidence-interval-for-beta_1","chapter":"Module 14","heading":"Confidence interval for \\(\\beta_{1}\\)","text":"illustrative purposes, using Muscle Mass data set (available Courseworks):person’s muscle mass expected decrease age. explore relationship women, nutritionist randomly selected 15 women 10-year age group, beginning age 40 ending age 79. recorded Age (predictor) measure muscle mass (MM, response).Now let’s run simple linear regression model. can use “lm()” function:check summary model, use “summary()” function:estimates model parameters can found “Coefficients” “Estimate” column. example, estimate slope, , estimated coefficient associated “Age” predictor equal -1.19. Similarly, estimate intercept 156.3466.can construct confidence interval test hypothesis regarding \\(\\beta_{1}\\) either using R functions manually. consider ways. Let’s start R codes.find confidence interval slope, given \\(\\alpha = 0.05\\) significance level, use following function:can observe function computes lower upper bounds confidence interval specified level significance \\(\\alpha\\). function three arguments: first model name (whatever name give model), predictor’s name, confidence level).Now, let’s manually. confidence interval slope can computed \\[\\begin{align*}\nb_{1} \\pm t(1-\\alpha/2; n-2) \\times s(b_{1})\n\\end{align*}\\]found estimate slope \\(b_{1} = -1.19\\). \\(s(b_{1})\\) standard error estimate can found model summary “Coefficients” “Std. Error” column. example \\(s(b_{1}) = 0.0902\\). Finally, \\(\\alpha = 0.05\\), \\(t(1-\\alpha/2; n-2) = t(0.975; 58)\\) can found bySo putting everything together get\\[\\begin{align*}\n-1.19 \\pm 2.0017 \\times 0.0902\n\\end{align*}\\] ","code":"\n\nmodel = lm(MM ~ Age, data = mydata)\nsummary(model)\n#> \n#> Call:\n#> lm(formula = MM ~ Age, data = mydata)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -16.1368  -6.1968  -0.5969   6.7607  23.4731 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 156.3466     5.5123   28.36   <2e-16 ***\n#> Age          -1.1900     0.0902  -13.19   <2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 8.173 on 58 degrees of freedom\n#> Multiple R-squared:  0.7501, Adjusted R-squared:  0.7458 \n#> F-statistic: 174.1 on 1 and 58 DF,  p-value: < 2.2e-16\nconfint(model, \"Age\", level = 0.95)\n#>         2.5 %    97.5 %\n#> Age -1.370545 -1.009446\nqt(0.975, 58)\n#> [1] 2.001717"},{"path":"module-14.html","id":"testing-h_0-beta_1-0-quad-vs-quad-h_a-beta_1-neq-0-via-t-test","chapter":"Module 14","heading":"Testing \\(H_{0}: \\beta_{1} = 0 \\quad vs \\quad H_{a}: \\beta_{1} \\neq 0\\) via t-test","text":"Now let’s perform hypothesis testing concerning following hypotheses:\\[\\begin{align*}\nH_{0}: \\beta_{1} = 0  \\quad vs \\quad H_{}: \\beta_{1} \\neq 0\n\\end{align*}\\]First let’s performing t-test. easiest way just check summary output model: test statistic \\(t^{*}\\) can found “Coefficients” “t value” column. -13.19 case. corresponding P-value given intersection “Pr(>|t|)” column “Age” row, 0 example (basically, <2e-16 small number can treated 0). based P-value can make conclusion significance predictor.can perform procedure manually. , let’s consider another example. Suppose want test following hypothesis:\\[\\begin{align*}\nH_{0}: \\beta_{1} = 2  \\quad vs \\quad H_{}: \\beta_{1} \\neq 2\n\\end{align*}\\]First let’s find test statistic \\(t^{*}\\):\\[\\begin{align*}\nt^{*} = \\frac{b_{1} - 2}{s(b_{1})}\n\\end{align*}\\]example \\(t^{*} = \\frac{-1.19 - 2}{0.0902} = -35.3656\\). know \\(t^{*} \\sim t(n-2)\\). corresponding P-value can computed finding probability two tails beyond \\(\\pm|t^{*}|\\). SoAs can see get result reported table. Note, one-sided test, don’t multiply quatity 2 pick side corresponds hypothesis. ","code":"\n\n2*(1-pt(35.3656, 58))\n#> [1] 0"},{"path":"module-14.html","id":"testing-h_0-beta_1-0-quad-vs-quad-h_a-beta_1-neq-0-via-f-test","chapter":"Module 14","heading":"Testing \\(H_{0}: \\beta_{1} = 0 \\quad vs \\quad H_{a}: \\beta_{1} \\neq 0\\) via F-test","text":"Now let’s consider another way testing \\(H_{0}: \\beta_{1} = 0 \\quad vs \\quad H_{}: \\beta_{1} \\neq 0\\), F-test. , let’s obtain ANOVA table:output helps set anova table: provides values degrees freedom, sum squares, mean sum squares Regression (stated Age table) error (stated residuals).Anova table also provides test statistic F-test, 174.06 (check whether indeed equal MSR/MSE) given “F value” column. corresponding P-value provided “Pr(>F)” column 0.","code":"\n\nanova(model)\n#> Analysis of Variance Table\n#> \n#> Response: MM\n#>           Df  Sum Sq Mean Sq F value    Pr(>F)    \n#> Age        1 11627.5 11627.5  174.06 < 2.2e-16 ***\n#> Residuals 58  3874.4    66.8                      \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"module-14.html","id":"confidence-interval-for-mean-response","chapter":"Module 14","heading":"Confidence interval for mean response","text":"Now construct 95% confidence interval mean muscle mass women age 20. , use following formula:output gives estimate mean response (132.5467 case) lower upper boundaries confidence interval.","code":"\n\npredict(model, data.frame(Age = 20), interval = \"confidence\", level = 0.95)\n#>        fit     lwr      upr\n#> 1 132.5467 125.025 140.0683"},{"path":"module-14.html","id":"prediction-interval-for-mean-response","chapter":"Module 14","heading":"Prediction interval for mean response","text":"Similarly, can find prediction interval mean muscle mass women age 20 (remember difference confidence prediction intervals?). , use following formula:Note: Many topics discussed module might unfamiliar ’s ok. take STAT 5205: Linear Regression Models class upcoming fall semester, exposed related topics detail. now, enough know basic R functions.","code":"\n\npredict(model, data.frame(Age = 20), interval = \"prediction\", level = 0.95)\n#>        fit      lwr      upr\n#> 1 132.5467 114.5401 150.5532"},{"path":"problem-set-4.html","id":"problem-set-4","chapter":"Problem Set 4","heading":"Problem Set 4","text":" ","code":""},{"path":"problem-set-4.html","id":"problem-1-3","chapter":"Problem Set 4","heading":"Problem 1","text":"problem use functions apply() family functions whenever think need loops. Create function (name fun1) takes three arguments n, miu, sd (n number randomly generated numbers, miu mean value distribution numbers come , sd standard deviation distribution) following:\nFirst generates n random numbers normal distribution mean = miu standard deviation = sd\npopulates empty matrix follows: n divisible 2 3, fills matrix row, 2 rows n/2 columns; n divisible 3 2, fills matrix column, 3 columns n/3 rows; n divisible 2 3, fills matrix row, 6 rows n/6 columns; else fills row one column\nreturns vector mean values column matrix none randomly generated numbers negative; returns vector median values row matrix randomly generated numbers negative.\nTest function (n = 50, miu = 0.5, sd = 2)Create function (name fun1) takes three arguments n, miu, sd (n number randomly generated numbers, miu mean value distribution numbers come , sd standard deviation distribution) following:First generates n random numbers normal distribution mean = miu standard deviation = sdThen populates empty matrix follows: n divisible 2 3, fills matrix row, 2 rows n/2 columns; n divisible 3 2, fills matrix column, 3 columns n/3 rows; n divisible 2 3, fills matrix row, 6 rows n/6 columns; else fills row one columnAnd returns vector mean values column matrix none randomly generated numbers negative; returns vector median values row matrix randomly generated numbers negative.Test function (n = 50, miu = 0.5, sd = 2) Create function (name fun2) take one argument n, represents number trials simulation. function simulate process rolling unfair die following probability distribution: “1” - 0.1, “2” - 0.3, “3” - 0.2, “4” - 0.05, “5” - 0.3, “6” - 0.05. report results n trials returning frequency table outcomes (example, many times got “1”, “2”, ).\nTest function n = 100.Create function (name fun2) take one argument n, represents number trials simulation. function simulate process rolling unfair die following probability distribution: “1” - 0.1, “2” - 0.3, “3” - 0.2, “4” - 0.05, “5” - 0.3, “6” - 0.05. report results n trials returning frequency table outcomes (example, many times got “1”, “2”, ).Test function n = 100. Create function (name fun3) take one argument n, represents number trials simulation. function simulate process rolling two fair dice. report results n trials returning vectors outcomes dice (name Die1 Die2, respectively) vector compares outcomes obtained Die1 Die2 (name comparison). comparison vector created follows: created using mapply() function factor three levels (“Die1 > Die2”, “Die1 < Die2”, “Die1 = Die2”). instance, outcome Die1 5 outcome Die2 4, produce “Die1 > Die2”.\nTest function n = 30.Create function (name fun3) take one argument n, represents number trials simulation. function simulate process rolling two fair dice. report results n trials returning vectors outcomes dice (name Die1 Die2, respectively) vector compares outcomes obtained Die1 Die2 (name comparison). comparison vector created follows: created using mapply() function factor three levels (“Die1 > Die2”, “Die1 < Die2”, “Die1 = Die2”). instance, outcome Die1 5 outcome Die2 4, produce “Die1 > Die2”.Test function n = 30. ","code":""},{"path":"problem-set-4.html","id":"problem-2-2","chapter":"Problem Set 4","heading":"Problem 2","text":", working ames_housing.csv dataset. contains information homes sold Ames, Iowa, 2006 2010. dataset includes 18 variables covers wide range home characteristics. purpose assignment, going work following variables:Sales_Price - Sale PriceNeighborhood - Physical locations within Ames city limitsRoof_Style - Type roofFence - Fence qualityTotRms_AbvGrd - Total rooms grade (include bathrooms)Gr_Liv_Area - grade(ground) living area square feet John new real estate agent area. friend , worked area , told average price houses sold area $210,000. John feels bit skeptical claim wants test . Perform appropriate statistical procedure test claim. Use \\(\\alpha = 0.05\\) significance level make conclusion. State null alternative hypotheses. test statistic? degrees freedom? p-value? conclude? John industry quite time. course past 10 years, ’s noticed type roof houses can somehow define fence quality. words, thinks two features (Roof_Style Fence variables dataset) somehow related. Test hypothesis based sample data \\(\\alpha = 0.01\\) significance level. State null alternative hypotheses. test statistic? degrees freedom? p-value? conclude? John specifically interested two neighborhoods: North_Ames College_Creek. research prior arrival thinks average houses College_Creek neighborhood $50,000 expensive houses sold North_Ames neighborhood. Test hypothesis \\(\\alpha = 0.02\\) significance level. State null alternative hypotheses. test statistic? degrees freedom? p-value? conclude? John decides split homes dataset following three groups based total number rooms ground: \"2-4\", \"5-8\", \"9 \". believes 10% homes belong \"2-4\" category, 85% belong \"5-8\" category, remaining 5% belong \"9 \" category. Test hypothesis using appropriate statistical procedure \\(\\alpha = 0.01\\) significance level. State null alternative hypotheses. test statistic? degrees freedom? p-value? conclude?\nperform test, need add new variable dataset (name Rooms) using splitting rule proposed John. words, need create factor variable 3 levels converting TotRms_AbvGrd variable. (Hint: might want check case_when() function dpyr package).John decides split homes dataset following three groups based total number rooms ground: \"2-4\", \"5-8\", \"9 \". believes 10% homes belong \"2-4\" category, 85% belong \"5-8\" category, remaining 5% belong \"9 \" category. Test hypothesis using appropriate statistical procedure \\(\\alpha = 0.01\\) significance level. State null alternative hypotheses. test statistic? degrees freedom? p-value? conclude?perform test, need add new variable dataset (name Rooms) using splitting rule proposed John. words, need create factor variable 3 levels converting TotRms_AbvGrd variable. (Hint: might want check case_when() function dpyr package). ","code":""},{"path":"problem-set-4.html","id":"problem-3-2","chapter":"Problem Set 4","heading":"Problem 3","text":"Tri-City Office Equipment Corporation sells imported copier franchise basis performs preventive maintenance repair service copier. data copier_maintenance.txt (available Courseworks) collected 45 recent calls users perform routine preventive maintenance service; observation, recorded number copiers serviced (Copiers, predictor) total number minutes spent service person (Minutes, response).Fit least squares linear regression model. Display summary model obtained part 1. Plot data overlay linear regression function obtained part 1. Obtain point estimate mean service time 7 copiers serviced. Obtain 95% confidence interval slope. Obtain 95% confidence interval mean service time 7 copiers serviced. Obtain 95% prediction interval mean service time 7 copiers serviced.","code":""},{"path":"ps-4-solutions.html","id":"ps-4-solutions","chapter":"PS 4 Solutions","heading":"PS 4 Solutions","text":" ","code":""},{"path":"ps-4-solutions.html","id":"problem-1-4","chapter":"PS 4 Solutions","heading":"Problem 1","text":"problem use functions apply() family functions whenever think need loops. Create function (name fun1) takes three arguments n, miu, sd (n number randomly generated numbers, miu mean value distribution numbers come , sd standard deviation distribution) following:\nFirst generates n random numbers normal distribution mean = miu standard deviation = sd\npopulates empty matrix follows: n divisible 2 3, fills matrix row, 2 rows n/2 columns; n divisible 3 2, fills matrix column, 3 columns n/3 rows; n divisible 2 3, fills matrix row, 6 rows n/6 columns; else fills row one column\nreturns vector mean values column matrix none randomly generated numbers negative; returns vector median values row matrix randomly generated numbers negative.\nTest function (n = 50, miu = 0.5, sd = 2)Create function (name fun1) takes three arguments n, miu, sd (n number randomly generated numbers, miu mean value distribution numbers come , sd standard deviation distribution) following:First generates n random numbers normal distribution mean = miu standard deviation = sdThen populates empty matrix follows: n divisible 2 3, fills matrix row, 2 rows n/2 columns; n divisible 3 2, fills matrix column, 3 columns n/3 rows; n divisible 2 3, fills matrix row, 6 rows n/6 columns; else fills row one columnAnd returns vector mean values column matrix none randomly generated numbers negative; returns vector median values row matrix randomly generated numbers negative.Test function (n = 50, miu = 0.5, sd = 2) Create function (name fun2) take one argument n, represents number trials simulation. function simulate process rolling unfair die following probability distribution: “1” - 0.1, “2” - 0.3, “3” - 0.2, “4” - 0.05, “5” - 0.3, “6” - 0.05. report results n trials returning frequency table outcomes (example, many times got “1”, “2”, ).\nTest function n = 100.Create function (name fun2) take one argument n, represents number trials simulation. function simulate process rolling unfair die following probability distribution: “1” - 0.1, “2” - 0.3, “3” - 0.2, “4” - 0.05, “5” - 0.3, “6” - 0.05. report results n trials returning frequency table outcomes (example, many times got “1”, “2”, ).Test function n = 100.“1” - 0.1, “2” - 0.3, “3” - 0.2, “4” - 0.05, “5” - 0.3, “6” - 0.05 Create function (name fun3) take one argument n, represents number trials simulation. function simulate process rolling two fair dice. report results n trials returning vectors outcomes dice (name Die1 Die2, respectively) vector compares outcomes obtained Die1 Die2 (name comparison). comparison vector created follows: created using mapply() function factor three levels (“Die1 > Die2”, “Die1 < Die2”, “Die1 = Die2”). instance, outcome Die1 5 outcome Die2 4, produce “Die1 > Die2”.\nTest function n = 30.Create function (name fun3) take one argument n, represents number trials simulation. function simulate process rolling two fair dice. report results n trials returning vectors outcomes dice (name Die1 Die2, respectively) vector compares outcomes obtained Die1 Die2 (name comparison). comparison vector created follows: created using mapply() function factor three levels (“Die1 > Die2”, “Die1 < Die2”, “Die1 = Die2”). instance, outcome Die1 5 outcome Die2 4, produce “Die1 > Die2”.Test function n = 30. ","code":"\nset.seed(1)\n\nfun1 <- function(n, miu, sd){\n  \n  data <- rnorm(n, mean=miu, sd=sd)\n  \n  if (n%%2==0 && n%%3!=0) {\n    \n    mat <- matrix(data, byrow=T, nrow=2)\n    \n  }\n  \n  else if (n%%3==0 && n%%2!=0) {\n    \n    mat <- matrix(data, byrow=F, ncol=3)\n    \n  }\n  \n  else if (n%%2==0 && n%%3==0) {\n    \n    mat <- matrix(data, byrow=T, nrow=6)\n    \n  }\n  \n  else {\n    \n    mat <- matrix(data, byrow=T, nrow=1)\n    \n  }\n  \n  print(\"The matrix is:\")\n  \n  print(mat)\n  \n  if (all(mat>=0)) {\n    \n    result <- apply(mat, 2, mean)\n    \n  }\n  \n  else {\n    \n    result <- apply(mat, 1, median)\n    \n  }\n  \n  print(\"The funciton result is:\")\n  \n  return (result)\n}\n\nfun1(n = 50, miu = 0.5, sd = 2)\n#> [1] \"The matrix is:\"\n#>            [,1]      [,2]      [,3]       [,4]     [,5]\n#> [1,] -0.7529076 0.8672866 -1.171257  3.6905616 1.159016\n#> [2,]  0.3877425 0.1884090 -2.441505 -0.4563001 1.335883\n#>           [,6]      [,7]     [,8]      [,9]      [,10]\n#> [1,] -1.140937 1.4748581 1.976649 1.6515627 -0.1107768\n#> [2,]  3.217359 0.2944245 1.275343 0.3923899 -2.2541191\n#>           [,11]      [,12]      [,13]     [,14]    [,15]\n#> [1,]  3.5235623  1.2796865 -0.7424812 -3.929400 2.749862\n#> [2,] -0.3299891 -0.2885799  0.3813732  2.700051 2.026351\n#>          [,16]       [,17]    [,18]    [,19]      [,20]\n#> [1,] 0.4101328  0.46761947 2.387672 2.142442  1.6878026\n#> [2,] 0.1709528 -0.00672336 1.893927 1.613326 -0.8775114\n#>           [,21]    [,22]    [,23]      [,24]    [,25]\n#> [1,]  2.3379547 2.064273 0.649130 -3.4787034 1.739651\n#> [2,] -0.9149903 1.229164 2.037066  0.2753076 2.262215\n#> [1] \"The funciton result is:\"\n#> [1] 1.2796865 0.3813732\nset.seed(1)\n\nfun2 <- function(n) {\n  \n  trials <- sample(1:6, n, replace=T, prob=c(0.1, 0.3, 0.2, 0.05, 0.3, 0.05))\n  \n  return(table(trials))\n  \n}\n\nfun2(100)\n#> trials\n#>  1  2  3  4  5  6 \n#> 11 33 26  2 24  4\nset.seed(1)\n\nfun3 <- function(n) {\n  \n  Die1 <- sample(1:6, n, replace=T)\n  \n  Die2 <- sample(1:6, n, replace=T)\n  \n  compare <- function(a, b) {\n    \n    if (a>b) {\n      \n      return (factor(\"Die1 > Die2\"))\n    }\n    \n    else if (a<b) {\n      \n      return (factor(\"Die1 < Die2\"))\n      \n    }\n    else {\n      \n      return (factor(\"Die1 = Die2\"))\n      \n    }\n    \n  }\n  \n  comparison <- mapply(compare, Die1, Die2)\n  \n  return (data.frame(Die1, Die2, comparison))\n  \n}\n\nfun3(30)\n#>    Die1 Die2  comparison\n#> 1     1    1 Die1 = Die2\n#> 2     4    4 Die1 = Die2\n#> 3     1    3 Die1 < Die2\n#> 4     2    6 Die1 < Die2\n#> 5     5    2 Die1 > Die2\n#> 6     3    2 Die1 > Die2\n#> 7     6    6 Die1 = Die2\n#> 8     2    4 Die1 < Die2\n#> 9     3    4 Die1 < Die2\n#> 10    3    4 Die1 < Die2\n#> 11    1    2 Die1 < Die2\n#> 12    5    4 Die1 > Die2\n#> 13    5    1 Die1 > Die2\n#> 14    2    6 Die1 < Die2\n#> 15    6    1 Die1 > Die2\n#> 16    6    4 Die1 > Die2\n#> 17    2    1 Die1 > Die2\n#> 18    1    6 Die1 < Die2\n#> 19    5    2 Die1 > Die2\n#> 20    5    3 Die1 > Die2\n#> 21    1    2 Die1 < Die2\n#> 22    1    6 Die1 < Die2\n#> 23    6    6 Die1 = Die2\n#> 24    5    2 Die1 > Die2\n#> 25    5    5 Die1 = Die2\n#> 26    2    2 Die1 = Die2\n#> 27    2    6 Die1 < Die2\n#> 28    6    6 Die1 = Die2\n#> 29    1    6 Die1 < Die2\n#> 30    4    1 Die1 > Die2"},{"path":"ps-4-solutions.html","id":"problem-2-3","chapter":"PS 4 Solutions","heading":"Problem 2","text":"John new real estate agent area. friend , worked area , told average price houses sold area $210,000. John feels bit skeptical claim wants test . Perform appropriate statistical procedure test claim. Use \\(\\alpha = 0.05\\) significance level make conclusion. State null alternative hypotheses. test statistic? degrees freedom? p-value? conclude?\\[\\begin{align}\n& H_{0}: \\textrm{average price houses sold area equals \\$210,000.} \\\\\n& H_{1}: \\textrm{average price houses sold area } \\neq \\textrm{ \\$210,000.}\n\\end{align}\\]test statistics \\(t = \\frac{\\bar{x}-210000}{s/sqrt{n}} \\sim t(n-1)\\), \\(n\\) sample size:degrees freedom equals \\(n-1 = 2924\\).Based t-test, \\(p\\)-values \\(<2.2\\times 10^{-16}\\). Thus, reject null hypothesis conclude “average house price area different $210,000”. John industry quite time. course past 10 years, ’s noticed type roof houses can somehow define fence quality. words, thinks two features (Roof_Style Fence variables dataset) somehow related. Test hypothesis based sample data \\(\\alpha = 0.01\\) significance level. State null alternative hypotheses. test statistic? degrees freedom? p-value? conclude?\\[\\begin{align}\n& H_{0}: \\textrm{\"Roof Style\" \"Fence\" independent. observed difference due chance.} \\\\\n& H_{1}: \\textrm{\"Roof Style\" \"Fence\" independent. observed difference due chance.}\n\\end{align}\\]test statistics \n\\[\n\\chi^{2} = \\sum_{=1}^{k}\\frac{(\\textrm{observed}_{} - \\textrm{exptected}_{})^{2}}{\\textrm{expected}_{}}.\n\\]observed values cell values table:Suppose “Roof_Style” “Fence” independent. expected value “Good_Privacy” fence “Flat” roof style :\\[\n118\\times\\frac{20}{2925} \\approx 0.8068.\n\\]degrees freedom :\n\\[\n(\\textrm{number rows} - 1)(\\textrm{number columns}-1) = (5-1)\\times(5-1) = 16.\n\\]\\(p\\)-value \\(0.1522\\). larger significance level \\(0.1\\). fail reject null hypothesis. conclude roof style fence independent. John specifically interested two neighborhoods: North_Ames College_Creek. research prior arrival thinks average houses College_Creek neighborhood $50,000 expensive houses sold North_Ames neighborhood. Test hypothesis \\(\\alpha = 0.02\\) significance level. State null alternative hypotheses. test statistic? degrees freedom? p-value? conclude?Let \\(\\mu_{\\textrm{collegeCreek}}\\) mean housing price “College_Creek” \\(\\mu_{\\textrm{northAmes}}\\) mean housing price “North_Ames”. hypotheses :\\[\\begin{align*}\n& H_{0}: \\mu_{\\textrm{collegeCreek}}-\\mu_{\\textrm{northAmes}}  =  \\textrm{\\$50,000}. \\\\\n& H_{1}: \\mu_{\\textrm{collegeCreek}}-\\mu_{\\textrm{northAmes}} > \\textrm{\\$50,000}.\n\\end{align*}\\]Perform Levene’s test test variances housing price “College_Creek” “North_Ames” homogeneous.\\(p\\)-value Levene’s test pretty small, indicating variances housing price “College_Creek” “North_Ames” different.test statistics \n\\[\nt = \\frac{\\bar{x}_{1}-\\bar{x}_{2}-50000}{\\sqrt{s_{1}^{2}/n_{1}+s^{2}_{2}/n_{2}}} \\sim t(n_{1}+n_{2}-2).\n\\]degrees freedom :\\(p\\)-value two-sample t test \\(0.033\\), greater significance level \\(0.02\\). fail reject \\(H_{0}\\). conclude average housing price “College_Creek” $50,000 expensive “North_Ames”. John decides split homes dataset following three groups based total number rooms ground: \"2-4\", \"5-8\", \"9 \". believes 10% homes belong \"2-4\" category, 85% belong \"5-8\" category, remaining 5% belong \"9 \" category. Test hypothesis using appropriate statistical procedure \\(\\alpha = 0.01\\) significance level. State null alternative hypotheses. test statistic? degrees freedom? p-value? conclude?\nperform test, need add new variable dataset (name Rooms) using splitting rule proposed John. words, need create factor variable 3 levels converting TotRms_AbvGrd variable. (Hint: might want check case_when() function dpyr package).John decides split homes dataset following three groups based total number rooms ground: \"2-4\", \"5-8\", \"9 \". believes 10% homes belong \"2-4\" category, 85% belong \"5-8\" category, remaining 5% belong \"9 \" category. Test hypothesis using appropriate statistical procedure \\(\\alpha = 0.01\\) significance level. State null alternative hypotheses. test statistic? degrees freedom? p-value? conclude?perform test, need add new variable dataset (name Rooms) using splitting rule proposed John. words, need create factor variable 3 levels converting TotRms_AbvGrd variable. (Hint: might want check case_when() function dpyr package).\\[\\begin{align*}\n& H_{0}: \\textrm{distribution number rooms ground :} \\\\\n& \\textrm{\"2-4\" accounts 10%, \"5-8\" accounts 85% \"9 \" accounts 5%.} \\\\\n& H_{1}: \\textrm{distribution number rooms ground : }\\\\\n& \\textrm{\"2-4\" accounts 10%, \"5-8\" accounts 85% \"9 \" accounts 5%.}\n\\end{align*}\\]test statistics \n\\[\n\\chi^{2} = \\sum_{=1}^{k}\\frac{(\\textrm{observed}_{} - \\textrm{exptected}_{})^{2}}{\\textrm{expected}_{}}.\n\\]\ndegrees freedom \\(3-1 = 2\\).\\(p\\)-value \\(<2.2\\times 10^{-16}\\), smaller significance level \\(0.01\\). reject null hypothesis conclude distribution grades number rooms ground : “2-4” ~ 10%, “5-8” ~ 85% “9 ” ~ 5%. ","code":"\n\ndata <- read.csv(\"ames_housing.csv\", header = T, stringsAsFactors = TRUE)\n\nlibrary(tidyverse)\n#> ── Attaching packages ─────────────────── tidyverse 1.3.2 ──\n#> ✔ ggplot2 3.3.6      ✔ purrr   0.3.5 \n#> ✔ tibble  3.1.8      ✔ dplyr   1.0.10\n#> ✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n#> ✔ readr   2.1.3      ✔ forcats 0.5.2 \n#> ── Conflicts ────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\nlength(data$Sale_Price)\n#> [1] 2925\nt.test(x=data$Sale_Price,\n       alternative = \"two.sided\",\n       mu = 210000,\n       conf.level = 0.95)\n#> \n#>  One Sample t-test\n#> \n#> data:  data$Sale_Price\n#> t = -19.783, df = 2924, p-value < 2.2e-16\n#> alternative hypothesis: true mean is not equal to 210000\n#> 95 percent confidence interval:\n#>  177878.2 183671.5\n#> sample estimates:\n#> mean of x \n#>  180774.9\ndata %>%\n  \n  select(Roof_Style, Fence) %>%\n  \n  table() %>%\n  \n  addmargins()\n#>           Fence\n#> Roof_Style Good_Privacy Good_Wood Minimum_Privacy\n#>    Flat               1         1               0\n#>    Gable             96        92             263\n#>    Gambrel            2         2               7\n#>    Hip               19        16              59\n#>    Mansard            0         1               1\n#>    Sum              118       112             330\n#>           Fence\n#> Roof_Style Minimum_Wood_Wire No_Fence  Sum\n#>    Flat                    0       18   20\n#>    Gable                   8     1862 2321\n#>    Gambrel                 0       11   22\n#>    Hip                     4      453  551\n#>    Mansard                 0        9   11\n#>    Sum                    12     2353 2925\nchisq.test(data$Roof_Style, data$Fence)\n#> \n#>  Pearson's Chi-squared test\n#> \n#> data:  data$Roof_Style and data$Fence\n#> X-squared = 21.698, df = 16, p-value = 0.1532\nlibrary(car)\ndata1 <- data %>% filter(Neighborhood %in% c(\"College_Creek\", \"North_Ames\"))\nleveneTest(Sale_Price ~ Neighborhood, data = data1)\n#> Levene's Test for Homogeneity of Variance (center = median)\n#>        Df F value    Pr(>F)    \n#> group   1  63.816 5.539e-15 ***\n#>       708                      \n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nnrow(data1)-2\n#> [1] 708\ncollegeCreek <- data1 %>%\n  \n         filter(Neighborhood == \"College_Creek\") %>%\n          \n         select(Sale_Price)\n\nnorthAmes <- data1 %>%\n  \n         filter(Neighborhood == \"North_Ames\") %>%\n          \n         select(Sale_Price)\n\nt.test(x = collegeCreek,\n       \n       y = northAmes,\n       \n       alternative = \"greater\",\n       \n       var.equal = FALSE,\n       \n       mu = 50000,\n       \n       conf.level = 0.98)\n#> \n#>  Welch Two Sample t-test\n#> \n#> data:  collegeCreek and northAmes\n#> t = 1.8394, df = 378.66, p-value = 0.03332\n#> alternative hypothesis: true difference in means is greater than 50000\n#> 98 percent confidence interval:\n#>  49192.59      Inf\n#> sample estimates:\n#> mean of x mean of y \n#>  201803.4  145097.3\ncategorize <- function(x) {\n  case_when(x<=4 & x>=2 ~ \"2-4\",\n            x<=8 & x>=5 ~ \"5-8\",\n            x>=9 ~ \"9 or more\") %>%\n  as.factor()\n}\ndata <- data %>%\n  mutate(Rooms = categorize(TotRms_AbvGrd))\ndata %>% \n  select(Rooms) %>%\n  table()\n#> Rooms\n#>       2-4       5-8 9 or more \n#>       228      2424       273\nchisq.test(x=c(228, 2424, 273), p=c(0.1, 0.85, 0.05))\n#> \n#>  Chi-squared test for given probabilities\n#> \n#> data:  c(228, 2424, 273)\n#> X-squared = 125.63, df = 2, p-value < 2.2e-16"},{"path":"ps-4-solutions.html","id":"problem-3-3","chapter":"PS 4 Solutions","heading":"Problem 3","text":"Fit least squares linear regression model. Display summary model obtained part 1. Plot data overlay linear regression function obtained part 1. Obtain point estimate mean service time 7 copiers serviced. Obtain 95% confidence interval slope. Obtain 95% confidence interval mean service time 7 copiers serviced. Obtain 95% prediction interval mean service time 7 copiers serviced.","code":"\n\ndata2 <- read.table(file = \"copier_maintenance.txt\", header = T, sep = \"\")\n\n\nmodel <- lm(Minutes ~ Copiers, data = data2)\n\nsummary(model)\n#> \n#> Call:\n#> lm(formula = Minutes ~ Copiers, data = data2)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -22.7723  -3.7371   0.3334   6.3334  15.4039 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)  -0.5802     2.8039  -0.207    0.837    \n#> Copiers      15.0352     0.4831  31.123   <2e-16 ***\n#> ---\n#> Signif. codes:  \n#> 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 8.914 on 43 degrees of freedom\n#> Multiple R-squared:  0.9575, Adjusted R-squared:  0.9565 \n#> F-statistic: 968.7 on 1 and 43 DF,  p-value: < 2.2e-16\n\nlibrary(tidyverse)\n\n  ggplot(data = data2, aes(x = Copiers, y = Minutes)) + \n  \n  geom_point(color = \"steelblue\") +\n  \n  labs(title = \"Minutes versus Copiers\",\n       \n       x = \"Copiers\",\n       \n       y = \"Minutes\") +\n  \n  geom_smooth(method = 'lm', se = FALSE)\n#> `geom_smooth()` using formula 'y ~ x'\n\npredict(model, data.frame(Copiers = 7))\n#>        1 \n#> 104.6666\n\nconfint(model, \"Copiers\", level = 0.95)\n#>            2.5 %   97.5 %\n#> Copiers 14.06101 16.00949\n\npredict(model, data.frame(Copiers = 7), interval = \"confidence\", level = 0.95)\n#>        fit      lwr      upr\n#> 1 104.6666 101.4159 107.9173\n\npredict(model, data.frame(Copiers = 7), interval = \"prediction\", level = 0.95)\n#>        fit      lwr      upr\n#> 1 104.6666 86.39922 122.9339"}]
